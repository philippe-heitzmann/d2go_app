module __torch__.detectron2.export.flatten.TracingAdapter {
  parameters {
  }
  attributes {
    training = True
    _is_full_backward_hook = None
    model = <__torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper object at 00000230BC4C76F0>
  }
  methods {
    method forward {
      graph(%self.1 : __torch__.detectron2.export.flatten.TracingAdapter,
            %1883 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu)):
        %model : __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper = prim::GetAttr[name="model"](%self.1)
        %5354 : (Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%model, %1883)
        %5350 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), %5351 : Long(0, strides=[2], requires_grad=0, device=cpu), %5352 : Float(0, strides=[1], requires_grad=0, device=cpu), %5353 : Long(2, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%5354)
        %4213 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(0, strides=[2], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu), Long(2, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%5350, %5351, %5352, %5353)
        return (%4213)
  
    }
  }
  submodules {
    module __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper {
      parameters {
      }
      attributes {
        training = True
        _is_full_backward_hook = None
        model = <__torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN object at 00000230BC4C79F0>
      }
      methods {
        method forward {
          graph(%self.3 : __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper,
                %13 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu)):
            %model.9 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %roi_heads : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads = prim::GetAttr[name="roi_heads"](%model.9)
            %model.7 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %proposal_generator : __torch__.detectron2.modeling.proposal_generator.rpn.RPN = prim::GetAttr[name="proposal_generator"](%model.7)
            %model.5 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %backbone : __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass = prim::GetAttr[name="backbone"](%model.5)
            %model.3 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %pixel_std : Tensor = prim::GetAttr[name="pixel_std"](%model.3)
            %model.1 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%model.1)
            %11 : Function = prim::Constant[name="move_device_like"](), scope: __module.model
            %x.1 : Tensor = prim::CallFunction(%11, %13, %pixel_mean), scope: __module.model
            %14 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:229:0
            %15 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu) = aten::sub(%x.1, %pixel_mean, %14), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:229:0
            %t : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu) = aten::div(%15, %pixel_std), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:229:0
            %39 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %40 : int = aten::size(%t, %39), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %41 : Long(device=cpu) = prim::NumToTensor(%40), scope: __module.model
            %51 : int = prim::Constant[value=2](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %52 : int = aten::size(%t, %51), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %53 : Long(device=cpu) = prim::NumToTensor(%52), scope: __module.model
            %54 : Tensor[] = prim::ListConstruct(%41, %53), scope: __module.model
            %55 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
            %image_size : Long(2, strides=[1], requires_grad=0, device=cpu) = aten::stack(%54, %55), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
            %57 : Tensor[] = prim::ListConstruct(%image_size), scope: __module.model
            %58 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %59 : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::stack(%57, %58), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %60 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %61 : bool = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %max_size : Long(2, strides=[1], requires_grad=0, device=cpu), %63 : Long(2, strides=[1], requires_grad=0, device=cpu) = aten::max(%59, %60, %61), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %64 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %65 : int = prim::Constant[value=-1](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %66 : Long(requires_grad=0, device=cpu) = aten::select(%max_size, %64, %65), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %67 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %68 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %69 : Long(requires_grad=0, device=cpu) = aten::select(%image_size, %67, %68), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %70 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %71 : Long(requires_grad=0, device=cpu) = aten::sub(%66, %69, %70), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %72 : int = aten::Int(%71), scope: __module.model
            %73 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %74 : int = prim::Constant[value=-2](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %75 : Long(requires_grad=0, device=cpu) = aten::select(%max_size, %73, %74), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %76 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %77 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %78 : Long(requires_grad=0, device=cpu) = aten::select(%image_size, %76, %77), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %79 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %80 : Long(requires_grad=0, device=cpu) = aten::sub(%75, %78, %79), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %81 : int = aten::Int(%80), scope: __module.model
            %82 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %83 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %84 : int[] = prim::ListConstruct(%82, %72, %83, %81), scope: __module.model
            %85 : str = prim::Constant[value="constant"](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %86 : float = prim::Constant[value=0.](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %87 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu) = aten::pad(%t, %84, %85, %86), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %88 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %batched_imgs : Float(1, 3, 667, 1333, strides=[3, 1, 3999, 3], requires_grad=0, device=cpu) = aten::unsqueeze_(%87, %88), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %90 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:127:0
            %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu) = aten::contiguous(%batched_imgs, %90), scope: __module.model # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:127:0
            %99 : Tensor = prim::CallMethod[name="forward"](%backbone, %X.1)
            %100 : Tensor = prim::CallMethod[name="forward"](%proposal_generator, %99, %image_size)
            %101 : (Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%roi_heads, %99, %100, %image_size)
            %95 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), %96 : Long(0, strides=[2], requires_grad=0, device=cpu), %97 : Float(0, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%101)
            %98 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(0, strides=[2], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu), Long(2, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%95, %96, %97, %image_size)
            return (%98)
      
        }
      }
      submodules {
        module __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN {
          parameters {
          }
          attributes {
            pixel_mean = ...
            pixel_std = ...
            training = False
            _is_full_backward_hook = None
            backbone = <__torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass object at 00000230BBFDE940>
            proposal_generator = <__torch__.detectron2.modeling.proposal_generator.rpn.RPN object at 00000230BC1BC3D0>
            roi_heads = <__torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads object at 00000230BC4C67F0>
          }
          methods {
          }
          submodules {
            module __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                body = <__torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone object at 00000230BBFDF3C0>
                quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested object at 00000230BBFDFAC0>
                dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested object at 00000230BBFDFF40>
              }
              methods {
                method forward {
                  graph(%self.5 : __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass,
                        %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                    %dequant_stubs.1 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.5)
                    %body : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone = prim::GetAttr[name="body"](%self.5)
                    %quant_stubs.1 : __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.5)
                    %12 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.1, %X.1)
                    %13 : (Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%body, %12)
                    %7 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu), %8 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu), %9 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu), %10 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = prim::TupleUnpack(%13)
                    %14 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs.1, %7, %8, %9, %10)
                    return (%14)
              
                }
              }
              submodules {
                module __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    trunk0 = <__torch__.torch.nn.modules.container.Sequential object at 00000230AE4D84C0>
                    trunk1 = <__torch__.torch.nn.modules.container.___torch_mangle_29.Sequential object at 00000230AE4EFAC0>
                    trunk2 = <__torch__.torch.nn.modules.container.___torch_mangle_79.Sequential object at 00000230BC0CA140>
                    trunk3 = <__torch__.torch.nn.modules.container.___torch_mangle_178.Sequential object at 00000230BBFE0040>
                  }
                  methods {
                    method forward {
                      graph(%self.11 : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone,
                            %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                        %trunk3 : __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential = prim::GetAttr[name="trunk3"](%self.11)
                        %trunk2 : __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential = prim::GetAttr[name="trunk2"](%self.11)
                        %trunk1 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="trunk1"](%self.11)
                        %trunk0 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="trunk0"](%self.11)
                        %11 : Tensor = prim::CallMethod[name="forward"](%trunk0, %1)
                        %12 : Tensor = prim::CallMethod[name="forward"](%trunk1, %11)
                        %13 : Tensor = prim::CallMethod[name="forward"](%trunk2, %12)
                        %14 : Tensor = prim::CallMethod[name="forward"](%trunk3, %13)
                        %10 : (QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu), QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu), QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu), QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11, %12, %13, %14)
                        return (%10)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu object at 00000230AE4D18C0>
                        fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock object at 00000230AE4D9CC0>
                      }
                      methods {
                        method forward {
                          graph(%self.13 : __torch__.torch.nn.modules.container.Sequential,
                                %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                            %fbnetv2_0_1.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.13)
                            %fbnetv2_0_0.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu = prim::GetAttr[name="fbnetv2_0_0"](%self.13)
                            %6 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.1, %1)
                            %7 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.1, %6)
                            return (%7)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d object at 00000230AE4D04C0>
                            bn = <__torch__.torch.nn.modules.linear.Identity object at 00000230AE4D1CC0>
                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_0.Identity object at 00000230AE4D1140>
                          }
                          methods {
                            method forward {
                              graph(%self.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu,
                                    %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                                %relu.1 : __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity = prim::GetAttr[name="relu"](%self.15)
                                %bn.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name="bn"](%self.15)
                                %conv.1 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d = prim::GetAttr[name="conv"](%self.15)
                                %8 : Tensor = prim::CallMethod[name="forward"](%conv.1, %1)
                                %9 : NoneType = prim::CallMethod[name="forward"](%bn.1)
                                %10 : NoneType = prim::CallMethod[name="forward"](%relu.1)
                                return (%8)
                          
                            }
                          }
                          submodules {
                            module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                                in_channels = 3
                                out_channels = 16
                                kernel_size = (3, 3)
                                stride = (2, 2)
                                padding = (1, 1)
                                dilation = (1, 1)
                                transposed = False
                                output_padding = (0, 0)
                                groups = 1
                                padding_mode = zeros
                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4D1840>
                                scale = 0.11585384607315063
                                zero_point = 0
                              }
                              methods {
                                method __getstate__ {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d):
                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                    %training : bool = prim::GetAttr[name="training"](%self)
                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                    return (%19)
                              
                                }
                                method __setstate__ {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                    %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                    %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                    %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                    %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                    %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                    %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                    %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                    %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                    %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                    %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                    %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                    %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                    %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                    %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                    %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                    %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                     = prim::SetAttr[name="stride"](%self, %13)
                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                     = prim::SetAttr[name="padding"](%self, %16)
                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                     = prim::SetAttr[name="dilation"](%self, %19)
                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                     = prim::SetAttr[name="transposed"](%self, %22)
                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                     = prim::SetAttr[name="groups"](%self, %28)
                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                     = prim::SetAttr[name="scale"](%self, %41)
                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                     = prim::SetAttr[name="training"](%self, %47)
                                    return (%48)
                              
                                }
                                method _weight_bias {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d):
                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                    return (%2)
                              
                                }
                                method set_weight_bias {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
                                        %w.1 : Tensor,
                                        %b.1 : Tensor?):
                                    %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                    %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                    %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                     = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                      block0():
                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                        -> ()
                                      block1():
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                        -> ()
                                    return (%37)
                              
                                }
                                method forward {
                                  graph(%self.17 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
                                        %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                                    %_packed_params.1 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.17)
                                    %15 : float = prim::Constant[value=0.11585384607315063](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.3 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.1, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    return (%input.3)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.modules.linear.Identity {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.19 : __torch__.torch.nn.modules.linear.Identity):
                                    %1 : NoneType = prim::Constant()
                                    return (%1)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.21 : __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity):
                                    %1 : NoneType = prim::Constant()
                                    return (%1)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu object at 00000230AE4D0340>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu object at 00000230AE4D4A40>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd object at 00000230AE4D82C0>
                          }
                          methods {
                            method forward {
                              graph(%self.23 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock,
                                    %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                %res_conn.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd = prim::GetAttr[name="res_conn"](%self.23)
                                %pwl.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu = prim::GetAttr[name="pwl"](%self.23)
                                %dw.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu = prim::GetAttr[name="dw"](%self.23)
                                %8 : Tensor = prim::CallMethod[name="forward"](%dw.9, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%pwl.1, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%res_conn.1, %9, %1)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.Conv2d object at 00000230AE4D01C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %conv.3 : __torch__.torch.nn.quantized.modules.conv.Conv2d = prim::GetAttr[name="conv"](%self.25)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.3, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 16
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4D0FC0>
                                    scale = 0.029041629284620285
                                    zero_point = 92
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.27 : __torch__.torch.nn.quantized.modules.conv.Conv2d,
                                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.3 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.27)
                                        %15 : float = prim::Constant[value=0.029041629284620285](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=92](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.5 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.3, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.5)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d object at 00000230AE4D4040>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_3.Identity object at 00000230AE4D4940>
                              }
                              methods {
                                method forward {
                                  graph(%self.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %bn.3 : __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity = prim::GetAttr[name="bn"](%self.29)
                                    %conv.5 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv"](%self.29)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.5, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.3)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4D5C40>
                                    scale = 0.1336701512336731
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.31 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
                                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.5 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.31)
                                        %15 : float = prim::Constant[value=0.1336701512336731](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.5, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.33 : __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.QFunctional object at 00000230AE4D99C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %add_func.1 : __torch__.torch.nn.quantized.modules.functional_modules.QFunctional = prim::GetAttr[name="add_func"](%self.35)
                                    %activation_post_process.1 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity = prim::GetAttr[name="activation_post_process"](%add_func.1)
                                    %5 : float = prim::Constant[value=0.18334655463695526](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=47](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.7 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.1)
                                    return (%input.7)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5.Identity object at 00000230AE4D71C0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.37 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_1_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock object at 00000230AE4E28C0>
                        fbnetv2_1_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock object at 00000230AE4ED4C0>
                      }
                      methods {
                        method forward {
                          graph(%self.39 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential,
                                %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                            %fbnetv2_1_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock = prim::GetAttr[name="fbnetv2_1_1"](%self.39)
                            %fbnetv2_1_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock = prim::GetAttr[name="fbnetv2_1_0"](%self.39)
                            %6 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_0, %1)
                            %7 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_1, %6)
                            return (%7)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu object at 00000230AE4DA840>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu object at 00000230AE4DD740>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu object at 00000230AE4DF840>
                          }
                          methods {
                            method forward {
                              graph(%self.41 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock,
                                    %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                %pwl.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu = prim::GetAttr[name="pwl"](%self.41)
                                %dw.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu = prim::GetAttr[name="dw"](%self.41)
                                %pw.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu = prim::GetAttr[name="pw"](%self.41)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.1, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.11, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.3, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d object at 00000230AE4DBF40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_7.Identity object at 00000230AE4DA2C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_8.Identity object at 00000230AE4DA3C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %relu.3 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity = prim::GetAttr[name="relu"](%self.43)
                                    %bn.5 : __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity = prim::GetAttr[name="bn"](%self.43)
                                    %conv.7 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d = prim::GetAttr[name="conv"](%self.43)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.7, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.5)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.3)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4DB4C0>
                                    scale = 0.078753829002380371
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.45 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
                                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.7 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.45)
                                        %15 : float = prim::Constant[value=0.078753829002380371](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.9 : QUInt8(1, 64, 334, 667, strides=[14257792, 1, 42688, 64], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.7, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.9)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.47 : __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.49 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d object at 00000230AE4DC8C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 334, 667, strides=[14257792, 1, 42688, 64], requires_grad=0, device=cpu)):
                                    %conv.9 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv"](%self.51)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.9, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 64
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 64
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4DCAC0>
                                    scale = 0.05707220733165741
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.53 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
                                            %1 : QUInt8(1, 64, 334, 667, strides=[14257792, 1, 42688, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.9 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.53)
                                        %15 : float = prim::Constant[value=0.05707220733165741](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.11 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.9, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.11)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d object at 00000230AE4DE040>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_13.Identity object at 00000230AE4DE5C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                    %bn.7 : __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity = prim::GetAttr[name="bn"](%self.55)
                                    %conv.11 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="conv"](%self.55)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.11, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.7)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4DE3C0>
                                    scale = 0.092787548899650574
                                    zero_point = 62
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.57 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
                                            %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.11 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.57)
                                        %15 : float = prim::Constant[value=0.092787548899650574](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.13 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.11, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.13)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.59 : __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu object at 00000230AE4E6640>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu object at 00000230AE4E73C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu object at 00000230AE4E8940>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd object at 00000230AE4ED3C0>
                          }
                          methods {
                            method forward {
                              graph(%self.61 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock,
                                    %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                %res_conn.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd = prim::GetAttr[name="res_conn"](%self.61)
                                %pwl.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu = prim::GetAttr[name="pwl"](%self.61)
                                %dw.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu = prim::GetAttr[name="dw"](%self.61)
                                %pw.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu = prim::GetAttr[name="pw"](%self.61)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.3, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.13, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.5, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.3, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d object at 00000230AE4E3940>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_17.Identity object at 00000230AE4E2DC0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_18.Identity object at 00000230AE4E54C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.63 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                    %relu.5 : __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity = prim::GetAttr[name="relu"](%self.63)
                                    %bn.9 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity = prim::GetAttr[name="bn"](%self.63)
                                    %conv.13 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d = prim::GetAttr[name="conv"](%self.63)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.13, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.9)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.5)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4E2FC0>
                                    scale = 0.02094450406730175
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.65 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.13 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.65)
                                        %15 : float = prim::Constant[value=0.02094450406730175](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.15 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.13, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.15)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.67 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.69 : __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d object at 00000230AE4E66C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.71 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                    %conv.15 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv"](%self.71)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.15, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 64
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 64
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4E76C0>
                                    scale = 0.016607090830802917
                                    zero_point = 49
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.73 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
                                            %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.15 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.73)
                                        %15 : float = prim::Constant[value=0.016607090830802917](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=49](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.17 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.15, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d object at 00000230AE4E7F40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_23.Identity object at 00000230AE4E96C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.75 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                    %bn.11 : __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity = prim::GetAttr[name="bn"](%self.75)
                                    %conv.17 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv"](%self.75)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.17, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.11)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4E8CC0>
                                    scale = 0.068524576723575592
                                    zero_point = 60
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.77 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
                                            %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.17 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.77)
                                        %15 : float = prim::Constant[value=0.068524576723575592](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.17, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.79 : __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional object at 00000230AE4ECC40>
                              }
                              methods {
                                method forward {
                                  graph(%self.81 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd,
                                        %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                    %add_func.3 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional = prim::GetAttr[name="add_func"](%self.81)
                                    %activation_post_process.3 : __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity = prim::GetAttr[name="activation_post_process"](%add_func.3)
                                    %5 : float = prim::Constant[value=0.10955619066953659](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.19 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.3)
                                    return (%input.19)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_25.Identity object at 00000230AE4EDFC0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.83 : __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_2_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock object at 00000230BC0AB0C0>
                        fbnetv2_2_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock object at 00000230BC0B3340>
                        fbnetv2_2_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock object at 00000230BC0BDFC0>
                        fbnetv2_2_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock object at 00000230BC0C7AC0>
                      }
                      methods {
                        method forward {
                          graph(%self.85 : __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential,
                                %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                            %fbnetv2_2_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock = prim::GetAttr[name="fbnetv2_2_3"](%self.85)
                            %fbnetv2_2_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock = prim::GetAttr[name="fbnetv2_2_2"](%self.85)
                            %fbnetv2_2_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock = prim::GetAttr[name="fbnetv2_2_1"](%self.85)
                            %fbnetv2_2_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock = prim::GetAttr[name="fbnetv2_2_0"](%self.85)
                            %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_0, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_1, %10)
                            %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_2, %11)
                            %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_3, %12)
                            return (%13)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu object at 00000230AE4F1940>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu object at 00000230AE4F1740>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu object at 00000230BC0AAB40>
                          }
                          methods {
                            method forward {
                              graph(%self.87 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock,
                                    %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                %pwl.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu = prim::GetAttr[name="pwl"](%self.87)
                                %dw.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu = prim::GetAttr[name="dw"](%self.87)
                                %pw.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu = prim::GetAttr[name="pw"](%self.87)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.5, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.15, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.7, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d object at 00000230AE4EFDC0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_31.Identity object at 00000230AE4EECC0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_32.Identity object at 00000230AE4EEF40>
                              }
                              methods {
                                method forward {
                                  graph(%self.89 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                    %relu.7 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity = prim::GetAttr[name="relu"](%self.89)
                                    %bn.13 : __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity = prim::GetAttr[name="bn"](%self.89)
                                    %conv.19 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d = prim::GetAttr[name="conv"](%self.89)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.19, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.13)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.7)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 128
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4EE740>
                                    scale = 0.025419605895876884
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.91 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.19 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.91)
                                        %15 : float = prim::Constant[value=0.025419605895876884](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.21 : QUInt8(1, 128, 167, 334, strides=[7139584, 1, 42752, 128], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.19, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.21)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.93 : __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.95 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d object at 00000230AE4F0C40>
                              }
                              methods {
                                method forward {
                                  graph(%self.97 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu,
                                        %1 : QUInt8(1, 128, 167, 334, strides=[7139584, 1, 42752, 128], requires_grad=0, device=cpu)):
                                    %conv.21 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="conv"](%self.97)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.21, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 128
                                    out_channels = 128
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 128
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4F1BC0>
                                    scale = 0.019645385444164276
                                    zero_point = 56
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.99 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
                                            %1 : QUInt8(1, 128, 167, 334, strides=[7139584, 1, 42752, 128], requires_grad=0, device=cpu)):
                                        %_packed_params.21 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.99)
                                        %15 : float = prim::Constant[value=0.019645385444164276](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.23 : QUInt8(1, 128, 84, 167, strides=[1795584, 1, 21376, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.21, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.23)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d object at 00000230AE4F26C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_37.Identity object at 00000230BC0AB040>
                              }
                              methods {
                                method forward {
                                  graph(%self.101 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu,
                                        %1 : QUInt8(1, 128, 84, 167, strides=[1795584, 1, 21376, 128], requires_grad=0, device=cpu)):
                                    %bn.15 : __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity = prim::GetAttr[name="bn"](%self.101)
                                    %conv.23 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="conv"](%self.101)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.23, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.15)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 128
                                    out_channels = 40
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230AE4F27C0>
                                    scale = 0.061339374631643295
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.103 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
                                            %1 : QUInt8(1, 128, 84, 167, strides=[1795584, 1, 21376, 128], requires_grad=0, device=cpu)):
                                        %_packed_params.23 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.103)
                                        %15 : float = prim::Constant[value=0.061339374631643295](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.25 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.23, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.25)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.105 : __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu object at 00000230BC0ABC40>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu object at 00000230BC0AE740>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu object at 00000230BC0B0EC0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd object at 00000230BC0B46C0>
                          }
                          methods {
                            method forward {
                              graph(%self.107 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock,
                                    %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                %res_conn.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd = prim::GetAttr[name="res_conn"](%self.107)
                                %pwl.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu = prim::GetAttr[name="pwl"](%self.107)
                                %dw.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu = prim::GetAttr[name="dw"](%self.107)
                                %pw.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu = prim::GetAttr[name="pw"](%self.107)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.7, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.17, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.9, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.5, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d object at 00000230BC0AC2C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_41.Identity object at 00000230BC0AD0C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_42.Identity object at 00000230BC0AC740>
                              }
                              methods {
                                method forward {
                                  graph(%self.109 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %relu.9 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity = prim::GetAttr[name="relu"](%self.109)
                                    %bn.17 : __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity = prim::GetAttr[name="bn"](%self.109)
                                    %conv.25 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d = prim::GetAttr[name="conv"](%self.109)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.25, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.17)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.9)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 40
                                    out_channels = 120
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0ABEC0>
                                    scale = 0.020118903368711472
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.111 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
                                            %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                        %_packed_params.25 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.111)
                                        %15 : float = prim::Constant[value=0.020118903368711472](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.27 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.25, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.27)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.113 : __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.115 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d object at 00000230BC0ABE40>
                              }
                              methods {
                                method forward {
                                  graph(%self.117 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu,
                                        %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                    %conv.27 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d = prim::GetAttr[name="conv"](%self.117)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.27, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 120
                                    out_channels = 120
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 120
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0AC4C0>
                                    scale = 0.0067670787684619427
                                    zero_point = 55
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.119 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
                                            %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                        %_packed_params.27 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.119)
                                        %15 : float = prim::Constant[value=0.0067670787684619427](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=55](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.29 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.27, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.29)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d object at 00000230BC0AE340>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_47.Identity object at 00000230BC0AFEC0>
                              }
                              methods {
                                method forward {
                                  graph(%self.121 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu,
                                        %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                    %bn.19 : __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity = prim::GetAttr[name="bn"](%self.121)
                                    %conv.29 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="conv"](%self.121)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.29, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.19)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 120
                                    out_channels = 40
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0AECC0>
                                    scale = 0.057710312306880951
                                    zero_point = 69
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.123 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
                                            %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                        %_packed_params.29 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.123)
                                        %15 : float = prim::Constant[value=0.057710312306880951](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.29, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.125 : __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional object at 00000230BC0B35C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.127 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %add_func.5 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional = prim::GetAttr[name="add_func"](%self.127)
                                    %activation_post_process.5 : __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity = prim::GetAttr[name="activation_post_process"](%add_func.5)
                                    %5 : float = prim::Constant[value=0.074877820909023285](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.31 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.5)
                                    return (%input.31)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_49.Identity object at 00000230BC0B50C0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.129 : __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu object at 00000230BC0B91C0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu object at 00000230BC0B79C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu object at 00000230BC0BA9C0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd object at 00000230BC0BDF40>
                          }
                          methods {
                            method forward {
                              graph(%self.131 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock,
                                    %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                %res_conn.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd = prim::GetAttr[name="res_conn"](%self.131)
                                %pwl.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu = prim::GetAttr[name="pwl"](%self.131)
                                %dw.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu = prim::GetAttr[name="dw"](%self.131)
                                %pw.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu = prim::GetAttr[name="pw"](%self.131)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.9, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.19, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.11, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.7, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d object at 00000230BC0B5B40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_54.Identity object at 00000230BC0B60C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_55.Identity object at 00000230BC0B6140>
                              }
                              methods {
                                method forward {
                                  graph(%self.133 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %relu.11 : __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity = prim::GetAttr[name="relu"](%self.133)
                                    %bn.21 : __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity = prim::GetAttr[name="bn"](%self.133)
                                    %conv.31 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d = prim::GetAttr[name="conv"](%self.133)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.31, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.21)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.11)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 40
                                    out_channels = 120
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0B5640>
                                    scale = 0.019609589129686356
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.135 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
                                            %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                        %_packed_params.31 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.135)
                                        %15 : float = prim::Constant[value=0.019609589129686356](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.33 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.31, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.33)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.137 : __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.139 : __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d object at 00000230BC0B74C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.141 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu,
                                        %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                    %conv.33 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d = prim::GetAttr[name="conv"](%self.141)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.33, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 120
                                    out_channels = 120
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 120
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0B7F40>
                                    scale = 0.0069701159372925758
                                    zero_point = 86
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.143 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
                                            %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                        %_packed_params.33 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.143)
                                        %15 : float = prim::Constant[value=0.0069701159372925758](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=86](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.35 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.33, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.35)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d object at 00000230BC0B9C40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_60.Identity object at 00000230BC0B9D40>
                              }
                              methods {
                                method forward {
                                  graph(%self.145 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu,
                                        %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                    %bn.23 : __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity = prim::GetAttr[name="bn"](%self.145)
                                    %conv.35 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d = prim::GetAttr[name="conv"](%self.145)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.35, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.23)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 120
                                    out_channels = 40
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0B98C0>
                                    scale = 0.065368488430976868
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.147 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
                                            %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                        %_packed_params.35 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.147)
                                        %15 : float = prim::Constant[value=0.065368488430976868](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.35, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.149 : __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional object at 00000230BC0BE7C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.151 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %add_func.7 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional = prim::GetAttr[name="add_func"](%self.151)
                                    %activation_post_process.7 : __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity = prim::GetAttr[name="activation_post_process"](%add_func.7)
                                    %5 : float = prim::Constant[value=0.10211624205112457](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=54](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.37 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.7)
                                    return (%input.37)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_62.Identity object at 00000230BC0BF140>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.153 : __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu object at 00000230BC0C2440>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu object at 00000230BC0C16C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu object at 00000230BC0C8D40>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd object at 00000230BC0C92C0>
                          }
                          methods {
                            method forward {
                              graph(%self.155 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock,
                                    %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                %res_conn.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd = prim::GetAttr[name="res_conn"](%self.155)
                                %pwl.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu = prim::GetAttr[name="pwl"](%self.155)
                                %dw.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu = prim::GetAttr[name="dw"](%self.155)
                                %pw.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu = prim::GetAttr[name="pw"](%self.155)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.11, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.21, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.13, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.9, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d object at 00000230BC0BFDC0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_67.Identity object at 00000230BC0C08C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_68.Identity object at 00000230BC0C0F40>
                              }
                              methods {
                                method forward {
                                  graph(%self.157 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %relu.13 : __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity = prim::GetAttr[name="relu"](%self.157)
                                    %bn.25 : __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity = prim::GetAttr[name="bn"](%self.157)
                                    %conv.37 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d = prim::GetAttr[name="conv"](%self.157)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.37, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.25)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.13)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 40
                                    out_channels = 120
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0BFC40>
                                    scale = 0.01242495235055685
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.159 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
                                            %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                        %_packed_params.37 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.159)
                                        %15 : float = prim::Constant[value=0.01242495235055685](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.39 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.37, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.39)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.161 : __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.163 : __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d object at 00000230BC0C30C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.165 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu,
                                        %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                    %conv.39 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="conv"](%self.165)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.39, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 120
                                    out_channels = 120
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 120
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0C19C0>
                                    scale = 0.0033951580990105867
                                    zero_point = 92
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.167 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
                                            %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                        %_packed_params.39 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.167)
                                        %15 : float = prim::Constant[value=0.0033951580990105867](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=92](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.41 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.39, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.41)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d object at 00000230BC0C36C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_73.Identity object at 00000230BC0C3DC0>
                              }
                              methods {
                                method forward {
                                  graph(%self.169 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu,
                                        %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                    %bn.27 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity = prim::GetAttr[name="bn"](%self.169)
                                    %conv.41 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="conv"](%self.169)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.41, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.27)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 120
                                    out_channels = 40
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0C3C40>
                                    scale = 0.044966179877519608
                                    zero_point = 54
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.171 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
                                            %1 : QUInt8(1, 120, 84, 167, strides=[1683360, 1, 20040, 120], requires_grad=0, device=cpu)):
                                        %_packed_params.41 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.171)
                                        %15 : float = prim::Constant[value=0.044966179877519608](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=54](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.41, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.173 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional object at 00000230BC0C7840>
                              }
                              methods {
                                method forward {
                                  graph(%self.175 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %add_func.9 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional = prim::GetAttr[name="add_func"](%self.175)
                                    %activation_post_process.9 : __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity = prim::GetAttr[name="activation_post_process"](%add_func.9)
                                    %5 : float = prim::Constant[value=0.10641296952962875](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=50](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.43 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.9)
                                    return (%input.43)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_75.Identity object at 00000230BC0C8040>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.177 : __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_3_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock object at 00000230BC0D29C0>
                        fbnetv2_3_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock object at 00000230BC0DE640>
                        fbnetv2_3_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock object at 00000230BC0E8040>
                        fbnetv2_3_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock object at 00000230BBFB4AC0>
                        fbnetv2_3_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock object at 00000230BBFBD140>
                        fbnetv2_3_5 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock object at 00000230BBFC8840>
                        fbnetv2_3_6 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock object at 00000230BBFD3640>
                        fbnetv2_3_7 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock object at 00000230BBFDCE40>
                      }
                      methods {
                        method forward {
                          graph(%self.179 : __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential,
                                %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                            %fbnetv2_3_7 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock = prim::GetAttr[name="fbnetv2_3_7"](%self.179)
                            %fbnetv2_3_6 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock = prim::GetAttr[name="fbnetv2_3_6"](%self.179)
                            %fbnetv2_3_5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock = prim::GetAttr[name="fbnetv2_3_5"](%self.179)
                            %fbnetv2_3_4 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock = prim::GetAttr[name="fbnetv2_3_4"](%self.179)
                            %fbnetv2_3_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock = prim::GetAttr[name="fbnetv2_3_3"](%self.179)
                            %fbnetv2_3_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock = prim::GetAttr[name="fbnetv2_3_2"](%self.179)
                            %fbnetv2_3_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock = prim::GetAttr[name="fbnetv2_3_1"](%self.179)
                            %fbnetv2_3_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock = prim::GetAttr[name="fbnetv2_3_0"](%self.179)
                            %18 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_0, %1)
                            %19 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_1, %18)
                            %20 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_2, %19)
                            %21 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_3, %20)
                            %22 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_4, %21)
                            %23 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_5, %22)
                            %24 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_6, %23)
                            %25 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_7, %24)
                            return (%25)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu object at 00000230BC0CCD40>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu object at 00000230BC0CD240>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu object at 00000230BC0D0C40>
                          }
                          methods {
                            method forward {
                              graph(%self.181 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock,
                                    %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                %pwl.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu = prim::GetAttr[name="pwl"](%self.181)
                                %dw.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu = prim::GetAttr[name="dw"](%self.181)
                                %pw.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu = prim::GetAttr[name="pw"](%self.181)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.13, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.23, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.15, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d object at 00000230BC0CB2C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_81.Identity object at 00000230BC0CAC40>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_82.Identity object at 00000230BC0CC7C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.183 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu,
                                        %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                    %relu.15 : __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity = prim::GetAttr[name="relu"](%self.183)
                                    %bn.29 : __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity = prim::GetAttr[name="bn"](%self.183)
                                    %conv.43 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d = prim::GetAttr[name="conv"](%self.183)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.43, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.29)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.15)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 40
                                    out_channels = 160
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0CA0C0>
                                    scale = 0.017263062298297882
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.185 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
                                            %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                        %_packed_params.43 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.185)
                                        %15 : float = prim::Constant[value=0.017263062298297882](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.45 : QUInt8(1, 160, 84, 167, strides=[2244480, 1, 26720, 160], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.43, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.45)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.187 : __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.189 : __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d object at 00000230BC0CCDC0>
                              }
                              methods {
                                method forward {
                                  graph(%self.191 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu,
                                        %1 : QUInt8(1, 160, 84, 167, strides=[2244480, 1, 26720, 160], requires_grad=0, device=cpu)):
                                    %conv.45 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d = prim::GetAttr[name="conv"](%self.191)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.45, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 160
                                    out_channels = 160
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 160
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0CD1C0>
                                    scale = 0.01257427129894495
                                    zero_point = 65
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.193 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
                                            %1 : QUInt8(1, 160, 84, 167, strides=[2244480, 1, 26720, 160], requires_grad=0, device=cpu)):
                                        %_packed_params.45 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.193)
                                        %15 : float = prim::Constant[value=0.01257427129894495](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.47 : QUInt8(1, 160, 42, 84, strides=[564480, 1, 13440, 160], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.45, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.47)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d object at 00000230BC0CE7C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_87.Identity object at 00000230BC0D0040>
                              }
                              methods {
                                method forward {
                                  graph(%self.195 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu,
                                        %1 : QUInt8(1, 160, 42, 84, strides=[564480, 1, 13440, 160], requires_grad=0, device=cpu)):
                                    %bn.31 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity = prim::GetAttr[name="bn"](%self.195)
                                    %conv.47 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d = prim::GetAttr[name="conv"](%self.195)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.47, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.31)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 160
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0CE9C0>
                                    scale = 0.065296202898025513
                                    zero_point = 48
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.197 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
                                            %1 : QUInt8(1, 160, 42, 84, strides=[564480, 1, 13440, 160], requires_grad=0, device=cpu)):
                                        %_packed_params.47 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.197)
                                        %15 : float = prim::Constant[value=0.065296202898025513](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=48](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.49 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.47, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.49)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.199 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu object at 00000230BC0D5340>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu object at 00000230BC0D6640>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu object at 00000230BC0DA340>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd object at 00000230BC0DDEC0>
                          }
                          methods {
                            method forward {
                              graph(%self.201 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock,
                                    %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                %res_conn.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd = prim::GetAttr[name="res_conn"](%self.201)
                                %pwl.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu = prim::GetAttr[name="pwl"](%self.201)
                                %dw.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu = prim::GetAttr[name="dw"](%self.201)
                                %pw.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu = prim::GetAttr[name="pw"](%self.201)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.15, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.25, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.17, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.11, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d object at 00000230BC0D31C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_91.Identity object at 00000230BC0D1940>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_92.Identity object at 00000230BC0D5840>
                              }
                              methods {
                                method forward {
                                  graph(%self.203 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %relu.17 : __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity = prim::GetAttr[name="relu"](%self.203)
                                    %bn.33 : __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity = prim::GetAttr[name="bn"](%self.203)
                                    %conv.49 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d = prim::GetAttr[name="conv"](%self.203)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.49, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.33)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.17)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 216
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0D13C0>
                                    scale = 0.015569943934679031
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.205 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
                                            %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.49 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.205)
                                        %15 : float = prim::Constant[value=0.015569943934679031](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.51 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.49, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.51)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.207 : __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.209 : __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d object at 00000230BC0D5DC0>
                              }
                              methods {
                                method forward {
                                  graph(%self.211 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu,
                                        %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                    %conv.51 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d = prim::GetAttr[name="conv"](%self.211)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.51, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 216
                                    out_channels = 216
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 216
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0D6FC0>
                                    scale = 0.0045942617580294609
                                    zero_point = 63
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.213 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
                                            %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                        %_packed_params.51 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.213)
                                        %15 : float = prim::Constant[value=0.0045942617580294609](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.53 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.51, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.53)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d object at 00000230BC0D8BC0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_97.Identity object at 00000230BC0DB140>
                              }
                              methods {
                                method forward {
                                  graph(%self.215 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu,
                                        %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                    %bn.35 : __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity = prim::GetAttr[name="bn"](%self.215)
                                    %conv.53 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d = prim::GetAttr[name="conv"](%self.215)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.53, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.35)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 216
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0D8EC0>
                                    scale = 0.055696174502372742
                                    zero_point = 59
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.217 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
                                            %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                        %_packed_params.53 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.217)
                                        %15 : float = prim::Constant[value=0.055696174502372742](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.53, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.219 : __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional object at 00000230BC0DC540>
                              }
                              methods {
                                method forward {
                                  graph(%self.221 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %add_func.11 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional = prim::GetAttr[name="add_func"](%self.221)
                                    %activation_post_process.11 : __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity = prim::GetAttr[name="activation_post_process"](%add_func.11)
                                    %5 : float = prim::Constant[value=0.069978676736354828](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.55 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.11)
                                    return (%input.55)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_99.Identity object at 00000230BC0DC3C0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.223 : __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu object at 00000230BC0DF440>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu object at 00000230BC0E06C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu object at 00000230BC0E4040>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd object at 00000230BC0E7C40>
                          }
                          methods {
                            method forward {
                              graph(%self.225 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock,
                                    %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                %res_conn.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd = prim::GetAttr[name="res_conn"](%self.225)
                                %pwl.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu = prim::GetAttr[name="pwl"](%self.225)
                                %dw.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu = prim::GetAttr[name="dw"](%self.225)
                                %pw.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu = prim::GetAttr[name="pw"](%self.225)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.17, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.27, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.19, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.13, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d object at 00000230BC0DF240>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_104.Identity object at 00000230BC0DE040>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_105.Identity object at 00000230BC0E02C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.227 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %relu.19 : __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity = prim::GetAttr[name="relu"](%self.227)
                                    %bn.37 : __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity = prim::GetAttr[name="bn"](%self.227)
                                    %conv.55 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d = prim::GetAttr[name="conv"](%self.227)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.55, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.37)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.19)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 216
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0DE0C0>
                                    scale = 0.010320775210857391
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.229 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
                                            %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.55 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.229)
                                        %15 : float = prim::Constant[value=0.010320775210857391](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.57 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.55, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.57)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.231 : __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.233 : __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d object at 00000230BC0E03C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.235 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu,
                                        %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                    %conv.57 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d = prim::GetAttr[name="conv"](%self.235)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.57, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 216
                                    out_channels = 216
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 216
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0E0F40>
                                    scale = 0.002296387916430831
                                    zero_point = 43
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.237 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
                                            %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                        %_packed_params.57 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.237)
                                        %15 : float = prim::Constant[value=0.002296387916430831](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=43](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.59 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.57, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.59)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d object at 00000230BC0E28C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_110.Identity object at 00000230BC0E4E40>
                              }
                              methods {
                                method forward {
                                  graph(%self.239 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu,
                                        %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                    %bn.39 : __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity = prim::GetAttr[name="bn"](%self.239)
                                    %conv.59 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d = prim::GetAttr[name="conv"](%self.239)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.59, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.39)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 216
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0E40C0>
                                    scale = 0.033724598586559296
                                    zero_point = 59
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.241 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
                                            %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                        %_packed_params.59 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.241)
                                        %15 : float = prim::Constant[value=0.033724598586559296](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.59, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.243 : __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional object at 00000230BC0E8640>
                              }
                              methods {
                                method forward {
                                  graph(%self.245 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %add_func.13 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional = prim::GetAttr[name="add_func"](%self.245)
                                    %activation_post_process.13 : __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity = prim::GetAttr[name="activation_post_process"](%add_func.13)
                                    %5 : float = prim::Constant[value=0.065939456224441528](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.61 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.13)
                                    return (%input.61)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_112.Identity object at 00000230BC0E5D40>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.247 : __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu object at 00000230BBFACAC0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu object at 00000230BBFAF3C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu object at 00000230BBFB2FC0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd object at 00000230BBFB41C0>
                          }
                          methods {
                            method forward {
                              graph(%self.249 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock,
                                    %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                %res_conn.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd = prim::GetAttr[name="res_conn"](%self.249)
                                %pwl.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu = prim::GetAttr[name="pwl"](%self.249)
                                %dw.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu = prim::GetAttr[name="dw"](%self.249)
                                %pw.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu = prim::GetAttr[name="pw"](%self.249)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.19, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.29, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.21, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.15, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d object at 00000230BC0E8840>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_117.Identity object at 00000230BBFAC440>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_118.Identity object at 00000230BBFAC940>
                              }
                              methods {
                                method forward {
                                  graph(%self.251 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %relu.21 : __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity = prim::GetAttr[name="relu"](%self.251)
                                    %bn.41 : __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity = prim::GetAttr[name="bn"](%self.251)
                                    %conv.61 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d = prim::GetAttr[name="conv"](%self.251)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.61, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.41)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.21)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 216
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC0E9CC0>
                                    scale = 0.0097023583948612213
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.253 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
                                            %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.61 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.253)
                                        %15 : float = prim::Constant[value=0.0097023583948612213](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.63 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.61, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.63)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.255 : __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.257 : __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d object at 00000230BBFACC40>
                              }
                              methods {
                                method forward {
                                  graph(%self.259 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu,
                                        %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                    %conv.63 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d = prim::GetAttr[name="conv"](%self.259)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.63, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 216
                                    out_channels = 216
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 216
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFACDC0>
                                    scale = 0.0034326065797358751
                                    zero_point = 61
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.261 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
                                            %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                        %_packed_params.63 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.261)
                                        %15 : float = prim::Constant[value=0.0034326065797358751](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.65 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.63, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d object at 00000230BBFAFA40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_123.Identity object at 00000230BBFB07C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.263 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu,
                                        %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                    %bn.43 : __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity = prim::GetAttr[name="bn"](%self.263)
                                    %conv.65 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d = prim::GetAttr[name="conv"](%self.263)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.65, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.43)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 216
                                    out_channels = 72
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFAFFC0>
                                    scale = 0.042978081852197647
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.265 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
                                            %1 : QUInt8(1, 216, 42, 84, strides=[762048, 1, 18144, 216], requires_grad=0, device=cpu)):
                                        %_packed_params.65 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.265)
                                        %15 : float = prim::Constant[value=0.042978081852197647](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.65, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.267 : __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional object at 00000230BBFB4140>
                              }
                              methods {
                                method forward {
                                  graph(%self.269 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %add_func.15 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional = prim::GetAttr[name="add_func"](%self.269)
                                    %activation_post_process.15 : __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity = prim::GetAttr[name="activation_post_process"](%add_func.15)
                                    %5 : float = prim::Constant[value=0.073325932025909424](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.67 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.15)
                                    return (%input.67)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_125.Identity object at 00000230BBFB3840>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.271 : __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu object at 00000230BBFB6440>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu object at 00000230BBFB6540>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu object at 00000230BBFBB940>
                          }
                          methods {
                            method forward {
                              graph(%self.273 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock,
                                    %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                %pwl.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu = prim::GetAttr[name="pwl"](%self.273)
                                %dw.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu = prim::GetAttr[name="dw"](%self.273)
                                %pw.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu = prim::GetAttr[name="pw"](%self.273)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.21, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.31, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.23, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d object at 00000230BBFB5F40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_130.Identity object at 00000230BBFB4FC0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_131.Identity object at 00000230BBFB82C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.275 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu,
                                        %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                    %relu.23 : __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity = prim::GetAttr[name="relu"](%self.275)
                                    %bn.45 : __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity = prim::GetAttr[name="bn"](%self.275)
                                    %conv.67 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d = prim::GetAttr[name="conv"](%self.275)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.67, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.45)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.23)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 72
                                    out_channels = 288
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFB58C0>
                                    scale = 0.015027329325675964
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.277 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
                                            %1 : QUInt8(1, 72, 42, 84, strides=[254016, 1, 6048, 72], requires_grad=0, device=cpu)):
                                        %_packed_params.67 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.277)
                                        %15 : float = prim::Constant[value=0.015027329325675964](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.69 : QUInt8(1, 288, 42, 84, strides=[1016064, 1, 24192, 288], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.67, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.69)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.279 : __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.281 : __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d object at 00000230BBFB7740>
                              }
                              methods {
                                method forward {
                                  graph(%self.283 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu,
                                        %1 : QUInt8(1, 288, 42, 84, strides=[1016064, 1, 24192, 288], requires_grad=0, device=cpu)):
                                    %conv.69 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d = prim::GetAttr[name="conv"](%self.283)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.69, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 288
                                    out_channels = 288
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 288
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFB6AC0>
                                    scale = 0.010243155062198639
                                    zero_point = 54
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.285 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
                                            %1 : QUInt8(1, 288, 42, 84, strides=[1016064, 1, 24192, 288], requires_grad=0, device=cpu)):
                                        %_packed_params.69 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.285)
                                        %15 : float = prim::Constant[value=0.010243155062198639](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=54](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.71 : QUInt8(1, 288, 42, 84, strides=[1016064, 1, 24192, 288], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.69, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.71)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d object at 00000230BBFB87C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_136.Identity object at 00000230BBFBB3C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.287 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu,
                                        %1 : QUInt8(1, 288, 42, 84, strides=[1016064, 1, 24192, 288], requires_grad=0, device=cpu)):
                                    %bn.47 : __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity = prim::GetAttr[name="bn"](%self.287)
                                    %conv.71 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d = prim::GetAttr[name="conv"](%self.287)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.71, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.47)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 288
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFB9540>
                                    scale = 0.019521206617355347
                                    zero_point = 87
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.289 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
                                            %1 : QUInt8(1, 288, 42, 84, strides=[1016064, 1, 24192, 288], requires_grad=0, device=cpu)):
                                        %_packed_params.71 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.289)
                                        %15 : float = prim::Constant[value=0.019521206617355347](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=87](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.73 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.71, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.73)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.291 : __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu object at 00000230BBFC1B40>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu object at 00000230BBFC16C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu object at 00000230BBFC44C0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd object at 00000230BBFC9540>
                          }
                          methods {
                            method forward {
                              graph(%self.293 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %res_conn.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd = prim::GetAttr[name="res_conn"](%self.293)
                                %pwl.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu = prim::GetAttr[name="pwl"](%self.293)
                                %dw.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu = prim::GetAttr[name="dw"](%self.293)
                                %pw.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu = prim::GetAttr[name="pw"](%self.293)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.23, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.33, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.25, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.17, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d object at 00000230BBFBC9C0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_140.Identity object at 00000230BBFBE7C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_141.Identity object at 00000230BBFC14C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.295 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %relu.25 : __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity = prim::GetAttr[name="relu"](%self.295)
                                    %bn.49 : __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity = prim::GetAttr[name="bn"](%self.295)
                                    %conv.73 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d = prim::GetAttr[name="conv"](%self.295)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.73, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.49)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.25)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 448
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFBD440>
                                    scale = 0.013961838558316231
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.297 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.73 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.297)
                                        %15 : float = prim::Constant[value=0.013961838558316231](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.75 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.73, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.75)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.299 : __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.301 : __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d object at 00000230BBFC0840>
                              }
                              methods {
                                method forward {
                                  graph(%self.303 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu,
                                        %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                    %conv.75 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d = prim::GetAttr[name="conv"](%self.303)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.75, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 448
                                    out_channels = 448
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 448
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFC1C40>
                                    scale = 0.0048557627014815807
                                    zero_point = 49
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.305 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %_packed_params.75 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.305)
                                        %15 : float = prim::Constant[value=0.0048557627014815807](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=49](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.77 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.75, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.77)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d object at 00000230BBFC3140>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_146.Identity object at 00000230BBFC5AC0>
                              }
                              methods {
                                method forward {
                                  graph(%self.307 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu,
                                        %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                    %bn.51 : __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity = prim::GetAttr[name="bn"](%self.307)
                                    %conv.77 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d = prim::GetAttr[name="conv"](%self.307)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.77, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.51)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 448
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFC43C0>
                                    scale = 0.018382290378212929
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.309 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %_packed_params.77 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.309)
                                        %15 : float = prim::Constant[value=0.018382290378212929](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.77, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.311 : __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional object at 00000230BBFC8640>
                              }
                              methods {
                                method forward {
                                  graph(%self.313 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %add_func.17 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional = prim::GetAttr[name="add_func"](%self.313)
                                    %activation_post_process.17 : __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity = prim::GetAttr[name="activation_post_process"](%add_func.17)
                                    %5 : float = prim::Constant[value=0.024247467517852783](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=87](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.79 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.17)
                                    return (%input.79)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_148.Identity object at 00000230BBFC69C0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.315 : __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu object at 00000230BBFCC0C0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu object at 00000230BBFCDE40>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu object at 00000230BBFCFAC0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd object at 00000230BBFD2F40>
                          }
                          methods {
                            method forward {
                              graph(%self.317 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %res_conn.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd = prim::GetAttr[name="res_conn"](%self.317)
                                %pwl.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu = prim::GetAttr[name="pwl"](%self.317)
                                %dw.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu = prim::GetAttr[name="dw"](%self.317)
                                %pw.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu = prim::GetAttr[name="pw"](%self.317)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.25, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.35, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.27, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.19, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d object at 00000230BBFC8BC0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_153.Identity object at 00000230BBFCA8C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_154.Identity object at 00000230BBFCB740>
                              }
                              methods {
                                method forward {
                                  graph(%self.319 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %relu.27 : __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity = prim::GetAttr[name="relu"](%self.319)
                                    %bn.53 : __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity = prim::GetAttr[name="bn"](%self.319)
                                    %conv.79 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d = prim::GetAttr[name="conv"](%self.319)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.79, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.53)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.27)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 448
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFC8D40>
                                    scale = 0.0088738147169351578
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.321 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.79 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.321)
                                        %15 : float = prim::Constant[value=0.0088738147169351578](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.81 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.79, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.81)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.323 : __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.325 : __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d object at 00000230BBFCA6C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.327 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu,
                                        %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                    %conv.81 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d = prim::GetAttr[name="conv"](%self.327)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.81, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 448
                                    out_channels = 448
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 448
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFCC8C0>
                                    scale = 0.0040600020438432693
                                    zero_point = 48
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.329 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %_packed_params.81 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.329)
                                        %15 : float = prim::Constant[value=0.0040600020438432693](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=48](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.83 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.81, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.83)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d object at 00000230BBFCCB40>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_159.Identity object at 00000230BBFCF4C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.331 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu,
                                        %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                    %bn.55 : __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity = prim::GetAttr[name="bn"](%self.331)
                                    %conv.83 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d = prim::GetAttr[name="conv"](%self.331)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.83, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.55)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 448
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFCCD40>
                                    scale = 0.013197137042880058
                                    zero_point = 88
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.333 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %_packed_params.83 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.333)
                                        %15 : float = prim::Constant[value=0.013197137042880058](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=88](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.83, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.335 : __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional object at 00000230BBFD31C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.337 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %add_func.19 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional = prim::GetAttr[name="add_func"](%self.337)
                                    %activation_post_process.19 : __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity = prim::GetAttr[name="activation_post_process"](%add_func.19)
                                    %5 : float = prim::Constant[value=0.034928727895021439](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=86](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %input.85 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.19)
                                    return (%input.85)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_161.Identity object at 00000230BBFD2D40>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.339 : __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu object at 00000230BBFD8240>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu object at 00000230BBFD73C0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu object at 00000230BBFD83C0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd object at 00000230BBFDCCC0>
                          }
                          methods {
                            method forward {
                              graph(%self.341 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %res_conn.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd = prim::GetAttr[name="res_conn"](%self.341)
                                %pwl.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu = prim::GetAttr[name="pwl"](%self.341)
                                %dw.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu = prim::GetAttr[name="dw"](%self.341)
                                %pw.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu = prim::GetAttr[name="pw"](%self.341)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.27, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.37, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.29, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.21, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d object at 00000230BBFD4DC0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_166.Identity object at 00000230BBFD43C0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_167.Identity object at 00000230BBFD4F40>
                              }
                              methods {
                                method forward {
                                  graph(%self.343 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %relu.29 : __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity = prim::GetAttr[name="relu"](%self.343)
                                    %bn.57 : __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity = prim::GetAttr[name="bn"](%self.343)
                                    %conv.85 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d = prim::GetAttr[name="conv"](%self.343)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.85, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.57)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.29)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 112
                                    out_channels = 448
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFD4340>
                                    scale = 0.0092473095282912254
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.345 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %_packed_params.85 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.345)
                                        %15 : float = prim::Constant[value=0.0092473095282912254](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.87 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.85, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.87)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.347 : __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.349 : __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d object at 00000230BBFD70C0>
                              }
                              methods {
                                method forward {
                                  graph(%self.351 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu,
                                        %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                    %conv.87 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d = prim::GetAttr[name="conv"](%self.351)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.87, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 448
                                    out_channels = 448
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 448
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFD74C0>
                                    scale = 0.0036785728298127651
                                    zero_point = 65
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.353 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %_packed_params.87 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.353)
                                        %15 : float = prim::Constant[value=0.0036785728298127651](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.89 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.87, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%input.89)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d object at 00000230BBFD8DC0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_172.Identity object at 00000230BBFD9E40>
                              }
                              methods {
                                method forward {
                                  graph(%self.355 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu,
                                        %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                    %bn.59 : __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity = prim::GetAttr[name="bn"](%self.355)
                                    %conv.89 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d = prim::GetAttr[name="conv"](%self.355)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.89, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.59)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 448
                                    out_channels = 112
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFD9740>
                                    scale = 0.014938217587769032
                                    zero_point = 79
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.357 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %_packed_params.89 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.357)
                                        %15 : float = prim::Constant[value=0.014938217587769032](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %16 : int = prim::Constant[value=79](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %17 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.89, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        return (%17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.359 : __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional object at 00000230BBFDCB40>
                              }
                              methods {
                                method forward {
                                  graph(%self.361 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %add_func.21 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional = prim::GetAttr[name="add_func"](%self.361)
                                    %activation_post_process.21 : __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity = prim::GetAttr[name="activation_post_process"](%add_func.21)
                                    %5 : float = prim::Constant[value=0.056048460304737091](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %6 : int = prim::Constant[value=92](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %Xq.1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.21)
                                    return (%Xq.1)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_174.Identity object at 00000230BBFDC540>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.363 : __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    stubs = <__torch__.torch.nn.modules.container.ModuleList object at 00000230BBFDFE40>
                  }
                  methods {
                    method forward {
                      graph(%self.7 : __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested,
                            %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                        %stubs.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="stubs"](%self.7)
                        %_0.1 : __torch__.torch.nn.quantized.modules.Quantize = prim::GetAttr[name="0"](%stubs.1)
                        %5 : Tensor = prim::CallMethod[name="forward"](%_0.1, %X.1)
                        return (%5)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.quantized.modules.Quantize object at 00000230BBFDFA40>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.Quantize {
                          parameters {
                          }
                          attributes {
                            scale = ...
                            zero_point = ...
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.9 : __torch__.torch.nn.quantized.modules.Quantize,
                                    %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                                %2 : float = prim::Constant[value=0.92053180932998657](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                %3 : int = prim::Constant[value=127](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                %input.1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%X.1, %2, %3, %4), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                return (%input.1)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    stubs = <__torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList object at 00000230BBFDFC40>
                  }
                  methods {
                    method forward {
                      graph(%self.365 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested,
                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu),
                            %2 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu),
                            %3 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu),
                            %4 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                        %stubs.9 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_3 : __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize = prim::GetAttr[name="3"](%stubs.9)
                        %stubs.7 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_2 : __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize = prim::GetAttr[name="2"](%stubs.7)
                        %stubs.5 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_1.1 : __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize = prim::GetAttr[name="1"](%stubs.5)
                        %stubs.3 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_0.3 : __torch__.torch.nn.quantized.modules.DeQuantize = prim::GetAttr[name="0"](%stubs.3)
                        %17 : NoneType = prim::CallMethod[name="forward"](%_0.3, %1)
                        %18 : NoneType = prim::CallMethod[name="forward"](%_1.1, %2)
                        %19 : NoneType = prim::CallMethod[name="forward"](%_2, %3)
                        %20 : Tensor = prim::CallMethod[name="forward"](%_3, %4)
                        return (%20)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.quantized.modules.DeQuantize object at 00000230BBFDF240>
                        1 = <__torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize object at 00000230BBFE00C0>
                        2 = <__torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize object at 00000230BBFDE7C0>
                        3 = <__torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize object at 00000230BBFDFEC0>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.367 : __torch__.torch.nn.quantized.modules.DeQuantize,
                                    %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.369 : __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize,
                                    %1 : QUInt8(1, 32, 167, 334, strides=[1784896, 1, 10688, 32], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.371 : __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize,
                                    %1 : QUInt8(1, 40, 84, 167, strides=[561120, 1, 6680, 40], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.373 : __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %feature_map : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.dequant_stubs/__module.model.model.backbone.dequant_stubs.stubs.3 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                return (%feature_map)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.proposal_generator.rpn.RPN {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                rpn_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass object at 00000230BC1BB5D0>
                anchor_generator = <__torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator object at 00000230BC1BB8D0>
              }
              methods {
                method forward {
                  graph(%self.375 : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                        %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                        %image_size : Long(2, strides=[1], requires_grad=0, device=cpu)):
                    %rpn_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass = prim::GetAttr[name="rpn_head"](%self.375)
                    %anchor_generator : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator = prim::GetAttr[name="anchor_generator"](%self.375)
                    %550 : Tensor = prim::CallMethod[name="forward"](%anchor_generator, %1)
                    %551 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%rpn_head, %1)
                    %7 : Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), %8 : Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%551)
                    %9 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %10 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %11 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %12 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %13 : int[] = prim::ListConstruct(%9, %10, %11, %12), scope: __module.model/__module.model.model.proposal_generator
                    %14 : Float(1, 42, 84, 15, strides=[52920, 1260, 15, 1], requires_grad=0, device=cpu) = aten::permute(%7, %13), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %16 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %logits_i : Float(1, 52920, strides=[52920, 1], requires_grad=0, device=cpu) = aten::flatten(%14, %15, %16), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %18 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %19 : int = aten::size(%8, %18), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %20 : Long(device=cpu) = prim::NumToTensor(%19), scope: __module.model/__module.model.model.proposal_generator
                    %21 : int = aten::Int(%20), scope: __module.model/__module.model.model.proposal_generator
                    %37 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %38 : int = aten::size(%8, %37), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %39 : Long(device=cpu) = prim::NumToTensor(%38), scope: __module.model/__module.model.model.proposal_generator
                    %40 : int = aten::Int(%39), scope: __module.model/__module.model.model.proposal_generator
                    %53 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %54 : int = aten::size(%8, %53), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %55 : Long(device=cpu) = prim::NumToTensor(%54), scope: __module.model/__module.model.model.proposal_generator
                    %56 : int = aten::Int(%55), scope: __module.model/__module.model.model.proposal_generator
                    %57 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %58 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %59 : int[] = prim::ListConstruct(%21, %57, %58, %40, %56), scope: __module.model/__module.model.model.proposal_generator
                    %60 : Float(1, 15, 4, 42, 84, strides=[60, 4, 1, 5040, 60], requires_grad=0, device=cpu) = aten::view(%8, %59), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %61 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %62 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %63 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %64 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %65 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %66 : int[] = prim::ListConstruct(%61, %62, %63, %64, %65), scope: __module.model/__module.model.model.proposal_generator
                    %67 : Float(1, 42, 84, 15, 4, strides=[60, 5040, 60, 4, 1], requires_grad=0, device=cpu) = aten::permute(%60, %66), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %68 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %69 : int = prim::Constant[value=-2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %pred_anchor_deltas_i : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::flatten(%67, %68, %69), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %71 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:522:0
                    %72 : int = aten::size(%pred_anchor_deltas_i, %71), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:522:0
                    %N : Long(device=cpu) = prim::NumToTensor(%72), scope: __module.model/__module.model.model.proposal_generator
                    %74 : int = aten::Int(%N), scope: __module.model/__module.model.model.proposal_generator
                    %75 : int = aten::Int(%N), scope: __module.model/__module.model.model.proposal_generator
                    %82 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:526:0
                    %83 : int = aten::size(%550, %82), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:526:0
                    %B : Long(device=cpu) = prim::NumToTensor(%83), scope: __module.model/__module.model.model.proposal_generator
                    %85 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %86 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %87 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %88 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:527:0
                    %89 : int[] = prim::ListConstruct(%88, %87), scope: __module.model/__module.model.model.proposal_generator
                    %deltas.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_anchor_deltas_i, %89), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:527:0
                    %91 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %92 : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%550, %91), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %93 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %94 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %95 : int[] = prim::ListConstruct(%75, %93, %94), scope: __module.model/__module.model.model.proposal_generator
                    %96 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %97 : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::expand(%92, %95, %96), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %98 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %99 : int[] = prim::ListConstruct(%98, %86), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%97, %99), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %101 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %102 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %103 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %104 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %deltas.3 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%deltas.1, %101, %102, %103, %104), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %106 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %107 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %108 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %109 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.3 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%boxes.1, %106, %107, %108, %109), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %111 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %112 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %113 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %114 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %115 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %111, %112, %113, %114), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %116 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %117 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %118 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%115, %116, %117), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %119 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %120 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %121 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %122 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %123 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %119, %120, %121, %122), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %124 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %125 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %126 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%123, %124, %125), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %widths.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::sub(%118, %126, %127), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %129 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %130 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %131 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %133 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %129, %130, %131, %132), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %134 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %135 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %136 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%133, %134, %135), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %137 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %138 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %139 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %140 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %141 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %137, %138, %139, %140), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %142 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %143 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %144 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%141, %142, %143), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %145 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %heights.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::sub(%136, %144, %145), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %147 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %148 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %149 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %151 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %147, %148, %149, %150), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %152 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %153 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %154 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%151, %152, %153), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %155 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %156 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::mul(%widths.1, %155), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %157 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %ctr_x.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::add(%154, %156, %157), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %159 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %160 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %161 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %162 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %163 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %159, %160, %161, %162), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %164 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %166 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%163, %164, %165), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %167 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %168 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::mul(%heights.1, %167), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %169 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %ctr_y.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::add(%166, %168, %169), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %171 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %172 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %173 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %174 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %175 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %171, %172, %173, %174), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %176 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %177 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %178 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %179 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %180 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%175, %176, %177, %178, %179), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %181 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %dx.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%180, %181), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %183 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %184 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %185 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %186 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %187 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %183, %184, %185, %186), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %188 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %189 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %190 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %191 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %192 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%187, %188, %189, %190, %191), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %193 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %dy.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%192, %193), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %195 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %196 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %197 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %198 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %199 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %195, %196, %197, %198), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %200 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %201 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %202 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %203 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %204 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%199, %200, %201, %202, %203), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %205 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %dw.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%204, %205), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %207 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %208 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %209 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %210 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %211 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %207, %208, %209, %210), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %212 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %213 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %214 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %215 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %216 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%211, %212, %213, %214, %215), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %217 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %dh.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%216, %217), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %219 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %220 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %dw.3 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dw.1, %219, %220), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %222 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %223 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %dh.3 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dh.1, %222, %223), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %225 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %226 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %227 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %228 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %229 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths.1, %225, %226, %227, %228), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %230 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %231 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%229, %230), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %232 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dx.1, %231), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %233 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %234 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %235 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %236 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %237 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_x.1, %233, %234, %235, %236), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %238 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %239 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%237, %238), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %240 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %pred_ctr_x.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%232, %239, %240), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %242 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %243 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %244 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %245 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %246 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights.1, %242, %243, %244, %245), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %248 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%246, %247), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %249 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dy.1, %248), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %250 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %251 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %252 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %253 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %254 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_y.1, %250, %251, %252, %253), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %255 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %256 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%254, %255), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %pred_ctr_y.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%249, %256, %257), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %259 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dw.3), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %260 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %261 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %262 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %263 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %264 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths.1, %260, %261, %262, %263), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %265 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %266 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%264, %265), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %pred_w.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%259, %266), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %268 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dh.3), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %269 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %270 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %271 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %273 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights.1, %269, %270, %271, %272), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %274 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %275 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%273, %274), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %pred_h.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%268, %275), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %277 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %278 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w.1, %277), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %279 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %x1.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_x.1, %278, %279), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %281 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %282 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h.1, %281), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %y1.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_y.1, %282, %283), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %285 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %286 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w.1, %285), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %287 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %x2.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_x.1, %286, %287), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %289 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %290 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h.1, %289), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %291 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %y2.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_y.1, %290, %291), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %293 : Tensor[] = prim::ListConstruct(%x1.1, %y1.1, %x2.1, %y2.1), scope: __module.model/__module.model.model.proposal_generator
                    %294 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %pred_boxes.1 : Float(52920, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::stack(%293, %294), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %296 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %297 : int = aten::size(%deltas.3, %296), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %298 : Long(device=cpu) = prim::NumToTensor(%297), scope: __module.model/__module.model.model.proposal_generator
                    %299 : int = aten::Int(%298), scope: __module.model/__module.model.model.proposal_generator
                    %300 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %301 : int = aten::size(%deltas.3, %300), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %302 : Long(device=cpu) = prim::NumToTensor(%301), scope: __module.model/__module.model.model.proposal_generator
                    %303 : int = aten::Int(%302), scope: __module.model/__module.model.model.proposal_generator
                    %304 : int[] = prim::ListConstruct(%299, %303), scope: __module.model/__module.model.model.proposal_generator
                    %proposals_i.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_boxes.1, %304), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %306 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:532:0
                    %307 : int[] = prim::ListConstruct(%74, %306, %85), scope: __module.model/__module.model.model.proposal_generator
                    %proposals_i : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::view(%proposals_i.1, %307), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:532:0
                    %309 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %310 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %311 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %312 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %313 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %314 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::arange(%309, %310, %311, %312, %313), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %315 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator
                    %batch_idx : Tensor = prim::CallFunction(%315, %314, %proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %320 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:73:0
                    %321 : int = aten::size(%logits_i, %320), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:73:0
                    %Hi_Wi_A : Long(device=cpu) = prim::NumToTensor(%321), scope: __module.model/__module.model.model.proposal_generator
                    %323 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %324 : int = prim::Constant[value=1000](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:75:0
                    %num_proposals_i : Long(requires_grad=0, device=cpu) = aten::clamp(%Hi_Wi_A, %323, %324), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:75:0
                    %326 : int = aten::Int(%num_proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %327 : int = aten::Int(%num_proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %328 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %329 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %330 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %topk_scores : Float(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu), %topk_idx : Long(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu) = aten::topk(%logits_i, %327, %328, %329, %330), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %333 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %334 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %335 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %336 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %337 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::slice(%batch_idx, %333, %334, %335, %336), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %338 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %339 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%337, %338), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %340 : Tensor?[] = prim::ListConstruct(%339, %topk_idx), scope: __module.model/__module.model.model.proposal_generator
                    %topk_proposals : Float(1, 1000, 4, strides=[4000, 4, 1], requires_grad=0, device=cpu) = aten::index(%proposals_i, %340), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %342 : int[] = prim::ListConstruct(%326), scope: __module.model/__module.model.model.proposal_generator
                    %343 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %344 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %345 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %346 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %347 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %348 : Long(1000, strides=[1], requires_grad=0, device=cpu) = aten::full(%342, %343, %344, %345, %346, %347), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %349 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator
                    %level_ids : Tensor = prim::CallFunction(%349, %348, %proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %351 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %352 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %tensor.5 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::select(%topk_proposals, %351, %352), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %354 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %355 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %356 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %357 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.7 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.5, %354, %355, %356, %357), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %368 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %369 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %scores_per_img.1 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::select(%topk_scores, %368, %369), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %380 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:723:0
                    %381 : Tensor[] = aten::unbind(%image_size, %380), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:723:0
                    %h.1 : Long(requires_grad=0, device=cpu), %w.1 : Long(requires_grad=0, device=cpu) = prim::ListUnpack(%381), scope: __module.model/__module.model.model.proposal_generator
                    %384 : Scalar = aten::ScalarImplicit(%h.1), scope: __module.model/__module.model.model.proposal_generator
                    %385 : Scalar = aten::ScalarImplicit(%w.1), scope: __module.model/__module.model.model.proposal_generator
                    %386 : Scalar = aten::ScalarImplicit(%h.1), scope: __module.model/__module.model.model.proposal_generator
                    %387 : Scalar = aten::ScalarImplicit(%w.1), scope: __module.model/__module.model.model.proposal_generator
                    %388 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %389 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %390 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %391 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %392 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %388, %389, %390, %391), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %393 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %394 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %395 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%392, %393, %394), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %396 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %x1.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%395, %396, %387), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %398 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %399 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %400 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %401 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %402 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %398, %399, %400, %401), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %403 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %404 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %405 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%402, %403, %404), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %406 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %y1.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%405, %406, %386), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %408 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %409 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %410 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %411 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %412 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %408, %409, %410, %411), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %413 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %414 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %415 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%412, %413, %414), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %416 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %x2.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%415, %416, %385), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %418 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %419 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %420 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %421 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %422 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %418, %419, %420, %421), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %423 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %424 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %425 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%422, %423, %424), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %426 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %y2.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%425, %426, %384), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %428 : Tensor[] = prim::ListConstruct(%x1.3, %y1.3, %x2.3, %y2.3), scope: __module.model/__module.model.model.proposal_generator
                    %429 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %box : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%428, %429), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %431 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %432 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %433 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %434 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %435 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %431, %432, %433, %434), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %436 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %437 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %438 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%435, %436, %437), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %439 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %440 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %441 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %442 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %443 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %439, %440, %441, %442), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %444 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %445 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %446 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%443, %444, %445), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %447 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %widths.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::sub(%438, %446, %447), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %449 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %450 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %451 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %452 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %453 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %449, %450, %451, %452), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %454 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %455 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %456 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%453, %454, %455), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %457 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %458 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %459 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %460 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %461 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %457, %458, %459, %460), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %462 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %463 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %464 : Float(1000, strides=[4], requires_grad=0, device=cpu) = aten::select(%461, %462, %463), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %465 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %heights.3 : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::sub(%456, %464, %465), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %467 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %468 : Bool(1000, strides=[1], requires_grad=0, device=cpu) = aten::gt(%widths.3, %467), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %469 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %470 : Bool(1000, strides=[1], requires_grad=0, device=cpu) = aten::gt(%heights.3, %469), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %item.1 : Bool(1000, strides=[1], requires_grad=0, device=cpu) = aten::__and__(%468, %470), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %472 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.9 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%box, %472), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:235:0
                    %474 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %475 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %476 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %477 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.11 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.9, %474, %475, %476, %477), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %488 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %scores_per_img : Float(1000, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores_per_img.1, %488), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:119:0
                    %490 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %491 : Long(1000, strides=[1], requires_grad=0, device=cpu) = aten::index(%level_ids, %490), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:119:0
                    %500 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %501 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %502 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %503 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.5 : Float(1000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.11, %500, %501, %502, %503), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %509 : float = prim::Constant[value=0.69999999999999996](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\jit\_trace.py:1130:0
                    %510 : Function = prim::Constant[name="_batched_nms_coordinate_trick"](), scope: __module.model/__module.model.model.proposal_generator
                    %keep.1 : Tensor = prim::CallFunction(%510, %boxes.5, %scores_per_img, %491, %509), scope: __module.model/__module.model.model.proposal_generator
                    %512 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %513 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %514 : int = prim::Constant[value=30](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %515 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %item : Long(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%keep.1, %512, %513, %514, %515), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %517 : Tensor?[] = prim::ListConstruct(%item), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.13 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes.5, %517), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:235:0
                    %519 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %520 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %521 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %522 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.15 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.13, %519, %520, %521, %522), scope: __module.model/__module.model.model.proposal_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    return (%tensor.15)
              
                }
              }
              submodules {
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    rpn_feature = <__torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule object at 00000230BC1B6350>
                    rpn_regressor = <__torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor object at 00000230BC1B6AD0>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested object at 00000230BC1BACD0>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested object at 00000230BC1BB4D0>
                  }
                  methods {
                    method forward {
                      graph(%self.379 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass,
                            %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                        %dequant_stubs.3 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.379)
                        %rpn_regressor : __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor = prim::GetAttr[name="rpn_regressor"](%self.379)
                        %rpn_feature : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule = prim::GetAttr[name="rpn_feature"](%self.379)
                        %quant_stubs.3 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.379)
                        %15 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.3, %1)
                        %16 : Tensor = prim::CallMethod[name="forward"](%rpn_feature, %15)
                        %17 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%rpn_regressor, %16)
                        %9 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), %10 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%17)
                        %18 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%dequant_stubs.3, %9, %10)
                        %12 : Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), %13 : Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%18)
                        %14 : (Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%12, %13)
                        return (%14)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_223.Sequential object at 00000230BC1B5850>
                      }
                      methods {
                        method forward {
                          graph(%self.385 : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule,
                                %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                            %_0.9 : __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential = prim::GetAttr[name="0"](%self.385)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.9, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock object at 00000230BBFE9E40>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock object at 00000230BC1A95D0>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock object at 00000230BC1B2FD0>
                          }
                          methods {
                            method forward {
                              graph(%self.387 : __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %fbnetv2_0_2.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.387)
                                %fbnetv2_0_1.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.387)
                                %fbnetv2_0_0.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.387)
                                %8 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.3, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.3, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2.1, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu object at 00000230BBFE0340>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu object at 00000230BBFE1BC0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu object at 00000230BBFE4B40>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd object at 00000230BBFE8EC0>
                              }
                              methods {
                                method forward {
                                  graph(%self.389 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %res_conn.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd = prim::GetAttr[name="res_conn"](%self.389)
                                    %pwl.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu = prim::GetAttr[name="pwl"](%self.389)
                                    %dw.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu = prim::GetAttr[name="dw"](%self.389)
                                    %pw.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu = prim::GetAttr[name="pw"](%self.389)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.29, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.39, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.31, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.23, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d object at 00000230BBFDFFC0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_185.Identity object at 00000230BBFDEBC0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_186.Identity object at 00000230BBFE2140>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.391 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %relu.31 : __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity = prim::GetAttr[name="relu"](%self.391)
                                        %bn.61 : __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity = prim::GetAttr[name="bn"](%self.391)
                                        %conv.91 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d = prim::GetAttr[name="conv"](%self.391)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.91, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.61)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.31)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 448
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFE0140>
                                        scale = 0.01914406381547451
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.393 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.91 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.393)
                                            %15 : float = prim::Constant[value=0.01914406381547451](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.93 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.91, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.93)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.395 : __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.397 : __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d object at 00000230BBFE15C0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.399 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %conv.93 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d = prim::GetAttr[name="conv"](%self.399)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.93, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 448
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 448
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFE06C0>
                                        scale = 0.0027076601982116699
                                        zero_point = 54
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.401 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
                                                %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.93 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.401)
                                            %15 : float = prim::Constant[value=0.0027076601982116699](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=54](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.95 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.93, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.95)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d object at 00000230BBFE3140>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_191.Identity object at 00000230BBFE4A40>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.403 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %bn.63 : __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity = prim::GetAttr[name="bn"](%self.403)
                                        %conv.95 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d = prim::GetAttr[name="conv"](%self.403)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.95, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.63)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFE5E40>
                                        scale = 0.021053750067949295
                                        zero_point = 80
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.405 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
                                                %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.95 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.405)
                                            %15 : float = prim::Constant[value=0.021053750067949295](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=80](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %17 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.95, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.407 : __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional object at 00000230BBFE93C0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.409 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %add_func.23 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional = prim::GetAttr[name="add_func"](%self.409)
                                        %activation_post_process.23 : __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity = prim::GetAttr[name="activation_post_process"](%add_func.23)
                                        %5 : float = prim::Constant[value=0.066744588315486908](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %6 : int = prim::Constant[value=97](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.97 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.23)
                                        return (%input.97)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_193.Identity object at 00000230BBFE6D40>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.411 : __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu object at 00000230BC1A45D0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu object at 00000230BC1A4B50>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu object at 00000230BC1A6ED0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd object at 00000230BC1A9E50>
                              }
                              methods {
                                method forward {
                                  graph(%self.413 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %res_conn.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd = prim::GetAttr[name="res_conn"](%self.413)
                                    %pwl.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu = prim::GetAttr[name="pwl"](%self.413)
                                    %dw.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu = prim::GetAttr[name="dw"](%self.413)
                                    %pw.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu = prim::GetAttr[name="pw"](%self.413)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.31, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.41, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.33, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.25, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d object at 00000230BBFE8340>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_198.Identity object at 00000230BC1A3750>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_199.Identity object at 00000230BC1A3F50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.415 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %relu.33 : __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity = prim::GetAttr[name="relu"](%self.415)
                                        %bn.65 : __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity = prim::GetAttr[name="bn"](%self.415)
                                        %conv.97 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d = prim::GetAttr[name="conv"](%self.415)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.97, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.65)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.33)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 448
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFE87C0>
                                        scale = 0.021621430292725563
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.417 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.97 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.417)
                                            %15 : float = prim::Constant[value=0.021621430292725563](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.99 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.97, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.99)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.419 : __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.421 : __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d object at 00000230BC1A49D0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.423 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %conv.99 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d = prim::GetAttr[name="conv"](%self.423)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.99, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 448
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 448
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1A4A50>
                                        scale = 0.0035627409815788269
                                        zero_point = 74
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.425 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
                                                %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.99 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.425)
                                            %15 : float = prim::Constant[value=0.0035627409815788269](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=74](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.101 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.99, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.101)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d object at 00000230BC1A4450>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_204.Identity object at 00000230BC1A6250>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.427 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %bn.67 : __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity = prim::GetAttr[name="bn"](%self.427)
                                        %conv.101 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d = prim::GetAttr[name="conv"](%self.427)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.101, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.67)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1A68D0>
                                        scale = 0.026709176599979401
                                        zero_point = 63
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.429 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
                                                %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.101 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.429)
                                            %15 : float = prim::Constant[value=0.026709176599979401](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %17 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.101, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.431 : __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional object at 00000230BC1AAB50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.433 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %add_func.25 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional = prim::GetAttr[name="add_func"](%self.433)
                                        %activation_post_process.25 : __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity = prim::GetAttr[name="activation_post_process"](%add_func.25)
                                        %5 : float = prim::Constant[value=0.087418779730796814](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %6 : int = prim::Constant[value=94](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.103 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.25)
                                        return (%input.103)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_206.Identity object at 00000230BC1A7950>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.435 : __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu object at 00000230BC1ACA50>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu object at 00000230BC1ADF50>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu object at 00000230BC1B0BD0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd object at 00000230BC1B3A50>
                              }
                              methods {
                                method forward {
                                  graph(%self.437 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock,
                                        %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %res_conn.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd = prim::GetAttr[name="res_conn"](%self.437)
                                    %pwl.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu = prim::GetAttr[name="pwl"](%self.437)
                                    %dw.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu = prim::GetAttr[name="dw"](%self.437)
                                    %pw.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu = prim::GetAttr[name="pw"](%self.437)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.33, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.43, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.35, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.27, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d object at 00000230BC1A9750>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_211.Identity object at 00000230BC1ACD50>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_212.Identity object at 00000230BC1AC7D0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.439 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %relu.35 : __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity = prim::GetAttr[name="relu"](%self.439)
                                        %bn.69 : __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity = prim::GetAttr[name="bn"](%self.439)
                                        %conv.103 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d = prim::GetAttr[name="conv"](%self.439)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.103, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.69)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.35)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 448
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1A9AD0>
                                        scale = 0.020912541076540947
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.441 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
                                                %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                            %_packed_params.103 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.441)
                                            %15 : float = prim::Constant[value=0.020912541076540947](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.105 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.103, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.105)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.443 : __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.445 : __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d object at 00000230BC1ACED0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.447 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %conv.105 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d = prim::GetAttr[name="conv"](%self.447)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.105, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 448
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 448
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1AD450>
                                        scale = 0.0052649891003966331
                                        zero_point = 61
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.449 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
                                                %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.105 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.449)
                                            %15 : float = prim::Constant[value=0.0052649891003966331](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.107 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.105, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.107)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d object at 00000230BC1AE2D0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_217.Identity object at 00000230BC1AFD50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.451 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu,
                                            %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                        %bn.71 : __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity = prim::GetAttr[name="bn"](%self.451)
                                        %conv.107 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d = prim::GetAttr[name="conv"](%self.451)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.107, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.71)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 112
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1AE550>
                                        scale = 0.069133251905441284
                                        zero_point = 81
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.453 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
                                                %1 : QUInt8(1, 448, 42, 84, strides=[1580544, 1, 37632, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.107 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.453)
                                            %15 : float = prim::Constant[value=0.069133251905441284](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=81](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %17 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.107, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.455 : __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional object at 00000230BC1B4A50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.457 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd,
                                            %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                        %add_func.27 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional = prim::GetAttr[name="add_func"](%self.457)
                                        %activation_post_process.27 : __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity = prim::GetAttr[name="activation_post_process"](%add_func.27)
                                        %5 : float = prim::Constant[value=0.13211663067340851](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %6 : int = prim::Constant[value=90](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.109 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.27)
                                        return (%input.109)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_219.Identity object at 00000230BC1B4650>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.459 : __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        cls_logits = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d object at 00000230BC1B58D0>
                        bbox_pred = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d object at 00000230BC1B6CD0>
                      }
                      methods {
                        method forward {
                          graph(%self.461 : __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor,
                                %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                            %bbox_pred.1 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d = prim::GetAttr[name="bbox_pred"](%self.461)
                            %cls_logits : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d = prim::GetAttr[name="cls_logits"](%self.461)
                            %7 : Tensor = prim::CallMethod[name="forward"](%cls_logits, %1)
                            %8 : Tensor = prim::CallMethod[name="forward"](%bbox_pred.1, %1)
                            %6 : (QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%7, %8)
                            return (%6)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 112
                            out_channels = 15
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1B6950>
                            scale = 0.11338348686695099
                            zero_point = 127
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                 = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.463 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %_packed_params.109 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.463)
                                %15 : float = prim::Constant[value=0.11338348686695099](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %16 : int = prim::Constant[value=127](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %Xq.3 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.109, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                return (%Xq.3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 112
                            out_channels = 60
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1B6B50>
                            scale = 0.026389690116047859
                            zero_point = 99
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                 = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.465 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
                                    %1 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %_packed_params.111 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.465)
                                %15 : float = prim::Constant[value=0.026389690116047859](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %16 : int = prim::Constant[value=99](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %Xq.5 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.111, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                return (%Xq.5)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList object at 00000230BC1BABD0>
                      }
                      methods {
                        method forward {
                          graph(%self.381 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested,
                                %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                            %stubs.11 : __torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList = prim::GetAttr[name="stubs"](%self.381)
                            %_0.7 : __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize = prim::GetAttr[name="0"](%stubs.11)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.7, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize object at 00000230BC1B6FD0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.383 : __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize,
                                        %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.056048460304737091](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=92](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %input.91 : QUInt8(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%input.91)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList object at 00000230BC1BB250>
                      }
                      methods {
                        method forward {
                          graph(%self.467 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested,
                                %1 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu),
                                %2 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)):
                            %stubs.15 : __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList = prim::GetAttr[name="stubs"](%self.467)
                            %_1.3 : __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize = prim::GetAttr[name="1"](%stubs.15)
                            %stubs.13 : __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList = prim::GetAttr[name="stubs"](%self.467)
                            %_0.11 : __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize = prim::GetAttr[name="0"](%stubs.13)
                            %10 : Tensor = prim::CallMethod[name="forward"](%_0.11, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%_1.3, %2)
                            %9 : (Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%10, %11)
                            return (%9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize object at 00000230BC1BA6D0>
                            1 = <__torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize object at 00000230BC1B93D0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.469 : __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize,
                                        %1 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu)):
                                    %score : Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.dequant_stubs/__module.model.model.proposal_generator.rpn_head.dequant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%score)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.471 : __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize,
                                        %1 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)):
                                    %x.3 : Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.dequant_stubs/__module.model.model.proposal_generator.rpn_head.dequant_stubs.stubs.1 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%x.3)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    cell_anchors = <__torch__.detectron2.modeling.anchor_generator.BufferList object at 00000230BC1BB650>
                  }
                  methods {
                    method forward {
                      graph(%self.377 : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
                            %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                        %cell_anchors : __torch__.detectron2.modeling.anchor_generator.BufferList = prim::GetAttr[name="cell_anchors"](%self.377)
                        %_0.5 : Tensor = prim::GetAttr[name="0"](%cell_anchors)
                        %10 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %11 : int = aten::size(%1, %10), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %grid_height : Long(device=cpu) = prim::NumToTensor(%11), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %13 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %14 : int = aten::size(%1, %13), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %grid_width : Long(device=cpu) = prim::NumToTensor(%14), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %16 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %17 : Long(requires_grad=0, device=cpu) = aten::mul(%grid_width, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %18 : Scalar = aten::ScalarImplicit(%17), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %19 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %20 : int = prim::Constant[value=16](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %21 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %22 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %23 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %24 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %25 : Float(84, strides=[1], requires_grad=0, device=cpu) = aten::arange(%19, %18, %20, %21, %22, %23, %24), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %26 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %27 : Tensor = prim::CallFunction(%26, %25, %_0.5), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %28 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %29 : Long(requires_grad=0, device=cpu) = aten::mul(%grid_height, %28), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %30 : Scalar = aten::ScalarImplicit(%29), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %31 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %32 : int = prim::Constant[value=16](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %33 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %34 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %35 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %36 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %37 : Float(42, strides=[1], requires_grad=0, device=cpu) = aten::arange(%31, %30, %32, %33, %34, %35, %36), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %38 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %39 : Tensor = prim::CallFunction(%38, %37, %_0.5), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %40 : Tensor[] = prim::ListConstruct(%39, %27), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %41 : Tensor[] = aten::meshgrid(%40), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\functional.py:478:0
                        %shift_y.1 : Float(42, 84, strides=[1, 0], requires_grad=0, device=cpu), %shift_x.1 : Float(42, 84, strides=[0, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%41), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %44 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:53:0
                        %45 : int[] = prim::ListConstruct(%44), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %shift_x : Float(3528, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%shift_x.1, %45), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:53:0
                        %47 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:54:0
                        %48 : int[] = prim::ListConstruct(%47), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %shift_y : Float(3528, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%shift_y.1, %48), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:54:0
                        %50 : Tensor[] = prim::ListConstruct(%shift_x, %shift_y, %shift_x, %shift_y), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %51 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:175:0
                        %shifts : Float(3528, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%50, %51), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:175:0
                        %53 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %54 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %55 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %56 : int[] = prim::ListConstruct(%53, %54, %55), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %57 : Float(3528, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::view(%shifts, %56), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %58 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %59 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %60 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %61 : int[] = prim::ListConstruct(%58, %59, %60), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %62 : Float(1, 15, 4, strides=[60, 4, 1], requires_grad=0, device=cpu) = aten::view(%_0.5, %61), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %63 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %64 : Float(3528, 15, 4, strides=[60, 4, 1], requires_grad=0, device=cpu) = aten::add(%57, %62, %63), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %65 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %66 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %67 : int[] = prim::ListConstruct(%65, %66), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %tensor.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%64, %67), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %69 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %70 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %71 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %72 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %tensor.3 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.1, %69, %70, %71, %72), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        return (%tensor.3)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.modeling.anchor_generator.BufferList {
                      parameters {
                      }
                      attributes {
                        0 = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                box_pooler = <__torch__.detectron2.modeling.poolers.ROIPooler object at 00000230BC1BBD50>
                box_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass object at 00000230BC4C2A70>
                box_predictor = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass object at 00000230BC4C6B70>
              }
              methods {
                method forward {
                  graph(%self.473 : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                        %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                        %2 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu),
                        %image_size : Long(2, strides=[1], requires_grad=0, device=cpu)):
                    %box_predictor : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass = prim::GetAttr[name="box_predictor"](%self.473)
                    %box_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass = prim::GetAttr[name="box_head"](%self.473)
                    %box_pooler : __torch__.detectron2.modeling.poolers.ROIPooler = prim::GetAttr[name="box_pooler"](%self.473)
                    %458 : Tensor = prim::CallMethod[name="forward"](%box_pooler, %1, %2)
                    %459 : Tensor = prim::CallMethod[name="forward"](%box_head, %458)
                    %460 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%box_predictor, %459)
                    %10 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu), %11 : Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%460)
                    %12 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %13 : int = aten::size(%2, %12), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %14 : Long(device=cpu) = prim::NumToTensor(%13), scope: __module.model/__module.model.model.roi_heads
                    %15 : int = aten::Int(%14), scope: __module.model/__module.model.model.roi_heads
                    %19 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %20 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %21 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %22 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %deltas : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::to(%10, %19, %20, %21, %22), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %24 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %25 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %26 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %27 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %boxes.9 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%2, %24, %25, %26, %27), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %29 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %30 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %31 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %32 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %33 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %29, %30, %31, %32), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %34 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %35 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %36 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%33, %34, %35), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %37 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %38 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %39 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %40 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %41 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %37, %38, %39, %40), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %42 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %43 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %44 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%41, %42, %43), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %45 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %widths : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::sub(%36, %44, %45), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %47 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %48 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %49 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %50 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %51 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %47, %48, %49, %50), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %52 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %53 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %54 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%51, %52, %53), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %55 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %56 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %57 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %58 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %59 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %55, %56, %57, %58), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %60 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %61 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %62 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%59, %60, %61), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %63 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %heights : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::sub(%54, %62, %63), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %65 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %66 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %67 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %68 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %69 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %65, %66, %67, %68), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %70 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %71 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %72 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%69, %70, %71), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %73 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %74 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::mul(%widths, %73), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %75 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %ctr_x : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::add(%72, %74, %75), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %77 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %78 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %79 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %80 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %81 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.9, %77, %78, %79, %80), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %82 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %83 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %84 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%81, %82, %83), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %85 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %86 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::mul(%heights, %85), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %87 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %ctr_y : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::add(%84, %86, %87), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %89 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %90 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %91 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %92 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %93 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %89, %90, %91, %92), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %94 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %95 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %96 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %97 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %98 : Float(30, 80, strides=[320, 4], requires_grad=0, device=cpu) = aten::slice(%93, %94, %95, %96, %97), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %99 : Double(requires_grad=0, device=cpu) = prim::Constant[value={10}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %dx : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::div(%98, %99), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %101 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %102 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %103 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %104 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %105 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %101, %102, %103, %104), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %106 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %107 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %108 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %109 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %110 : Float(30, 80, strides=[320, 4], requires_grad=0, device=cpu) = aten::slice(%105, %106, %107, %108, %109), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %111 : Double(requires_grad=0, device=cpu) = prim::Constant[value={10}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %dy : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::div(%110, %111), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %113 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %114 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %115 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %116 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %117 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %113, %114, %115, %116), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %118 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %119 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %120 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %121 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %122 : Float(30, 80, strides=[320, 4], requires_grad=0, device=cpu) = aten::slice(%117, %118, %119, %120, %121), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %123 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %dw.5 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::div(%122, %123), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %125 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %126 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %127 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %128 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %129 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %125, %126, %127, %128), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %130 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %131 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %132 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %133 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %134 : Float(30, 80, strides=[320, 4], requires_grad=0, device=cpu) = aten::slice(%129, %130, %131, %132, %133), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %135 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %dh.5 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::div(%134, %135), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %137 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %138 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %dw.7 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::clamp(%dw.5, %137, %138), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %140 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %141 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %dh : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::clamp(%dh.5, %140, %141), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %143 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %144 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %145 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %146 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %147 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths, %143, %144, %145, %146), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %148 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %149 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%147, %148), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %150 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%dx, %149), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %151 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %152 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %153 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %154 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %155 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_x, %151, %152, %153, %154), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %156 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %157 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%155, %156), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %158 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %pred_ctr_x : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::add(%150, %157, %158), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %160 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %161 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %162 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %163 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %164 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights, %160, %161, %162, %163), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %166 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%164, %165), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %167 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%dy, %166), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %168 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %169 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %170 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %171 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %172 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_y, %168, %169, %170, %171), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %173 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %174 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%172, %173), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %175 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %pred_ctr_y : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::add(%167, %174, %175), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %177 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::exp(%dw.7), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %178 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %179 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %180 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %181 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %182 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths, %178, %179, %180, %181), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %183 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %184 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%182, %183), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %pred_w : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%177, %184), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %186 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::exp(%dh), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %187 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %188 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %189 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %190 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %191 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights, %187, %188, %189, %190), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %192 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %193 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%191, %192), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %pred_h : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%186, %193), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %195 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %196 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w, %195), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %197 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %x1.5 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_x, %196, %197), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %199 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %200 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h, %199), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %201 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %y1.5 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_y, %200, %201), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %203 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %204 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w, %203), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %205 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %x2.5 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_x, %204, %205), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %207 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %208 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h, %207), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %209 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %y2.5 : Float(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_y, %208, %209), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %211 : Tensor[] = prim::ListConstruct(%x1.5, %y1.5, %x2.5, %y2.5), scope: __module.model/__module.model.model.roi_heads
                    %212 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %pred_boxes : Float(30, 80, 4, strides=[320, 4, 1], requires_grad=0, device=cpu) = aten::stack(%211, %212), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %214 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %215 : int = aten::size(%deltas, %214), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %216 : Long(device=cpu) = prim::NumToTensor(%215), scope: __module.model/__module.model.model.roi_heads
                    %217 : int = aten::Int(%216), scope: __module.model/__module.model.model.roi_heads
                    %218 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %219 : int = aten::size(%deltas, %218), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %220 : Long(device=cpu) = prim::NumToTensor(%219), scope: __module.model/__module.model.model.roi_heads
                    %221 : int = aten::Int(%220), scope: __module.model/__module.model.model.roi_heads
                    %222 : int[] = prim::ListConstruct(%217, %221), scope: __module.model/__module.model.model.roi_heads
                    %223 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_boxes, %222), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %224 : int[] = prim::ListConstruct(%15), scope: __module.model/__module.model.model.roi_heads
                    %225 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:615:0
                    %226 : Tensor[] = aten::split_with_sizes(%223, %224, %225), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:615:0
                    %boxes.11 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%226), scope: __module.model/__module.model.model.roi_heads
                    %228 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %229 : int = aten::size(%boxes.9, %228), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %230 : Long(device=cpu) = prim::NumToTensor(%229), scope: __module.model/__module.model.model.roi_heads
                    %231 : int = aten::Int(%230), scope: __module.model/__module.model.model.roi_heads
                    %235 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\functional.py:1792:0
                    %236 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %237 : Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = aten::softmax(%11, %235, %236), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\functional.py:1792:0
                    %238 : int[] = prim::ListConstruct(%231), scope: __module.model/__module.model.model.roi_heads
                    %239 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:615:0
                    %240 : Tensor[] = aten::split_with_sizes(%237, %238, %239), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:615:0
                    %scores.1 : Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%240), scope: __module.model/__module.model.model.roi_heads
                    %252 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %253 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %254 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %255 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %256 : Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = aten::slice(%scores.1, %252, %253, %254, %255), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %258 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %259 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %260 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %scores.3 : Float(30, 80, strides=[81, 1], requires_grad=0, device=cpu) = aten::slice(%256, %257, %258, %259, %260), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %265 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:143:0
                    %266 : int = aten::size(%boxes.11, %265), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:143:0
                    %267 : Long(device=cpu) = prim::NumToTensor(%266), scope: __module.model/__module.model.model.roi_heads
                    %268 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:673:0
                    %num_bbox_reg_classes : Long(requires_grad=0, device=cpu) = aten::floor_divide(%267, %268), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:673:0
                    %270 : int = aten::Int(%num_bbox_reg_classes), scope: __module.model/__module.model.model.roi_heads
                    %271 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %272 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %273 : int[] = prim::ListConstruct(%271, %272), scope: __module.model/__module.model.model.roi_heads
                    %tensor.17 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%boxes.11, %273), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %275 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %276 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %277 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %278 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor.19 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.17, %275, %276, %277, %278), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %291 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:723:0
                    %292 : Tensor[] = aten::unbind(%image_size, %291), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_tensor.py:723:0
                    %h : Long(requires_grad=0, device=cpu), %w : Long(requires_grad=0, device=cpu) = prim::ListUnpack(%292), scope: __module.model/__module.model.model.roi_heads
                    %295 : Scalar = aten::ScalarImplicit(%h), scope: __module.model/__module.model.model.roi_heads
                    %296 : Scalar = aten::ScalarImplicit(%w), scope: __module.model/__module.model.model.roi_heads
                    %297 : Scalar = aten::ScalarImplicit(%h), scope: __module.model/__module.model.model.roi_heads
                    %298 : Scalar = aten::ScalarImplicit(%w), scope: __module.model/__module.model.model.roi_heads
                    %299 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %300 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %301 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %302 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %303 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %299, %300, %301, %302), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %304 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %305 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %306 : Float(2400, strides=[4], requires_grad=0, device=cpu) = aten::select(%303, %304, %305), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %307 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %x1 : Float(2400, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%306, %307, %298), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %309 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %310 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %311 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %312 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %313 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %309, %310, %311, %312), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %314 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %315 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %316 : Float(2400, strides=[4], requires_grad=0, device=cpu) = aten::select(%313, %314, %315), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %317 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %y1 : Float(2400, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%316, %317, %297), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %319 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %320 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %321 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %322 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %323 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %319, %320, %321, %322), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %324 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %325 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %326 : Float(2400, strides=[4], requires_grad=0, device=cpu) = aten::select(%323, %324, %325), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %327 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %x2 : Float(2400, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%326, %327, %296), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %329 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %330 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %331 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %332 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %333 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %329, %330, %331, %332), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %334 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %335 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %336 : Float(2400, strides=[4], requires_grad=0, device=cpu) = aten::select(%333, %334, %335), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %337 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %y2 : Float(2400, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%336, %337, %295), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %339 : Tensor[] = prim::ListConstruct(%x1, %y1, %x2, %y2), scope: __module.model/__module.model.model.roi_heads
                    %340 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %341 : Float(2400, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%339, %340), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %342 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %343 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %344 : int[] = prim::ListConstruct(%342, %270, %343), scope: __module.model/__module.model.model.roi_heads
                    %boxes.13 : Float(30, 80, 4, strides=[320, 4, 1], requires_grad=0, device=cpu) = aten::view(%341, %344), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %346 : float = prim::Constant[value=0.050000000000000003](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:151:0
                    %filter_mask : Bool(30, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::gt(%scores.3, %346), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:151:0
                    %filter_inds.1 : Long(0, 2, strides=[1, 0], requires_grad=0, device=cpu) = aten::nonzero(%filter_mask), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:154:0
                    %351 : Tensor?[] = prim::ListConstruct(%filter_mask), scope: __module.model/__module.model.model.roi_heads
                    %boxes.15 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes.13, %351), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:158:0
                    %353 : Tensor?[] = prim::ListConstruct(%filter_mask), scope: __module.model/__module.model.model.roi_heads
                    %scores : Float(0, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores.3, %353), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:159:0
                    %355 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %356 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %357 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %358 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %359 : Long(0, 2, strides=[1, 0], requires_grad=0, device=cpu) = aten::slice(%filter_inds.1, %355, %356, %357, %358), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %360 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %361 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %362 : Long(0, strides=[1], requires_grad=0, device=cpu) = aten::select(%359, %360, %361), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %371 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %372 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %373 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %374 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %boxes : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%boxes.15, %371, %372, %373, %374), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %380 : float = prim::Constant[value=0.5](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\jit\_trace.py:1130:0
                    %381 : Function = prim::Constant[name="_batched_nms_coordinate_trick"](), scope: __module.model/__module.model.model.roi_heads
                    %keep.3 : Tensor = prim::CallFunction(%381, %boxes, %scores, %362, %380), scope: __module.model/__module.model.model.roi_heads
                    %383 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %384 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %385 : int = prim::Constant[value=100](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %386 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %keep : Long(0, strides=[1], requires_grad=0, device=cpu) = aten::slice(%keep.3, %383, %384, %385, %386), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %388 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %tensor.21 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes, %388), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %390 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %391 : Float(0, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores, %390), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %392 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %filter_inds : Long(0, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::index(%filter_inds.1, %392), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %394 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %395 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %396 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %397 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor.23 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.21, %394, %395, %396, %397), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %403 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %404 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %405 : int[] = prim::ListConstruct(%403, %404), scope: __module.model/__module.model.model.roi_heads
                    %406 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%tensor.23, %405), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %407 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %408 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %409 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %410 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%406, %407, %408, %409, %410), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %432 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %433 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %434 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %435 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %436 : Long(0, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::slice(%filter_inds, %432, %433, %434, %435), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %437 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %438 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %439 : Long(0, strides=[2], requires_grad=0, device=cpu) = aten::select(%436, %437, %438), scope: __module.model/__module.model.model.roi_heads # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %457 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(0, strides=[2], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%tensor, %439, %391)
                    return (%457)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.poolers.ROIPooler {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList object at 00000230BC1BBBD0>
                  }
                  methods {
                    method forward {
                      graph(%self.475 : __torch__.detectron2.modeling.poolers.ROIPooler,
                            %1 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu),
                            %2 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %level_poolers : __torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList = prim::GetAttr[name="level_poolers"](%self.475)
                        %_0.13 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers)
                        %10 : Tensor[] = prim::ListConstruct(%2), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %11 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\poolers.py:94:0
                        %12 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\poolers.py:94:0
                        %13 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %14 : int = aten::size(%2, %13), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %15 : Long(device=cpu) = prim::NumToTensor(%14), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %19 : Tensor[] = prim::ListConstruct(%15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %20 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
                        %21 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::stack(%19, %20), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
                        %22 : Function = prim::Constant[name="_convert_boxes_to_pooler_format"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %rois : Tensor = prim::CallFunction(%22, %12, %21), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %25 : Tensor = prim::CallMethod[name="forward"](%_0.13, %rois, %1)
                        return (%25)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 00000230BC1BBAD0>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.detectron2.layers.roi_align.ROIAlign {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.477 : __torch__.detectron2.layers.roi_align.ROIAlign,
                                    %rois : Tensor,
                                    %2 : Float(1, 112, 42, 84, strides=[395136, 1, 9408, 112], requires_grad=0, device=cpu)):
                                %8 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %9 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %10 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %11 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0
                                %boxes.7 : Float(30, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::to(%rois, %8, %9, %10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %18 : float = prim::Constant[value=0.0625](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %19 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %20 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %21 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %22 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                %X.3 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu) = torchvision::roi_align(%2, %boxes.7, %18, %19, %20, %21, %22), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                return (%X.3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    roi_box_conv = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule object at 00000230BC4C2470>
                    avgpool = <__torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d object at 00000230BC4C3670>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested object at 00000230BC4C24F0>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested object at 00000230BC4C3DF0>
                  }
                  methods {
                    method forward {
                      graph(%self.479 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass,
                            %1 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                        %dequant_stubs.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.479)
                        %avgpool : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d = prim::GetAttr[name="avgpool"](%self.479)
                        %roi_box_conv : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule = prim::GetAttr[name="roi_box_conv"](%self.479)
                        %quant_stubs.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.479)
                        %36 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.5, %1)
                        %37 : Tensor = prim::CallMethod[name="forward"](%roi_box_conv, %36)
                        %38 : Tensor = prim::CallMethod[name="forward"](%avgpool, %37)
                        %39 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs.5, %38)
                        return (%39)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_281.Sequential object at 00000230BC4C2C70>
                      }
                      methods {
                        method forward {
                          graph(%self.485 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule,
                                %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                            %_0.17 : __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential = prim::GetAttr[name="0"](%self.485)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.17, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock object at 00000230BC1C39D0>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock object at 00000230BC1D0CD0>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock object at 00000230BC1D9950>
                            fbnetv2_0_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock object at 00000230BC4C2BF0>
                          }
                          methods {
                            method forward {
                              graph(%self.487 : __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential,
                                    %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                %fbnetv2_0_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock = prim::GetAttr[name="fbnetv2_0_3"](%self.487)
                                %fbnetv2_0_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.487)
                                %fbnetv2_0_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.487)
                                %fbnetv2_0_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.487)
                                %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_3, %12)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu object at 00000230BC1BCFD0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu object at 00000230BC1BDFD0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu object at 00000230BC1C21D0>
                              }
                              methods {
                                method forward {
                                  graph(%self.489 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock,
                                        %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %pwl.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu = prim::GetAttr[name="pwl"](%self.489)
                                    %dw.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu = prim::GetAttr[name="dw"](%self.489)
                                    %pw.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu = prim::GetAttr[name="pw"](%self.489)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%pw.35, %1)
                                    %9 : Tensor = prim::CallMethod[name="forward"](%dw.45, %8)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pwl.37, %9)
                                    return (%10)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d object at 00000230BC1BBDD0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_236.Identity object at 00000230BC1BBED0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_237.Identity object at 00000230BC1BDAD0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.491 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu,
                                            %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                        %relu.37 : __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity = prim::GetAttr[name="relu"](%self.491)
                                        %bn.73 : __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity = prim::GetAttr[name="bn"](%self.491)
                                        %conv.109 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d = prim::GetAttr[name="conv"](%self.491)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.109, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.73)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.37)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 112
                                        out_channels = 448
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1BBE50>
                                        scale = 0.021674800664186478
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.493 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
                                                %1 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.113 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.493)
                                            %15 : float = prim::Constant[value=0.021674800664186478](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.113 : QUInt8(30, 448, 6, 6, strides=[16128, 1, 2688, 448], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.113, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.113)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.495 : __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.497 : __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d object at 00000230BC1BDF50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.499 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu,
                                            %1 : QUInt8(30, 448, 6, 6, strides=[16128, 1, 2688, 448], requires_grad=0, device=cpu)):
                                        %conv.111 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d = prim::GetAttr[name="conv"](%self.499)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.111, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 448
                                        kernel_size = (3, 3)
                                        stride = (2, 2)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 448
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1BD9D0>
                                        scale = 0.010925987735390663
                                        zero_point = 67
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.501 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
                                                %1 : QUInt8(30, 448, 6, 6, strides=[16128, 1, 2688, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.115 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.501)
                                            %15 : float = prim::Constant[value=0.010925987735390663](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.115 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.115, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.115)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d object at 00000230BC1BFDD0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_242.Identity object at 00000230BC1C1F50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.503 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu,
                                            %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu)):
                                        %bn.75 : __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity = prim::GetAttr[name="bn"](%self.503)
                                        %conv.113 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d = prim::GetAttr[name="conv"](%self.503)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.113, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.75)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 448
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1C2450>
                                        scale = 0.061936497688293457
                                        zero_point = 74
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.505 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
                                                %1 : QUInt8(30, 448, 3, 3, strides=[4032, 1, 1344, 448], requires_grad=0, device=cpu)):
                                            %_packed_params.117 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.505)
                                            %15 : float = prim::Constant[value=0.061936497688293457](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=74](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.117 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.117, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.117)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.507 : __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu object at 00000230BC1C7550>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu object at 00000230BC1C9FD0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu object at 00000230BC1CCD50>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd object at 00000230BC1D0750>
                              }
                              methods {
                                method forward {
                                  graph(%self.509 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock,
                                        %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                    %res_conn.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd = prim::GetAttr[name="res_conn"](%self.509)
                                    %pwl.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu = prim::GetAttr[name="pwl"](%self.509)
                                    %dw.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu = prim::GetAttr[name="dw"](%self.509)
                                    %pw.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu = prim::GetAttr[name="pw"](%self.509)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.37, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.47, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.39, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.29, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d object at 00000230BC1C54D0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_246.Identity object at 00000230BC1C56D0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_247.Identity object at 00000230BC1C8250>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.511 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu,
                                            %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                        %relu.39 : __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity = prim::GetAttr[name="relu"](%self.511)
                                        %bn.77 : __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity = prim::GetAttr[name="bn"](%self.511)
                                        %conv.115 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d = prim::GetAttr[name="conv"](%self.511)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.115, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.77)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.39)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 768
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1C65D0>
                                        scale = 0.022799083963036537
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.513 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
                                                %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.119 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.513)
                                            %15 : float = prim::Constant[value=0.022799083963036537](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.119 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.119, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.119)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.515 : __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.517 : __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d object at 00000230BC1C7E50>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.519 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu,
                                            %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                        %conv.117 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d = prim::GetAttr[name="conv"](%self.519)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.117, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 768
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 768
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1C8650>
                                        scale = 0.0027748993597924709
                                        zero_point = 66
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.521 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
                                                %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.121 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.521)
                                            %15 : float = prim::Constant[value=0.0027748993597924709](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.121 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.121, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.121)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d object at 00000230BC1C92D0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_252.Identity object at 00000230BC1CC8D0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.523 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu,
                                            %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                        %bn.79 : __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity = prim::GetAttr[name="bn"](%self.523)
                                        %conv.119 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d = prim::GetAttr[name="conv"](%self.523)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.119, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.79)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1CC750>
                                        scale = 0.048601623624563217
                                        zero_point = 61
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.525 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
                                                %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.123 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.525)
                                            %15 : float = prim::Constant[value=0.048601623624563217](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %17 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.123, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.527 : __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional object at 00000230BC1CF0D0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.529 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd,
                                            %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                        %add_func.29 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional = prim::GetAttr[name="add_func"](%self.529)
                                        %activation_post_process.29 : __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity = prim::GetAttr[name="activation_post_process"](%add_func.29)
                                        %5 : float = prim::Constant[value=0.0594521164894104](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %6 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.123 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.29)
                                        return (%input.123)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_254.Identity object at 00000230BC1D01D0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.531 : __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu object at 00000230BC1D37D0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu object at 00000230BC1D4450>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu object at 00000230BC1D5750>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd object at 00000230BC1D9350>
                              }
                              methods {
                                method forward {
                                  graph(%self.533 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock,
                                        %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                    %res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd = prim::GetAttr[name="res_conn"](%self.533)
                                    %pwl.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu = prim::GetAttr[name="pwl"](%self.533)
                                    %dw.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu = prim::GetAttr[name="dw"](%self.533)
                                    %pw.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu = prim::GetAttr[name="pw"](%self.533)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.39, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.49, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.41, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d object at 00000230BC1D1750>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_259.Identity object at 00000230BC1D2B50>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_260.Identity object at 00000230BC1D2BD0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.535 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu,
                                            %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                        %relu.41 : __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity = prim::GetAttr[name="relu"](%self.535)
                                        %bn.81 : __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity = prim::GetAttr[name="bn"](%self.535)
                                        %conv.121 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d = prim::GetAttr[name="conv"](%self.535)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.121, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.81)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.41)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 768
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1D0FD0>
                                        scale = 0.0076013030484318733
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.537 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
                                                %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.125 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.537)
                                            %15 : float = prim::Constant[value=0.0076013030484318733](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.125 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.125, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.125)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.539 : __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.541 : __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d object at 00000230BC1D4050>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.543 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu,
                                            %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                        %conv.123 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d = prim::GetAttr[name="conv"](%self.543)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.123, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 768
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 768
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1D4750>
                                        scale = 0.0013381578028202057
                                        zero_point = 66
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.545 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
                                                %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.127 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.545)
                                            %15 : float = prim::Constant[value=0.0013381578028202057](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.127 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.127, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.127)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d object at 00000230BC1D3950>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_265.Identity object at 00000230BC1D6ED0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.547 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu,
                                            %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                        %bn.83 : __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity = prim::GetAttr[name="bn"](%self.547)
                                        %conv.125 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d = prim::GetAttr[name="conv"](%self.547)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.125, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.83)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 128
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1D59D0>
                                        scale = 0.033281244337558746
                                        zero_point = 69
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.549 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
                                                %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.129 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.549)
                                            %15 : float = prim::Constant[value=0.033281244337558746](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=69](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %17 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.129, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%17)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.551 : __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional object at 00000230BC1D91D0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.553 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd,
                                            %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                        %add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional = prim::GetAttr[name="add_func"](%self.553)
                                        %activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity = prim::GetAttr[name="activation_post_process"](%add_func)
                                        %5 : float = prim::Constant[value=0.063229329884052277](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %6 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %input.129 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process)
                                        return (%input.129)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_267.Identity object at 00000230BC1DAB50>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.555 : __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu object at 00000230BC1DEBD0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu object at 00000230BBFAB5C0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu object at 00000230BC4C22F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.557 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock,
                                        %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                    %pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu = prim::GetAttr[name="pwl"](%self.557)
                                    %dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu = prim::GetAttr[name="dw"](%self.557)
                                    %pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu = prim::GetAttr[name="pw"](%self.557)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%pw, %1)
                                    %9 : Tensor = prim::CallMethod[name="forward"](%dw, %8)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pwl, %9)
                                    return (%10)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d object at 00000230BC1DCB50>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_272.Identity object at 00000230BC1DB8D0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_273.Identity object at 00000230BC1DC450>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.559 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu,
                                            %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                        %relu : __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity = prim::GetAttr[name="relu"](%self.559)
                                        %bn.85 : __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity = prim::GetAttr[name="bn"](%self.559)
                                        %conv.127 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d = prim::GetAttr[name="conv"](%self.559)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.127, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.85)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 128
                                        out_channels = 768
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1DC2D0>
                                        scale = 0.0098056122660636902
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.561 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
                                                %1 : QUInt8(30, 128, 3, 3, strides=[1152, 1, 384, 128], requires_grad=0, device=cpu)):
                                            %_packed_params.131 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.561)
                                            %15 : float = prim::Constant[value=0.0098056122660636902](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.131 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.131, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.131)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.563 : __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.565 : __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d object at 00000230BC1DE150>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.567 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu,
                                            %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                        %conv.129 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d = prim::GetAttr[name="conv"](%self.567)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.129, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 768
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 768
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BC1DD2D0>
                                        scale = 0.002167640021070838
                                        zero_point = 68
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.569 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
                                                %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.133 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.569)
                                            %15 : float = prim::Constant[value=0.002167640021070838](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %input.133 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.133, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%input.133)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d object at 00000230BBFABFC0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_278.Identity object at 00000230BC4C32F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.571 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu,
                                            %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                        %bn : __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity = prim::GetAttr[name="bn"](%self.571)
                                        %conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d = prim::GetAttr[name="conv"](%self.571)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 768
                                        out_channels = 160
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 00000230BBFAA540>
                                        scale = 0.104253850877285
                                        zero_point = 62
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.573 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
                                                %1 : QUInt8(30, 768, 3, 3, strides=[6912, 1, 2304, 768], requires_grad=0, device=cpu)):
                                            %_packed_params.135 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.573)
                                            %15 : float = prim::Constant[value=0.104253850877285](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            %x.5 : QUInt8(30, 160, 3, 3, strides=[1440, 1, 480, 160], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.135, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                                            return (%x.5)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.575 : __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self.577 : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d,
                                %1 : QUInt8(30, 160, 3, 3, strides=[1440, 1, 480, 160], requires_grad=0, device=cpu)):
                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\functional.py:1214:0
                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\functional.py:1214:0
                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool
                            %Xq.7 : QUInt8(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\functional.py:1214:0
                            return (%Xq.7)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList object at 00000230BC4C2170>
                      }
                      methods {
                        method forward {
                          graph(%self.481 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested,
                                %1 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                            %stubs.17 : __torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList = prim::GetAttr[name="stubs"](%self.481)
                            %_0.15 : __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize = prim::GetAttr[name="0"](%stubs.17)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.15, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize object at 00000230BC4C36F0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.483 : __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize,
                                        %1 : Float(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.036483913660049438](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=82](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %input.111 : QUInt8(30, 112, 6, 6, strides=[4032, 36, 6, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%input.111)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList object at 00000230BC4C2370>
                      }
                      methods {
                        method forward {
                          graph(%self.579 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested,
                                %1 : QUInt8(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu)):
                            %stubs.19 : __torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList = prim::GetAttr[name="stubs"](%self.579)
                            %_0.19 : __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize = prim::GetAttr[name="0"](%stubs.19)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.19, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize object at 00000230BC4C3D70>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.581 : __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize,
                                        %1 : QUInt8(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu)):
                                    %X : Float(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.dequant_stubs/__module.model.model.roi_heads.box_head.dequant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%X)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    cls_score = <__torch__.torch.nn.quantized.modules.linear.Linear object at 00000230BC4C26F0>
                    bbox_pred = <__torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear object at 00000230BC4C41F0>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested object at 00000230BC4C6AF0>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested object at 00000230BC4C6EF0>
                  }
                  methods {
                    method forward {
                      graph(%self.583 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass,
                            %1 : Float(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu)):
                        %dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.583)
                        %bbox_pred : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear = prim::GetAttr[name="bbox_pred"](%self.583)
                        %cls_score : __torch__.torch.nn.quantized.modules.linear.Linear = prim::GetAttr[name="cls_score"](%self.583)
                        %quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.583)
                        %16 : Tensor = prim::CallMethod[name="forward"](%quant_stubs, %1)
                        %7 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %8 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %9 : QUInt8(30, 160, strides=[160, 1], requires_grad=0, device=cpu) = aten::flatten(%16, %7, %8), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %17 : Tensor = prim::CallMethod[name="forward"](%cls_score, %9)
                        %18 : Tensor = prim::CallMethod[name="forward"](%bbox_pred, %9)
                        %19 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%dequant_stubs, %17, %18)
                        %13 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu), %14 : Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%19)
                        %15 : (Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu), Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%13, %14)
                        return (%15)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.quantized.modules.linear.Linear {
                      parameters {
                      }
                      attributes {
                        training = True
                        _is_full_backward_hook = None
                        _packed_params = <__torch__.torch.nn.quantized.modules.linear.LinearPackedParams object at 00000230BC4C3A70>
                      }
                      methods {
                        method forward {
                          graph(%self.589 : __torch__.torch.nn.quantized.modules.linear.Linear,
                                %1 : QUInt8(30, 160, strides=[160, 1], requires_grad=0, device=cpu)):
                            %_packed_params.137 : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams = prim::GetAttr[name="_packed_params"](%self.589)
                            %_packed_params.139 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%_packed_params.137)
                            %4 : float = prim::Constant[value=0.14934095740318298](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                            %5 : int = prim::Constant[value=28](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                            %Xq.9 : QUInt8(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = quantized::linear(%1, %_packed_params.139, %4, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                            return (%Xq.9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.linear.LinearPackedParams {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            dtype = 12
                            _packed_params = <__torch__.torch.classes.quantized.LinearPackedParamsBase object at 00000230BC4C3AF0>
                          }
                          methods {
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams):
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:41:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:41:31
                                %10 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:27
                                %2 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:25
                                %28 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::Uninitialized()
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %3 : bool = aten::eq(%dtype.1, %2) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:11
                                %30 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%3) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:8
                                  block0():
                                    %_packed_params.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %6 : Tensor, %7 : Tensor? = quantized::linear_unpack(%_packed_params.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:37:19
                                    %8 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%6, %7)
                                    -> (%8)
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %11 : bool = aten::eq(%dtype, %10) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:13
                                    %29 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%11) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:8
                                      block0():
                                        %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %14 : Tensor, %15 : Tensor? = quantized::linear_unpack_fp16(%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:39:19
                                        %16 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%14, %15)
                                        -> (%16)
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:41:12
                                        -> (%28)
                                    -> (%29)
                                return (%30)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams,
                                    %weight.1 : Tensor,
                                    %bias.1 : Tensor?):
                                %20 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:24
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:31:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:31:31
                                %11 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:27
                                %4 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:25
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %5 : bool = aten::eq(%dtype.1, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:11
                                 = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:8
                                  block0():
                                    %9 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack(%weight.1, %bias.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:27:34
                                     = prim::SetAttr[name="_packed_params"](%self, %9)
                                    -> ()
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %12 : bool = aten::eq(%dtype, %11) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:13
                                     = prim::If(%12) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:8
                                      block0():
                                        %16 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack_fp16(%weight.1, %bias.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:29:34
                                         = prim::SetAttr[name="_packed_params"](%self, %16)
                                        -> ()
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:31:12
                                        -> ()
                                    -> ()
                                return (%20)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear {
                      parameters {
                      }
                      attributes {
                        training = True
                        _is_full_backward_hook = None
                        _packed_params = <__torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams object at 00000230BC4C4D70>
                      }
                      methods {
                        method forward {
                          graph(%self.591 : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear,
                                %1 : QUInt8(30, 160, strides=[160, 1], requires_grad=0, device=cpu)):
                            %_packed_params.141 : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams = prim::GetAttr[name="_packed_params"](%self.591)
                            %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%_packed_params.141)
                            %4 : float = prim::Constant[value=0.017371678724884987](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                            %5 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                            %Xq : QUInt8(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = quantized::linear(%1, %_packed_params, %4, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\_ops.py:143:0
                            return (%Xq)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            dtype = 12
                            _packed_params = <__torch__.torch.classes.quantized.LinearPackedParamsBase object at 00000230BC4C4B70>
                          }
                          methods {
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams):
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:41:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:41:31
                                %10 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:27
                                %2 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:25
                                %28 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::Uninitialized()
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %3 : bool = aten::eq(%dtype.1, %2) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:11
                                %30 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%3) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:8
                                  block0():
                                    %_packed_params.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %6 : Tensor, %7 : Tensor? = quantized::linear_unpack(%_packed_params.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:37:19
                                    %8 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%6, %7)
                                    -> (%8)
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %11 : bool = aten::eq(%dtype, %10) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:13
                                    %29 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%11) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:8
                                      block0():
                                        %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %14 : Tensor, %15 : Tensor? = quantized::linear_unpack_fp16(%_packed_params) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:39:19
                                        %16 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%14, %15)
                                        -> (%16)
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:41:12
                                        -> (%28)
                                    -> (%29)
                                return (%30)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams,
                                    %weight.1 : Tensor,
                                    %bias.1 : Tensor?):
                                %20 : NoneType = prim::Constant() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:24
                                %18 : str = prim::Constant[value="builtins.RuntimeError"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:31:18
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:31:31
                                %11 : int = prim::Constant[value=5]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:27
                                %4 : int = prim::Constant[value=12]() # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:25
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %5 : bool = aten::eq(%dtype.1, %4) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:11
                                 = prim::If(%5) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:8
                                  block0():
                                    %9 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack(%weight.1, %bias.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:27:34
                                     = prim::SetAttr[name="_packed_params"](%self, %9)
                                    -> ()
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %12 : bool = aten::eq(%dtype, %11) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:13
                                     = prim::If(%12) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:8
                                      block0():
                                        %16 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack_fp16(%weight.1, %bias.1) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:29:34
                                         = prim::SetAttr[name="_packed_params"](%self, %16)
                                        -> ()
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:31:12
                                        -> ()
                                    -> ()
                                return (%20)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList object at 00000230BC4C4AF0>
                      }
                      methods {
                        method forward {
                          graph(%self.585 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested,
                                %1 : Float(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu)):
                            %stubs.21 : __torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList = prim::GetAttr[name="stubs"](%self.585)
                            %_0.21 : __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize = prim::GetAttr[name="0"](%stubs.21)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.21, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize object at 00000230BC4C47F0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.587 : __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize,
                                        %1 : Float(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.066273242235183716](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %x : QUInt8(30, 160, 1, 1, strides=[160, 1, 160, 160], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%x)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList object at 00000230BC4C78F0>
                      }
                      methods {
                        method forward {
                          graph(%self.593 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested,
                                %1 : QUInt8(30, 81, strides=[81, 1], requires_grad=0, device=cpu),
                                %2 : QUInt8(30, 320, strides=[320, 1], requires_grad=0, device=cpu)):
                            %stubs : __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList = prim::GetAttr[name="stubs"](%self.593)
                            %_1 : __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize = prim::GetAttr[name="1"](%stubs)
                            %stubs.23 : __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList = prim::GetAttr[name="stubs"](%self.593)
                            %_0 : __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize = prim::GetAttr[name="0"](%stubs.23)
                            %10 : Tensor = prim::CallMethod[name="forward"](%_0, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%_1, %2)
                            %9 : (Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu), Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11, %10)
                            return (%9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize object at 00000230BC4C7A70>
                            1 = <__torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize object at 00000230BC4C66F0>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.595 : __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize,
                                        %1 : QUInt8(30, 81, strides=[81, 1], requires_grad=0, device=cpu)):
                                    %input : Float(30, 81, strides=[81, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.dequant_stubs/__module.model.model.roi_heads.box_predictor.dequant_stubs.stubs.0 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%input)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize,
                                        %1 : QUInt8(30, 320, strides=[320, 1], requires_grad=0, device=cpu)):
                                    %deltas.5 : Float(30, 320, strides=[320, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.dequant_stubs/__module.model.model.roi_heads.box_predictor.dequant_stubs.stubs.1 # C:\Users\Administrator\.conda\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%deltas.5)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
