module __torch__.detectron2.export.flatten.TracingAdapter {
  parameters {
  }
  attributes {
    training = True
    _is_full_backward_hook = None
    model = <__torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper object at 0000020DCBAC7D90>
  }
  methods {
    method forward {
      graph(%self.1 : __torch__.detectron2.export.flatten.TracingAdapter,
            %2359 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu)):
        %model : __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper = prim::GetAttr[name="model"](%self.1)
        %6498 : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%model, %2359)
        %6492 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), %6493 : Long(0, strides=[2], requires_grad=0, device=cpu), %6494 : Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), %6495 : Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu), %6496 : Float(0, strides=[1], requires_grad=0, device=cpu), %6497 : Long(2, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%6498)
        %5078 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(0, strides=[2], requires_grad=0, device=cpu), Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu), Long(2, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%6492, %6493, %6494, %6495, %6496, %6497)
        return (%5078)
  
    }
  }
  submodules {
    module __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper {
      parameters {
      }
      attributes {
        training = True
        _is_full_backward_hook = None
        model = <__torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN object at 0000020DCBAC8E10>
      }
      methods {
        method forward {
          graph(%self.3 : __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper,
                %13 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu)):
            %model.9 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %roi_heads : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads = prim::GetAttr[name="roi_heads"](%model.9)
            %model.7 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %proposal_generator : __torch__.detectron2.modeling.proposal_generator.rpn.RPN = prim::GetAttr[name="proposal_generator"](%model.7)
            %model.5 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %backbone : __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass = prim::GetAttr[name="backbone"](%model.5)
            %model.3 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %pixel_std : Tensor = prim::GetAttr[name="pixel_std"](%model.3)
            %model.1 : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self.3)
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%model.1)
            %11 : Function = prim::Constant[name="move_device_like"](), scope: __module.model
            %x.1 : Tensor = prim::CallFunction(%11, %13, %pixel_mean), scope: __module.model
            %14 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:229:0
            %15 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu) = aten::sub(%x.1, %pixel_mean, %14), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:229:0
            %t : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu) = aten::div(%15, %pixel_std), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\meta_arch\rcnn.py:229:0
            %39 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %40 : int = aten::size(%t, %39), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %41 : Long(device=cpu) = prim::NumToTensor(%40), scope: __module.model
            %51 : int = prim::Constant[value=2](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %52 : int = aten::size(%t, %51), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:88:0
            %53 : Long(device=cpu) = prim::NumToTensor(%52), scope: __module.model
            %54 : Tensor[] = prim::ListConstruct(%41, %53), scope: __module.model
            %55 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
            %image_size : Long(2, strides=[1], requires_grad=0, device=cpu) = aten::stack(%54, %55), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
            %57 : Tensor[] = prim::ListConstruct(%image_size), scope: __module.model
            %58 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %59 : Long(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::stack(%57, %58), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %60 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %61 : bool = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %max_size : Long(2, strides=[1], requires_grad=0, device=cpu), %63 : Long(2, strides=[1], requires_grad=0, device=cpu) = aten::max(%59, %60, %61), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:90:0
            %64 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %65 : int = prim::Constant[value=-1](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %66 : Long(requires_grad=0, device=cpu) = aten::select(%max_size, %64, %65), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %67 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %68 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %69 : Long(requires_grad=0, device=cpu) = aten::select(%image_size, %67, %68), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %70 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %71 : Long(requires_grad=0, device=cpu) = aten::sub(%66, %69, %70), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %72 : int = aten::Int(%71), scope: __module.model
            %73 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %74 : int = prim::Constant[value=-2](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %75 : Long(requires_grad=0, device=cpu) = aten::select(%max_size, %73, %74), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %76 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %77 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %78 : Long(requires_grad=0, device=cpu) = aten::select(%image_size, %76, %77), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %79 : int = prim::Constant[value=1](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %80 : Long(requires_grad=0, device=cpu) = aten::sub(%75, %78, %79), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:114:0
            %81 : int = aten::Int(%80), scope: __module.model
            %82 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:4364:0
            %83 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:4364:0
            %84 : int[] = prim::ListConstruct(%82, %72, %83, %81), scope: __module.model
            %85 : float = prim::Constant[value=0.](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:4364:0
            %86 : Float(3, 667, 1333, strides=[1, 3999, 3], requires_grad=0, device=cpu) = aten::constant_pad_nd(%t, %84, %85), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:4364:0
            %87 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %batched_imgs : Float(1, 3, 667, 1333, strides=[3, 1, 3999, 3], requires_grad=0, device=cpu) = aten::unsqueeze_(%86, %87), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:115:0
            %89 : int = prim::Constant[value=0](), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:127:0
            %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu) = aten::contiguous(%batched_imgs, %89), scope: __module.model # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\image_list.py:127:0
            %100 : Tensor = prim::CallMethod[name="forward"](%backbone, %X.1)
            %101 : Tensor = prim::CallMethod[name="forward"](%proposal_generator, %100, %image_size)
            %102 : (Tensor, Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%roi_heads, %100, %101, %image_size)
            %94 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), %95 : Long(0, strides=[2], requires_grad=0, device=cpu), %96 : Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), %97 : Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu), %98 : Float(0, strides=[1], requires_grad=0, device=cpu) = prim::TupleUnpack(%102)
            %99 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(0, strides=[2], requires_grad=0, device=cpu), Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu), Long(2, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%94, %95, %96, %97, %98, %image_size)
            return (%99)
      
        }
      }
      submodules {
        module __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN {
          parameters {
          }
          attributes {
            pixel_mean = ...
            pixel_std = ...
            training = False
            _is_full_backward_hook = None
            backbone = <__torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass object at 0000020DCB8FED10>
            proposal_generator = <__torch__.detectron2.modeling.proposal_generator.rpn.RPN object at 0000020DCBAC6590>
            roi_heads = <__torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads object at 0000020DCBAC8810>
          }
          methods {
          }
          submodules {
            module __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                body = <__torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone object at 0000020DCB8F7710>
                quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested object at 0000020DCB8F8410>
                dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested object at 0000020DCB8FD790>
              }
              methods {
                method forward {
                  graph(%self.5 : __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass,
                        %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                    %dequant_stubs.1 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.5)
                    %body : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone = prim::GetAttr[name="body"](%self.5)
                    %quant_stubs.1 : __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.5)
                    %12 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.1, %X.1)
                    %13 : (Tensor, Tensor, Tensor, Tensor) = prim::CallMethod[name="forward"](%body, %12)
                    %7 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu), %8 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu), %9 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu), %10 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = prim::TupleUnpack(%13)
                    %14 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs.1, %7, %8, %9, %10)
                    return (%14)
              
                }
              }
              submodules {
                module __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    trunk0 = <__torch__.torch.nn.modules.container.Sequential object at 0000020DBEC1B430>
                    trunk1 = <__torch__.torch.nn.modules.container.___torch_mangle_29.Sequential object at 0000020DBEC05230>
                    trunk2 = <__torch__.torch.nn.modules.container.___torch_mangle_79.Sequential object at 0000020DCB23CF00>
                    trunk3 = <__torch__.torch.nn.modules.container.___torch_mangle_178.Sequential object at 0000020DCB8F7C90>
                  }
                  methods {
                    method forward {
                      graph(%self.11 : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone,
                            %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                        %trunk3 : __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential = prim::GetAttr[name="trunk3"](%self.11)
                        %trunk2 : __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential = prim::GetAttr[name="trunk2"](%self.11)
                        %trunk1 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="trunk1"](%self.11)
                        %trunk0 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="trunk0"](%self.11)
                        %11 : Tensor = prim::CallMethod[name="forward"](%trunk0, %1)
                        %12 : Tensor = prim::CallMethod[name="forward"](%trunk1, %11)
                        %13 : Tensor = prim::CallMethod[name="forward"](%trunk2, %12)
                        %14 : Tensor = prim::CallMethod[name="forward"](%trunk3, %13)
                        %10 : (QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu), QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu), QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu), QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11, %12, %13, %14)
                        return (%10)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu object at 0000020DBEBF51B0>
                        fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock object at 0000020DBEC1BCB0>
                      }
                      methods {
                        method forward {
                          graph(%self.13 : __torch__.torch.nn.modules.container.Sequential,
                                %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                            %fbnetv2_0_1.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.13)
                            %fbnetv2_0_0.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu = prim::GetAttr[name="fbnetv2_0_0"](%self.13)
                            %6 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.1, %1)
                            %7 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.1, %6)
                            return (%7)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d object at 0000020DBEC2AC30>
                            bn = <__torch__.torch.nn.modules.linear.Identity object at 0000020DBEBF58B0>
                            relu = <__torch__.torch.nn.modules.linear.___torch_mangle_0.Identity object at 0000020DBEBF43B0>
                          }
                          methods {
                            method forward {
                              graph(%self.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu,
                                    %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                                %relu.1 : __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity = prim::GetAttr[name="relu"](%self.15)
                                %bn.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name="bn"](%self.15)
                                %conv.1 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d = prim::GetAttr[name="conv"](%self.15)
                                %8 : Tensor = prim::CallMethod[name="forward"](%conv.1, %1)
                                %9 : NoneType = prim::CallMethod[name="forward"](%bn.1)
                                %10 : NoneType = prim::CallMethod[name="forward"](%relu.1)
                                return (%8)
                          
                            }
                          }
                          submodules {
                            module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                                in_channels = 3
                                out_channels = 16
                                kernel_size = (3, 3)
                                stride = (2, 2)
                                padding = (1, 1)
                                dilation = (1, 1)
                                transposed = False
                                output_padding = (0, 0)
                                groups = 1
                                padding_mode = zeros
                                _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEBF47B0>
                                scale = 0.23402351140975952
                                zero_point = 0
                              }
                              methods {
                                method __getstate__ {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d):
                                    %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                    %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                    %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                    %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                    %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                    %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                    %scale : float = prim::GetAttr[name="scale"](%self)
                                    %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                    %training : bool = prim::GetAttr[name="training"](%self)
                                    %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                    return (%19)
                              
                                }
                                method __setstate__ {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
                                        %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                    %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                    %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                    %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                    %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                    %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                    %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                    %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                    %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                    %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                    %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                    %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                    %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                    %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                    %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                    %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                    %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                    %4 : int = prim::TupleIndex(%state.1, %3)
                                     = prim::SetAttr[name="in_channels"](%self, %4)
                                    %7 : int = prim::TupleIndex(%state.1, %6)
                                     = prim::SetAttr[name="out_channels"](%self, %7)
                                    %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                     = prim::SetAttr[name="kernel_size"](%self, %10)
                                    %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                     = prim::SetAttr[name="stride"](%self, %13)
                                    %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                     = prim::SetAttr[name="padding"](%self, %16)
                                    %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                     = prim::SetAttr[name="dilation"](%self, %19)
                                    %22 : bool = prim::TupleIndex(%state.1, %21)
                                     = prim::SetAttr[name="transposed"](%self, %22)
                                    %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                     = prim::SetAttr[name="output_padding"](%self, %25)
                                    %28 : int = prim::TupleIndex(%state.1, %27)
                                     = prim::SetAttr[name="groups"](%self, %28)
                                    %31 : str = prim::TupleIndex(%state.1, %30)
                                     = prim::SetAttr[name="padding_mode"](%self, %31)
                                    %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                    %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                    %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                    %41 : float = prim::TupleIndex(%state.1, %40)
                                     = prim::SetAttr[name="scale"](%self, %41)
                                    %44 : int = prim::TupleIndex(%state.1, %43)
                                     = prim::SetAttr[name="zero_point"](%self, %44)
                                    %47 : bool = prim::TupleIndex(%state.1, %46)
                                     = prim::SetAttr[name="training"](%self, %47)
                                    return (%48)
                              
                                }
                                method _weight_bias {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d):
                                    %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                    return (%2)
                              
                                }
                                method set_weight_bias {
                                  graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
                                        %w.1 : Tensor,
                                        %b.1 : Tensor?):
                                    %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                    %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                    %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                    %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                    %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                     = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                      block0():
                                        %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                        %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                        %15 : int[] = prim::ListConstruct(%13, %14)
                                        %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                        %18 : int[] = prim::ListConstruct(%16, %17)
                                        %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                        %21 : int[] = prim::ListConstruct(%19, %20)
                                        %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                         = prim::SetAttr[name="_packed_params"](%self, %22)
                                        -> ()
                                      block1():
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %27 : int[] = prim::ListConstruct(%26, %26)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                        %32 : int[] = prim::ListConstruct(%30, %31)
                                        %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                        %35 : int[] = prim::ListConstruct(%33, %34)
                                        %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                         = prim::SetAttr[name="_packed_params"](%self, %36)
                                        -> ()
                                    return (%37)
                              
                                }
                                method forward {
                                  graph(%self.17 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
                                        %1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                                    %_packed_params.1 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.17)
                                    %15 : float = prim::Constant[value=0.23402351140975952](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                    %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                    %input.3 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.1, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0/__module.model.model.backbone.body.trunk0.fbnetv2_0_0.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                    return (%input.3)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.modules.linear.Identity {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.19 : __torch__.torch.nn.modules.linear.Identity):
                                    %1 : NoneType = prim::Constant()
                                    return (%1)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.21 : __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity):
                                    %1 : NoneType = prim::Constant()
                                    return (%1)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu object at 0000020DBEC0AEB0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu object at 0000020DBEC1B5B0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd object at 0000020DBEC1A730>
                          }
                          methods {
                            method forward {
                              graph(%self.23 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock,
                                    %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                %res_conn.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd = prim::GetAttr[name="res_conn"](%self.23)
                                %pwl.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu = prim::GetAttr[name="pwl"](%self.23)
                                %dw.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu = prim::GetAttr[name="dw"](%self.23)
                                %8 : Tensor = prim::CallMethod[name="forward"](%dw.9, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%pwl.1, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%res_conn.1, %9, %1)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.Conv2d object at 0000020DBEBF5930>
                              }
                              methods {
                                method forward {
                                  graph(%self.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %conv.3 : __torch__.torch.nn.quantized.modules.conv.Conv2d = prim::GetAttr[name="conv"](%self.25)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.3, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 16
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEC09AB0>
                                    scale = 0.22675390541553497
                                    zero_point = 58
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.27 : __torch__.torch.nn.quantized.modules.conv.Conv2d,
                                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.3 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.27)
                                        %15 : float = prim::Constant[value=0.22675390541553497](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.5 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.3, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.5)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d object at 0000020DBEC0BD30>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_3.Identity object at 0000020DBEC1AFB0>
                              }
                              methods {
                                method forward {
                                  graph(%self.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %bn.3 : __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity = prim::GetAttr[name="bn"](%self.29)
                                    %conv.5 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv"](%self.29)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.5, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.3)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 16
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEC1A7B0>
                                    scale = 0.18979501724243164
                                    zero_point = 89
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.31 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
                                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.5 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.31)
                                        %15 : float = prim::Constant[value=0.18979501724243164](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=89](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.3 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.5, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.3)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.33 : __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.QFunctional object at 0000020DBEC1A4B0>
                              }
                              methods {
                                method forward {
                                  graph(%self.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %add_func.1 : __torch__.torch.nn.quantized.modules.functional_modules.QFunctional = prim::GetAttr[name="add_func"](%self.35)
                                    %activation_post_process.1 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity = prim::GetAttr[name="activation_post_process"](%add_func.1)
                                    %5 : float = prim::Constant[value=0.36881163716316223](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=46](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.7 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk0/__module.model.model.backbone.body.trunk0.fbnetv2_0_1/__module.model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.1)
                                    return (%input.7)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_5.Identity object at 0000020DBEC1BAB0>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.37 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_1_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock object at 0000020DBEBEB830>
                        fbnetv2_1_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock object at 0000020DBEC04DB0>
                      }
                      methods {
                        method forward {
                          graph(%self.39 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential,
                                %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                            %fbnetv2_1_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock = prim::GetAttr[name="fbnetv2_1_1"](%self.39)
                            %fbnetv2_1_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock = prim::GetAttr[name="fbnetv2_1_0"](%self.39)
                            %6 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_0, %1)
                            %7 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_1_1, %6)
                            return (%7)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu object at 0000020DBEBF3FB0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu object at 0000020DBEC0DB30>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu object at 0000020DBEBEC130>
                          }
                          methods {
                            method forward {
                              graph(%self.41 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock,
                                    %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                %pwl.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu = prim::GetAttr[name="pwl"](%self.41)
                                %dw.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu = prim::GetAttr[name="dw"](%self.41)
                                %pw.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu = prim::GetAttr[name="pw"](%self.41)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.1, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.11, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.3, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d object at 0000020DBEC1AD30>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_7.Identity object at 0000020DBEBF3C30>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_8.Identity object at 0000020DBEBF2730>
                              }
                              methods {
                                method forward {
                                  graph(%self.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu,
                                        %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                    %relu.3 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity = prim::GetAttr[name="relu"](%self.43)
                                    %bn.5 : __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity = prim::GetAttr[name="bn"](%self.43)
                                    %conv.7 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d = prim::GetAttr[name="conv"](%self.43)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.7, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.5)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.3)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 16
                                    out_channels = 64
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEBF18B0>
                                    scale = 0.13088279962539673
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.45 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
                                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                        %_packed_params.7 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.45)
                                        %15 : float = prim::Constant[value=0.13088279962539673](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.9 : QUInt8(1, 64, 334, 667, strides=[14257792, 1, 42688, 64], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.7, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.9)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.47 : __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.49 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d object at 0000020DBEBF2AB0>
                              }
                              methods {
                                method forward {
                                  graph(%self.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 334, 667, strides=[14257792, 1, 42688, 64], requires_grad=0, device=cpu)):
                                    %conv.9 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv"](%self.51)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.9, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 64
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 64
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEC0C430>
                                    scale = 0.29605790972709656
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.53 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
                                            %1 : QUInt8(1, 64, 334, 667, strides=[14257792, 1, 42688, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.9 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.53)
                                        %15 : float = prim::Constant[value=0.29605790972709656](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.11 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.9, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.11)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d object at 0000020DBEC0CF30>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_13.Identity object at 0000020DBEBEC0B0>
                              }
                              methods {
                                method forward {
                                  graph(%self.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu,
                                        %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                    %bn.7 : __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity = prim::GetAttr[name="bn"](%self.55)
                                    %conv.11 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="conv"](%self.55)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.11, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.7)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 64
                                    out_channels = 24
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEBEAB30>
                                    scale = 0.20768782496452332
                                    zero_point = 53
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.57 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
                                            %1 : QUInt8(1, 64, 167, 334, strides=[3569792, 1, 21376, 64], requires_grad=0, device=cpu)):
                                        %_packed_params.11 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.57)
                                        %15 : float = prim::Constant[value=0.20768782496452332](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=53](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.13 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.11, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_0/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.13)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.59 : __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu object at 0000020DBEC09B30>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu object at 0000020D9D0DA2D0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu object at 0000020DBEBFD9B0>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd object at 0000020DBEC04830>
                          }
                          methods {
                            method forward {
                              graph(%self.61 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock,
                                    %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                %res_conn.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd = prim::GetAttr[name="res_conn"](%self.61)
                                %pwl.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu = prim::GetAttr[name="pwl"](%self.61)
                                %dw.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu = prim::GetAttr[name="dw"](%self.61)
                                %pw.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu = prim::GetAttr[name="pw"](%self.61)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.3, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.13, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.5, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.3, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d object at 0000020DBEBEB8B0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_17.Identity object at 0000020DBEC08DB0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_18.Identity object at 0000020DBEC096B0>
                              }
                              methods {
                                method forward {
                                  graph(%self.63 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu,
                                        %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                    %relu.5 : __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity = prim::GetAttr[name="relu"](%self.63)
                                    %bn.9 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity = prim::GetAttr[name="bn"](%self.63)
                                    %conv.13 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d = prim::GetAttr[name="conv"](%self.63)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.13, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.9)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.5)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 24
                                    out_channels = 48
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEC09230>
                                    scale = 0.057568550109863281
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.65 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
                                            %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                        %_packed_params.13 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.65)
                                        %15 : float = prim::Constant[value=0.057568550109863281](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.15 : QUInt8(1, 48, 167, 334, strides=[2677344, 1, 16032, 48], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.13, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.15)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.67 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.69 : __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d object at 0000020DBEC09730>
                              }
                              methods {
                                method forward {
                                  graph(%self.71 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu,
                                        %1 : QUInt8(1, 48, 167, 334, strides=[2677344, 1, 16032, 48], requires_grad=0, device=cpu)):
                                    %conv.15 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv"](%self.71)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.15, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 48
                                    out_channels = 48
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 48
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEBEEBB0>
                                    scale = 0.10869396477937698
                                    zero_point = 74
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.73 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
                                            %1 : QUInt8(1, 48, 167, 334, strides=[2677344, 1, 16032, 48], requires_grad=0, device=cpu)):
                                        %_packed_params.15 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.73)
                                        %15 : float = prim::Constant[value=0.10869396477937698](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=74](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.17 : QUInt8(1, 48, 167, 334, strides=[2677344, 1, 16032, 48], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.15, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d object at 0000020D9D0D9AD0>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_23.Identity object at 0000020DBEBFD7B0>
                              }
                              methods {
                                method forward {
                                  graph(%self.75 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu,
                                        %1 : QUInt8(1, 48, 167, 334, strides=[2677344, 1, 16032, 48], requires_grad=0, device=cpu)):
                                    %bn.11 : __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity = prim::GetAttr[name="bn"](%self.75)
                                    %conv.17 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv"](%self.75)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.17, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.11)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 48
                                    out_channels = 24
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020D9D0D4AD0>
                                    scale = 0.13859443366527557
                                    zero_point = 55
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.77 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
                                            %1 : QUInt8(1, 48, 167, 334, strides=[2677344, 1, 16032, 48], requires_grad=0, device=cpu)):
                                        %_packed_params.17 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.77)
                                        %15 : float = prim::Constant[value=0.13859443366527557](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=55](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.5 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.17, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.5)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.79 : __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional object at 0000020DBEBFFF30>
                              }
                              methods {
                                method forward {
                                  graph(%self.81 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd,
                                        %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                    %add_func.3 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional = prim::GetAttr[name="add_func"](%self.81)
                                    %activation_post_process.3 : __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity = prim::GetAttr[name="activation_post_process"](%add_func.3)
                                    %5 : float = prim::Constant[value=0.27203214168548584](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.19 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1/__module.model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.3)
                                    return (%input.19)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_25.Identity object at 0000020DBEBFC730>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.83 : __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_2_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock object at 0000020DCB204980>
                        fbnetv2_2_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock object at 0000020DCB227A00>
                        fbnetv2_2_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock object at 0000020DCB20BC00>
                        fbnetv2_2_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock object at 0000020DCB23D700>
                      }
                      methods {
                        method forward {
                          graph(%self.85 : __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential,
                                %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                            %fbnetv2_2_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock = prim::GetAttr[name="fbnetv2_2_3"](%self.85)
                            %fbnetv2_2_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock = prim::GetAttr[name="fbnetv2_2_2"](%self.85)
                            %fbnetv2_2_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock = prim::GetAttr[name="fbnetv2_2_1"](%self.85)
                            %fbnetv2_2_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock = prim::GetAttr[name="fbnetv2_2_0"](%self.85)
                            %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_0, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_1, %10)
                            %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_2, %11)
                            %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_2_3, %12)
                            return (%13)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu object at 0000020D9D0DBAD0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu object at 0000020DBEBF59B0>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu object at 0000020DCB205880>
                          }
                          methods {
                            method forward {
                              graph(%self.87 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock,
                                    %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                %pwl.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu = prim::GetAttr[name="pwl"](%self.87)
                                %dw.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu = prim::GetAttr[name="dw"](%self.87)
                                %pw.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu = prim::GetAttr[name="pw"](%self.87)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.5, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.15, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.7, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d object at 0000020DBEC08030>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_31.Identity object at 0000020D9D0DB350>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_32.Identity object at 0000020D9D0DAE50>
                              }
                              methods {
                                method forward {
                                  graph(%self.89 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu,
                                        %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                    %relu.7 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity = prim::GetAttr[name="relu"](%self.89)
                                    %bn.13 : __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity = prim::GetAttr[name="bn"](%self.89)
                                    %conv.19 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d = prim::GetAttr[name="conv"](%self.89)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.19, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.13)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.7)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 24
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEBEDF30>
                                    scale = 0.066544480621814728
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.91 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
                                            %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                        %_packed_params.19 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.91)
                                        %15 : float = prim::Constant[value=0.066544480621814728](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.21 : QUInt8(1, 96, 167, 334, strides=[5354688, 1, 32064, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.19, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.21)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.93 : __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.95 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d object at 0000020D9D0DAC50>
                              }
                              methods {
                                method forward {
                                  graph(%self.97 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 167, 334, strides=[5354688, 1, 32064, 96], requires_grad=0, device=cpu)):
                                    %conv.21 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="conv"](%self.97)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.21, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DBEBF0230>
                                    scale = 0.089724481105804443
                                    zero_point = 62
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.99 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
                                            %1 : QUInt8(1, 96, 167, 334, strides=[5354688, 1, 32064, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.21 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.99)
                                        %15 : float = prim::Constant[value=0.089724481105804443](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.23 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.21, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.23)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d object at 0000020DBEBF5C30>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_37.Identity object at 0000020DCB206180>
                              }
                              methods {
                                method forward {
                                  graph(%self.101 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %bn.15 : __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity = prim::GetAttr[name="bn"](%self.101)
                                    %conv.23 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="conv"](%self.101)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.23, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.15)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020D9D0D36D0>
                                    scale = 0.13966207206249237
                                    zero_point = 57
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.103 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.23 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.103)
                                        %15 : float = prim::Constant[value=0.13966207206249237](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=57](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.25 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.23, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_0/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.25)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.105 : __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu object at 0000020DCB20EC80>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu object at 0000020DCB21A780>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu object at 0000020DCB226500>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd object at 0000020DCB228280>
                          }
                          methods {
                            method forward {
                              graph(%self.107 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock,
                                    %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                %res_conn.5 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd = prim::GetAttr[name="res_conn"](%self.107)
                                %pwl.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu = prim::GetAttr[name="pwl"](%self.107)
                                %dw.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu = prim::GetAttr[name="dw"](%self.107)
                                %pw.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu = prim::GetAttr[name="pw"](%self.107)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.7, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.17, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.9, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.5, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d object at 0000020DCB204C00>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_41.Identity object at 0000020DCB20F180>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_42.Identity object at 0000020DCB20EA00>
                              }
                              methods {
                                method forward {
                                  graph(%self.109 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %relu.9 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity = prim::GetAttr[name="relu"](%self.109)
                                    %bn.17 : __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity = prim::GetAttr[name="bn"](%self.109)
                                    %conv.25 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d = prim::GetAttr[name="conv"](%self.109)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.25, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.17)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.9)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB20F980>
                                    scale = 0.046318020671606064
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.111 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.25 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.111)
                                        %15 : float = prim::Constant[value=0.046318020671606064](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.27 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.25, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.27)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.113 : __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.115 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d object at 0000020DCB20F100>
                              }
                              methods {
                                method forward {
                                  graph(%self.117 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %conv.27 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d = prim::GetAttr[name="conv"](%self.117)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.27, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB21AC00>
                                    scale = 0.038289416581392288
                                    zero_point = 48
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.119 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.27 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.119)
                                        %15 : float = prim::Constant[value=0.038289416581392288](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=48](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.29 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.27, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.29)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d object at 0000020DCB21AD00>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_47.Identity object at 0000020DCB228200>
                              }
                              methods {
                                method forward {
                                  graph(%self.121 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %bn.19 : __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity = prim::GetAttr[name="bn"](%self.121)
                                    %conv.29 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="conv"](%self.121)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.29, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.19)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB226F00>
                                    scale = 0.093257702887058258
                                    zero_point = 65
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.123 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.29 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.123)
                                        %15 : float = prim::Constant[value=0.093257702887058258](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.7 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.29, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.7)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.125 : __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional object at 0000020DCB226E00>
                              }
                              methods {
                                method forward {
                                  graph(%self.127 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %add_func.5 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional = prim::GetAttr[name="add_func"](%self.127)
                                    %activation_post_process.5 : __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity = prim::GetAttr[name="activation_post_process"](%add_func.5)
                                    %5 : float = prim::Constant[value=0.1453431099653244](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.31 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_1/__module.model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.5)
                                    return (%input.31)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_49.Identity object at 0000020DCB227700>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.129 : __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu object at 0000020DCB233900>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu object at 0000020DCB23E780>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu object at 0000020DCB20BA00>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd object at 0000020DCB20A900>
                          }
                          methods {
                            method forward {
                              graph(%self.131 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock,
                                    %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                %res_conn.7 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd = prim::GetAttr[name="res_conn"](%self.131)
                                %pwl.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu = prim::GetAttr[name="pwl"](%self.131)
                                %dw.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu = prim::GetAttr[name="dw"](%self.131)
                                %pw.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu = prim::GetAttr[name="pw"](%self.131)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.9, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.19, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.11, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.7, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d object at 0000020DCB227A80>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_54.Identity object at 0000020DCB234380>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_55.Identity object at 0000020DCB233F00>
                              }
                              methods {
                                method forward {
                                  graph(%self.133 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %relu.11 : __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity = prim::GetAttr[name="relu"](%self.133)
                                    %bn.21 : __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity = prim::GetAttr[name="bn"](%self.133)
                                    %conv.31 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d = prim::GetAttr[name="conv"](%self.133)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.31, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.21)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.11)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB232C00>
                                    scale = 0.02980509027838707
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.135 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.31 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.135)
                                        %15 : float = prim::Constant[value=0.02980509027838707](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.33 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.31, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.33)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.137 : __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.139 : __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d object at 0000020DCB233600>
                              }
                              methods {
                                method forward {
                                  graph(%self.141 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %conv.33 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d = prim::GetAttr[name="conv"](%self.141)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.33, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB240180>
                                    scale = 0.025917598977684975
                                    zero_point = 63
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.143 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.33 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.143)
                                        %15 : float = prim::Constant[value=0.025917598977684975](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.35 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.33, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.35)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d object at 0000020DCB240000>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_60.Identity object at 0000020DCB20B900>
                              }
                              methods {
                                method forward {
                                  graph(%self.145 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %bn.23 : __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity = prim::GetAttr[name="bn"](%self.145)
                                    %conv.35 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d = prim::GetAttr[name="conv"](%self.145)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.35, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.23)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB20B180>
                                    scale = 0.077115654945373535
                                    zero_point = 71
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.147 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.35 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.147)
                                        %15 : float = prim::Constant[value=0.077115654945373535](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=71](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.9 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.35, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.9)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.149 : __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional object at 0000020DCB20BB00>
                              }
                              methods {
                                method forward {
                                  graph(%self.151 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %add_func.7 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional = prim::GetAttr[name="add_func"](%self.151)
                                    %activation_post_process.7 : __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity = prim::GetAttr[name="activation_post_process"](%add_func.7)
                                    %5 : float = prim::Constant[value=0.12786135077476501](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=75](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.37 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2/__module.model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.7)
                                    return (%input.37)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_62.Identity object at 0000020DCB20C300>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.153 : __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu object at 0000020DCB21A680>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu object at 0000020DCB22D900>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu object at 0000020DCB23E080>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd object at 0000020DCB23D280>
                          }
                          methods {
                            method forward {
                              graph(%self.155 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock,
                                    %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                %res_conn.9 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd = prim::GetAttr[name="res_conn"](%self.155)
                                %pwl.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu = prim::GetAttr[name="pwl"](%self.155)
                                %dw.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu = prim::GetAttr[name="dw"](%self.155)
                                %pw.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu = prim::GetAttr[name="pw"](%self.155)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.11, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.21, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.13, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.9, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d object at 0000020DCB20BC80>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_67.Identity object at 0000020DCB21BB80>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_68.Identity object at 0000020DCB21BC00>
                              }
                              methods {
                                method forward {
                                  graph(%self.157 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %relu.13 : __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity = prim::GetAttr[name="relu"](%self.157)
                                    %bn.25 : __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity = prim::GetAttr[name="bn"](%self.157)
                                    %conv.37 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d = prim::GetAttr[name="conv"](%self.157)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.37, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.25)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.13)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 96
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB21A400>
                                    scale = 0.021504774689674377
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.159 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.37 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.159)
                                        %15 : float = prim::Constant[value=0.021504774689674377](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.39 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.37, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.39)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.161 : __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.163 : __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d object at 0000020DCB21D400>
                              }
                              methods {
                                method forward {
                                  graph(%self.165 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %conv.39 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="conv"](%self.165)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.39, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 96
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 96
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB22B980>
                                    scale = 0.016515623778104782
                                    zero_point = 72
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.167 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.39 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.167)
                                        %15 : float = prim::Constant[value=0.016515623778104782](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.41 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.39, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.41)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d object at 0000020DCB22CF00>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_73.Identity object at 0000020DCB23D080>
                              }
                              methods {
                                method forward {
                                  graph(%self.169 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu,
                                        %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                    %bn.27 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity = prim::GetAttr[name="bn"](%self.169)
                                    %conv.41 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="conv"](%self.169)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.41, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.27)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 96
                                    out_channels = 32
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB23E200>
                                    scale = 0.06984778493642807
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.171 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
                                            %1 : QUInt8(1, 96, 84, 167, strides=[1346688, 1, 16032, 96], requires_grad=0, device=cpu)):
                                        %_packed_params.41 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.171)
                                        %15 : float = prim::Constant[value=0.06984778493642807](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.11 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.41, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.11)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.173 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional object at 0000020DCB23E180>
                              }
                              methods {
                                method forward {
                                  graph(%self.175 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %add_func.9 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional = prim::GetAttr[name="add_func"](%self.175)
                                    %activation_post_process.9 : __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity = prim::GetAttr[name="activation_post_process"](%add_func.9)
                                    %5 : float = prim::Constant[value=0.15847215056419373](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=67](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.43 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk2/__module.model.model.backbone.body.trunk2.fbnetv2_2_3/__module.model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.9)
                                    return (%input.43)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_75.Identity object at 0000020DCB23C700>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.177 : __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        fbnetv2_3_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock object at 0000020DCB23BE80>
                        fbnetv2_3_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock object at 0000020DCB21C880>
                        fbnetv2_3_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock object at 0000020DBEC0DCB0>
                        fbnetv2_3_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock object at 0000020DCB8FDF10>
                        fbnetv2_3_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock object at 0000020DCB921C10>
                        fbnetv2_3_5 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock object at 0000020DCB908190>
                        fbnetv2_3_6 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock object at 0000020DCB8F8090>
                        fbnetv2_3_7 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock object at 0000020DCB8F8A90>
                      }
                      methods {
                        method forward {
                          graph(%self.179 : __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential,
                                %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                            %fbnetv2_3_7 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock = prim::GetAttr[name="fbnetv2_3_7"](%self.179)
                            %fbnetv2_3_6 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock = prim::GetAttr[name="fbnetv2_3_6"](%self.179)
                            %fbnetv2_3_5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock = prim::GetAttr[name="fbnetv2_3_5"](%self.179)
                            %fbnetv2_3_4 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock = prim::GetAttr[name="fbnetv2_3_4"](%self.179)
                            %fbnetv2_3_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock = prim::GetAttr[name="fbnetv2_3_3"](%self.179)
                            %fbnetv2_3_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock = prim::GetAttr[name="fbnetv2_3_2"](%self.179)
                            %fbnetv2_3_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock = prim::GetAttr[name="fbnetv2_3_1"](%self.179)
                            %fbnetv2_3_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock = prim::GetAttr[name="fbnetv2_3_0"](%self.179)
                            %18 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_0, %1)
                            %19 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_1, %18)
                            %20 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_2, %19)
                            %21 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_3, %20)
                            %22 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_4, %21)
                            %23 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_5, %22)
                            %24 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_6, %23)
                            %25 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_3_7, %24)
                            return (%25)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu object at 0000020DCB211200>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu object at 0000020DCB226100>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu object at 0000020DCB23B500>
                          }
                          methods {
                            method forward {
                              graph(%self.181 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock,
                                    %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                %pwl.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu = prim::GetAttr[name="pwl"](%self.181)
                                %dw.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu = prim::GetAttr[name="dw"](%self.181)
                                %pw.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu = prim::GetAttr[name="pw"](%self.181)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.13, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.23, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.15, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d object at 0000020DCB23C900>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_81.Identity object at 0000020DCB20FD00>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_82.Identity object at 0000020DCB211180>
                              }
                              methods {
                                method forward {
                                  graph(%self.183 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu,
                                        %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                    %relu.15 : __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity = prim::GetAttr[name="relu"](%self.183)
                                    %bn.29 : __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity = prim::GetAttr[name="bn"](%self.183)
                                    %conv.43 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d = prim::GetAttr[name="conv"](%self.183)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.43, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.29)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.15)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 32
                                    out_channels = 128
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB20D500>
                                    scale = 0.028126051649451256
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.185 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
                                            %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                        %_packed_params.43 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.185)
                                        %15 : float = prim::Constant[value=0.028126051649451256](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.45 : QUInt8(1, 128, 84, 167, strides=[1795584, 1, 21376, 128], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.43, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.45)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.187 : __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.189 : __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d object at 0000020DCB212000>
                              }
                              methods {
                                method forward {
                                  graph(%self.191 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu,
                                        %1 : QUInt8(1, 128, 84, 167, strides=[1795584, 1, 21376, 128], requires_grad=0, device=cpu)):
                                    %conv.45 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d = prim::GetAttr[name="conv"](%self.191)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.45, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 128
                                    out_channels = 128
                                    kernel_size = (5, 5)
                                    stride = (2, 2)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 128
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB225800>
                                    scale = 0.042158860713243484
                                    zero_point = 54
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.193 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
                                            %1 : QUInt8(1, 128, 84, 167, strides=[1795584, 1, 21376, 128], requires_grad=0, device=cpu)):
                                        %_packed_params.45 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.193)
                                        %15 : float = prim::Constant[value=0.042158860713243484](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=54](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.47 : QUInt8(1, 128, 42, 84, strides=[451584, 1, 10752, 128], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.45, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.47)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d object at 0000020DCB225F00>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_87.Identity object at 0000020DCB23B280>
                              }
                              methods {
                                method forward {
                                  graph(%self.195 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu,
                                        %1 : QUInt8(1, 128, 42, 84, strides=[451584, 1, 10752, 128], requires_grad=0, device=cpu)):
                                    %bn.31 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity = prim::GetAttr[name="bn"](%self.195)
                                    %conv.47 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d = prim::GetAttr[name="conv"](%self.195)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.47, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.31)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 128
                                    out_channels = 56
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB23C400>
                                    scale = 0.085477501153945923
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.197 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
                                            %1 : QUInt8(1, 128, 42, 84, strides=[451584, 1, 10752, 128], requires_grad=0, device=cpu)):
                                        %_packed_params.47 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.197)
                                        %15 : float = prim::Constant[value=0.085477501153945923](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.49 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.47, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_0/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.49)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.199 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu object at 0000020DCB218280>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu object at 0000020DCB236280>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu object at 0000020DCB218D80>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd object at 0000020DCB219180>
                          }
                          methods {
                            method forward {
                              graph(%self.201 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock,
                                    %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                %res_conn.11 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd = prim::GetAttr[name="res_conn"](%self.201)
                                %pwl.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu = prim::GetAttr[name="pwl"](%self.201)
                                %dw.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu = prim::GetAttr[name="dw"](%self.201)
                                %pw.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu = prim::GetAttr[name="pw"](%self.201)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.15, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.25, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.17, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.11, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d object at 0000020DCB23BA00>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_91.Identity object at 0000020DCB218180>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_92.Identity object at 0000020DCB216900>
                              }
                              methods {
                                method forward {
                                  graph(%self.203 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %relu.17 : __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity = prim::GetAttr[name="relu"](%self.203)
                                    %bn.33 : __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity = prim::GetAttr[name="bn"](%self.203)
                                    %conv.49 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d = prim::GetAttr[name="conv"](%self.203)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.49, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.33)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.17)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 56
                                    out_channels = 168
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB215E00>
                                    scale = 0.018082233145833015
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.205 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
                                            %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                        %_packed_params.49 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.205)
                                        %15 : float = prim::Constant[value=0.018082233145833015](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.51 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.49, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.51)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.207 : __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.209 : __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d object at 0000020DCB216B00>
                              }
                              methods {
                                method forward {
                                  graph(%self.211 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu,
                                        %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                    %conv.51 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d = prim::GetAttr[name="conv"](%self.211)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.51, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 168
                                    out_channels = 168
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 168
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB233480>
                                    scale = 0.014367960393428802
                                    zero_point = 76
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.213 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
                                            %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                        %_packed_params.51 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.213)
                                        %15 : float = prim::Constant[value=0.014367960393428802](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=76](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.53 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.51, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.53)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d object at 0000020DCB235400>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_97.Identity object at 0000020DCB218B00>
                              }
                              methods {
                                method forward {
                                  graph(%self.215 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu,
                                        %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                    %bn.35 : __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity = prim::GetAttr[name="bn"](%self.215)
                                    %conv.53 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d = prim::GetAttr[name="conv"](%self.215)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.53, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.35)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 168
                                    out_channels = 56
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB218480>
                                    scale = 0.081628315150737762
                                    zero_point = 73
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.217 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
                                            %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                        %_packed_params.53 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.217)
                                        %15 : float = prim::Constant[value=0.081628315150737762](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=73](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.13 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.53, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.13)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.219 : __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional object at 0000020DCB219F00>
                              }
                              methods {
                                method forward {
                                  graph(%self.221 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %add_func.11 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional = prim::GetAttr[name="add_func"](%self.221)
                                    %activation_post_process.11 : __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity = prim::GetAttr[name="activation_post_process"](%add_func.11)
                                    %5 : float = prim::Constant[value=0.096974745392799377](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=76](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.55 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_1/__module.model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.11)
                                    return (%input.55)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_99.Identity object at 0000020DCB218800>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.223 : __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu object at 0000020DBEC1F9B0>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu object at 0000020DCB211280>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu object at 0000020DBEC09030>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd object at 0000020DBEC08330>
                          }
                          methods {
                            method forward {
                              graph(%self.225 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock,
                                    %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                %res_conn.13 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd = prim::GetAttr[name="res_conn"](%self.225)
                                %pwl.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu = prim::GetAttr[name="pwl"](%self.225)
                                %dw.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu = prim::GetAttr[name="dw"](%self.225)
                                %pw.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu = prim::GetAttr[name="pw"](%self.225)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.17, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.27, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.19, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.13, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d object at 0000020DCB21CE00>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_104.Identity object at 0000020DBEC1E330>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_105.Identity object at 0000020DBEC1ED30>
                              }
                              methods {
                                method forward {
                                  graph(%self.227 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %relu.19 : __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity = prim::GetAttr[name="relu"](%self.227)
                                    %bn.37 : __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity = prim::GetAttr[name="bn"](%self.227)
                                    %conv.55 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d = prim::GetAttr[name="conv"](%self.227)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.55, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.37)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.19)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 56
                                    out_channels = 168
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB241880>
                                    scale = 0.012206130661070347
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.229 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
                                            %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                        %_packed_params.55 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.229)
                                        %15 : float = prim::Constant[value=0.012206130661070347](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.57 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.55, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.57)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.231 : __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.233 : __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d object at 0000020DBEC20130>
                              }
                              methods {
                                method forward {
                                  graph(%self.235 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu,
                                        %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                    %conv.57 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d = prim::GetAttr[name="conv"](%self.235)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.57, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 168
                                    out_channels = 168
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 168
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB20C800>
                                    scale = 0.008389773778617382
                                    zero_point = 59
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.237 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
                                            %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                        %_packed_params.57 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.237)
                                        %15 : float = prim::Constant[value=0.008389773778617382](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.59 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.57, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.59)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d object at 0000020DCB211580>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_110.Identity object at 0000020DBEC09D30>
                              }
                              methods {
                                method forward {
                                  graph(%self.239 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu,
                                        %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                    %bn.39 : __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity = prim::GetAttr[name="bn"](%self.239)
                                    %conv.59 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d = prim::GetAttr[name="conv"](%self.239)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.59, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.39)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 168
                                    out_channels = 56
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB20D200>
                                    scale = 0.054540254175662994
                                    zero_point = 59
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.241 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
                                            %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                        %_packed_params.59 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.241)
                                        %15 : float = prim::Constant[value=0.054540254175662994](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.15 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.59, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.15)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.243 : __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional object at 0000020DBEC090B0>
                              }
                              methods {
                                method forward {
                                  graph(%self.245 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %add_func.13 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional = prim::GetAttr[name="add_func"](%self.245)
                                    %activation_post_process.13 : __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity = prim::GetAttr[name="activation_post_process"](%add_func.13)
                                    %5 : float = prim::Constant[value=0.10126941651105881](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.61 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_2/__module.model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.13)
                                    return (%input.61)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_112.Identity object at 0000020DBEC09A30>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.247 : __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu object at 0000020D9D0DE450>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu object at 0000020DCB8F4A10>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu object at 0000020DCB8FEB90>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd object at 0000020DCB8FE590>
                          }
                          methods {
                            method forward {
                              graph(%self.249 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock,
                                    %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                %res_conn.15 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd = prim::GetAttr[name="res_conn"](%self.249)
                                %pwl.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu = prim::GetAttr[name="pwl"](%self.249)
                                %dw.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu = prim::GetAttr[name="dw"](%self.249)
                                %pw.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu = prim::GetAttr[name="pw"](%self.249)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.19, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.29, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.21, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.15, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d object at 0000020DBEC0D230>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_117.Identity object at 0000020D9D0DDC50>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_118.Identity object at 0000020D9D0DDA50>
                              }
                              methods {
                                method forward {
                                  graph(%self.251 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %relu.21 : __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity = prim::GetAttr[name="relu"](%self.251)
                                    %bn.41 : __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity = prim::GetAttr[name="bn"](%self.251)
                                    %conv.61 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d = prim::GetAttr[name="conv"](%self.251)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.61, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.41)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.21)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 56
                                    out_channels = 168
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB22F600>
                                    scale = 0.012566062621772289
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.253 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
                                            %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                        %_packed_params.61 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.253)
                                        %15 : float = prim::Constant[value=0.012566062621772289](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.63 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.61, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.63)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.255 : __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.257 : __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d object at 0000020D9D0DCC50>
                              }
                              methods {
                                method forward {
                                  graph(%self.259 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu,
                                        %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                    %conv.63 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d = prim::GetAttr[name="conv"](%self.259)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.63, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 168
                                    out_channels = 168
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 168
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB226300>
                                    scale = 0.0076472368091344833
                                    zero_point = 68
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.261 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
                                            %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                        %_packed_params.63 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.261)
                                        %15 : float = prim::Constant[value=0.0076472368091344833](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.65 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.63, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d object at 0000020DCB8F4B10>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_123.Identity object at 0000020DCB8FDC10>
                              }
                              methods {
                                method forward {
                                  graph(%self.263 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu,
                                        %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                    %bn.43 : __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity = prim::GetAttr[name="bn"](%self.263)
                                    %conv.65 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d = prim::GetAttr[name="conv"](%self.263)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.65, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.43)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 168
                                    out_channels = 56
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB8FEF10>
                                    scale = 0.064626649022102356
                                    zero_point = 62
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.265 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
                                            %1 : QUInt8(1, 168, 42, 84, strides=[592704, 1, 14112, 168], requires_grad=0, device=cpu)):
                                        %_packed_params.65 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.265)
                                        %15 : float = prim::Constant[value=0.064626649022102356](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.17 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.65, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.17)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.267 : __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional object at 0000020DCB8FE010>
                              }
                              methods {
                                method forward {
                                  graph(%self.269 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %add_func.15 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional = prim::GetAttr[name="add_func"](%self.269)
                                    %activation_post_process.15 : __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity = prim::GetAttr[name="activation_post_process"](%add_func.15)
                                    %5 : float = prim::Constant[value=0.10653065890073776](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=60](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.67 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3/__module.model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.15)
                                    return (%input.67)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_125.Identity object at 0000020DCB8FDC90>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.271 : __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu object at 0000020DCB909F90>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu object at 0000020DCB916610>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu object at 0000020DCB922E10>
                          }
                          methods {
                            method forward {
                              graph(%self.273 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock,
                                    %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                %pwl.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu = prim::GetAttr[name="pwl"](%self.273)
                                %dw.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu = prim::GetAttr[name="dw"](%self.273)
                                %pw.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu = prim::GetAttr[name="pw"](%self.273)
                                %8 : Tensor = prim::CallMethod[name="forward"](%pw.21, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%dw.31, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pwl.23, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d object at 0000020DCB8FDE90>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_130.Identity object at 0000020DCB90A210>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_131.Identity object at 0000020DCB909190>
                              }
                              methods {
                                method forward {
                                  graph(%self.275 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu,
                                        %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                    %relu.23 : __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity = prim::GetAttr[name="relu"](%self.275)
                                    %bn.45 : __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity = prim::GetAttr[name="bn"](%self.275)
                                    %conv.67 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d = prim::GetAttr[name="conv"](%self.275)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.67, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.45)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.23)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 56
                                    out_channels = 224
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB909290>
                                    scale = 0.030309252440929413
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.277 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
                                            %1 : QUInt8(1, 56, 42, 84, strides=[197568, 1, 4704, 56], requires_grad=0, device=cpu)):
                                        %_packed_params.67 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.277)
                                        %15 : float = prim::Constant[value=0.030309252440929413](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.69 : QUInt8(1, 224, 42, 84, strides=[790272, 1, 18816, 224], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.67, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.69)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.279 : __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.281 : __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d object at 0000020DCB90A510>
                              }
                              methods {
                                method forward {
                                  graph(%self.283 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu,
                                        %1 : QUInt8(1, 224, 42, 84, strides=[790272, 1, 18816, 224], requires_grad=0, device=cpu)):
                                    %conv.69 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d = prim::GetAttr[name="conv"](%self.283)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.69, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 224
                                    out_channels = 224
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 224
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB916790>
                                    scale = 0.031364411115646362
                                    zero_point = 65
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.285 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
                                            %1 : QUInt8(1, 224, 42, 84, strides=[790272, 1, 18816, 224], requires_grad=0, device=cpu)):
                                        %_packed_params.69 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.285)
                                        %15 : float = prim::Constant[value=0.031364411115646362](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.71 : QUInt8(1, 224, 42, 84, strides=[790272, 1, 18816, 224], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.69, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.71)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d object at 0000020DCB916390>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_136.Identity object at 0000020DCB922190>
                              }
                              methods {
                                method forward {
                                  graph(%self.287 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu,
                                        %1 : QUInt8(1, 224, 42, 84, strides=[790272, 1, 18816, 224], requires_grad=0, device=cpu)):
                                    %bn.47 : __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity = prim::GetAttr[name="bn"](%self.287)
                                    %conv.71 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d = prim::GetAttr[name="conv"](%self.287)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.71, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.47)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 224
                                    out_channels = 88
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB922F90>
                                    scale = 0.036332279443740845
                                    zero_point = 71
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.289 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
                                            %1 : QUInt8(1, 224, 42, 84, strides=[790272, 1, 18816, 224], requires_grad=0, device=cpu)):
                                        %_packed_params.71 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.289)
                                        %15 : float = prim::Constant[value=0.036332279443740845](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=71](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.73 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.71, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_4/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.73)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.291 : __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu object at 0000020DCB92DE90>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu object at 0000020DCB8FA110>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu object at 0000020DCB907610>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd object at 0000020DCB908E90>
                          }
                          methods {
                            method forward {
                              graph(%self.293 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %res_conn.17 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd = prim::GetAttr[name="res_conn"](%self.293)
                                %pwl.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu = prim::GetAttr[name="pwl"](%self.293)
                                %dw.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu = prim::GetAttr[name="dw"](%self.293)
                                %pw.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu = prim::GetAttr[name="pw"](%self.293)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.23, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.33, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.25, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.17, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d object at 0000020DCB921310>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_140.Identity object at 0000020DCB92ED10>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_141.Identity object at 0000020DCB92F110>
                              }
                              methods {
                                method forward {
                                  graph(%self.295 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %relu.25 : __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity = prim::GetAttr[name="relu"](%self.295)
                                    %bn.49 : __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity = prim::GetAttr[name="bn"](%self.295)
                                    %conv.73 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d = prim::GetAttr[name="conv"](%self.295)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.73, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.49)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.25)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 88
                                    out_channels = 352
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB92D710>
                                    scale = 0.017048543319106102
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.297 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %_packed_params.73 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.297)
                                        %15 : float = prim::Constant[value=0.017048543319106102](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.75 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.73, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.75)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.299 : __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.301 : __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d object at 0000020DCB92DA10>
                              }
                              methods {
                                method forward {
                                  graph(%self.303 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu,
                                        %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                    %conv.75 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d = prim::GetAttr[name="conv"](%self.303)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.75, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 352
                                    out_channels = 352
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 352
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB8F9710>
                                    scale = 0.014346770942211151
                                    zero_point = 64
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.305 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %_packed_params.75 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.305)
                                        %15 : float = prim::Constant[value=0.014346770942211151](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.77 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.75, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.77)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d object at 0000020DCB8FA990>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_146.Identity object at 0000020DCB907890>
                              }
                              methods {
                                method forward {
                                  graph(%self.307 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu,
                                        %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                    %bn.51 : __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity = prim::GetAttr[name="bn"](%self.307)
                                    %conv.77 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d = prim::GetAttr[name="conv"](%self.307)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.77, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.51)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 352
                                    out_channels = 88
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB907B90>
                                    scale = 0.025216508656740189
                                    zero_point = 61
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.309 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %_packed_params.77 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.309)
                                        %15 : float = prim::Constant[value=0.025216508656740189](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.19 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.77, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.19)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.311 : __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional object at 0000020DCB908D90>
                              }
                              methods {
                                method forward {
                                  graph(%self.313 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %add_func.17 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional = prim::GetAttr[name="add_func"](%self.313)
                                    %activation_post_process.17 : __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity = prim::GetAttr[name="activation_post_process"](%add_func.17)
                                    %5 : float = prim::Constant[value=0.051511440426111221](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.79 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_5/__module.model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.17)
                                    return (%input.79)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_148.Identity object at 0000020DCB908310>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.315 : __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu object at 0000020DCB917790>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu object at 0000020DCB928C90>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu object at 0000020DCB8F8D10>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd object at 0000020DCB8F8990>
                          }
                          methods {
                            method forward {
                              graph(%self.317 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %res_conn.19 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd = prim::GetAttr[name="res_conn"](%self.317)
                                %pwl.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu = prim::GetAttr[name="pwl"](%self.317)
                                %dw.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu = prim::GetAttr[name="dw"](%self.317)
                                %pw.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu = prim::GetAttr[name="pw"](%self.317)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.25, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.35, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.27, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.19, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d object at 0000020DCB908C10>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_153.Identity object at 0000020DCB918F10>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_154.Identity object at 0000020DCB917910>
                              }
                              methods {
                                method forward {
                                  graph(%self.319 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %relu.27 : __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity = prim::GetAttr[name="relu"](%self.319)
                                    %bn.53 : __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity = prim::GetAttr[name="bn"](%self.319)
                                    %conv.79 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d = prim::GetAttr[name="conv"](%self.319)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.79, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.53)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.27)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 88
                                    out_channels = 352
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB917490>
                                    scale = 0.007015641313046217
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.321 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %_packed_params.79 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.321)
                                        %15 : float = prim::Constant[value=0.007015641313046217](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.81 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.79, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.81)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.323 : __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.325 : __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d object at 0000020DCB917D10>
                              }
                              methods {
                                method forward {
                                  graph(%self.327 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu,
                                        %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                    %conv.81 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d = prim::GetAttr[name="conv"](%self.327)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.81, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 352
                                    out_channels = 352
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 352
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB927E10>
                                    scale = 0.0063367453403770924
                                    zero_point = 55
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.329 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %_packed_params.81 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.329)
                                        %15 : float = prim::Constant[value=0.0063367453403770924](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=55](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.83 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.81, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.83)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d object at 0000020DCB928490>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_159.Identity object at 0000020DCB8F8610>
                              }
                              methods {
                                method forward {
                                  graph(%self.331 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu,
                                        %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                    %bn.55 : __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity = prim::GetAttr[name="bn"](%self.331)
                                    %conv.83 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d = prim::GetAttr[name="conv"](%self.331)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.83, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.55)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 352
                                    out_channels = 88
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB8F7B90>
                                    scale = 0.021103033795952797
                                    zero_point = 63
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.333 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %_packed_params.83 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.333)
                                        %15 : float = prim::Constant[value=0.021103033795952797](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.21 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.83, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.21)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.335 : __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional object at 0000020DCB8F7D90>
                              }
                              methods {
                                method forward {
                                  graph(%self.337 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %add_func.19 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional = prim::GetAttr[name="add_func"](%self.337)
                                    %activation_post_process.19 : __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity = prim::GetAttr[name="activation_post_process"](%add_func.19)
                                    %5 : float = prim::Constant[value=0.066962011158466339](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=71](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %input.85 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_6/__module.model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.19)
                                    return (%input.85)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_161.Identity object at 0000020DCB8F7890>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.339 : __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu object at 0000020DCB90DF10>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu object at 0000020DCB923610>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu object at 0000020DCB8F7690>
                            res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd object at 0000020DCB8F7590>
                          }
                          methods {
                            method forward {
                              graph(%self.341 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %res_conn.21 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd = prim::GetAttr[name="res_conn"](%self.341)
                                %pwl.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu = prim::GetAttr[name="pwl"](%self.341)
                                %dw.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu = prim::GetAttr[name="dw"](%self.341)
                                %pw.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu = prim::GetAttr[name="pw"](%self.341)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw.27, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%dw.37, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%pwl.29, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.21, %12, %1)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d object at 0000020DCB8F7E10>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_166.Identity object at 0000020DCB90DC90>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_167.Identity object at 0000020DCB90EB10>
                              }
                              methods {
                                method forward {
                                  graph(%self.343 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %relu.29 : __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity = prim::GetAttr[name="relu"](%self.343)
                                    %bn.57 : __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity = prim::GetAttr[name="bn"](%self.343)
                                    %conv.85 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d = prim::GetAttr[name="conv"](%self.343)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%conv.85, %1)
                                    %9 : NoneType = prim::CallMethod[name="forward"](%bn.57)
                                    %10 : NoneType = prim::CallMethod[name="forward"](%relu.29)
                                    return (%8)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 88
                                    out_channels = 352
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB90D210>
                                    scale = 0.010070341639220715
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.345 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %_packed_params.85 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.345)
                                        %15 : float = prim::Constant[value=0.010070341639220715](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.87 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.85, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.87)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.347 : __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.349 : __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d object at 0000020DCB90F010>
                              }
                              methods {
                                method forward {
                                  graph(%self.351 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu,
                                        %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                    %conv.87 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d = prim::GetAttr[name="conv"](%self.351)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.87, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 352
                                    out_channels = 352
                                    kernel_size = (5, 5)
                                    stride = (1, 1)
                                    padding = (2, 2)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 352
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB923790>
                                    scale = 0.0061015426181256771
                                    zero_point = 59
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.353 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %_packed_params.87 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.353)
                                        %15 : float = prim::Constant[value=0.0061015426181256771](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=59](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input.89 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.87, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input.89)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d object at 0000020DCB925090>
                                bn = <__torch__.torch.nn.modules.linear.___torch_mangle_172.Identity object at 0000020DCB8F8D90>
                              }
                              methods {
                                method forward {
                                  graph(%self.355 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu,
                                        %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                    %bn.59 : __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity = prim::GetAttr[name="bn"](%self.355)
                                    %conv.89 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d = prim::GetAttr[name="conv"](%self.355)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.89, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%bn.59)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 352
                                    out_channels = 88
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB8F9010>
                                    scale = 0.022942099720239639
                                    zero_point = 66
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.357 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %_packed_params.89 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.357)
                                        %15 : float = prim::Constant[value=0.022942099720239639](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %x.23 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.89, %15, %16), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%x.23)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.359 : __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional object at 0000020DCB8F9110>
                              }
                              methods {
                                method forward {
                                  graph(%self.361 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                                        %2 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %add_func.21 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional = prim::GetAttr[name="add_func"](%self.361)
                                    %activation_post_process.21 : __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity = prim::GetAttr[name="activation_post_process"](%add_func.21)
                                    %5 : float = prim::Constant[value=0.089796319603919983](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %6 : int = prim::Constant[value=70](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %Xq.1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.body/__module.model.model.backbone.body.trunk3/__module.model.model.backbone.body.trunk3.fbnetv2_3_7/__module.model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                    %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.21)
                                    return (%Xq.1)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_174.Identity object at 0000020DCB8F8A10>
                                  }
                                  methods {
                                  }
                                  submodules {
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.363 : __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    stubs = <__torch__.torch.nn.modules.container.ModuleList object at 0000020DCB8F7E90>
                  }
                  methods {
                    method forward {
                      graph(%self.7 : __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested,
                            %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                        %stubs.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="stubs"](%self.7)
                        %_0.1 : __torch__.torch.nn.quantized.modules.Quantize = prim::GetAttr[name="0"](%stubs.1)
                        %5 : Tensor = prim::CallMethod[name="forward"](%_0.1, %X.1)
                        return (%5)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.quantized.modules.Quantize object at 0000020DCB8F8310>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.Quantize {
                          parameters {
                          }
                          attributes {
                            scale = ...
                            zero_point = ...
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.9 : __torch__.torch.nn.quantized.modules.Quantize,
                                    %X.1 : Float(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu)):
                                %2 : float = prim::Constant[value=0.016195546835660934](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                %3 : int = prim::Constant[value=127](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                %input.1 : QUInt8(1, 3, 667, 1333, strides=[2667333, 889111, 1333, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%X.1, %2, %3, %4), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.quant_stubs/__module.model.model.backbone.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                return (%input.1)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    stubs = <__torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList object at 0000020DCB8FEC10>
                  }
                  methods {
                    method forward {
                      graph(%self.365 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested,
                            %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu),
                            %2 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu),
                            %3 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu),
                            %4 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                        %stubs.9 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_3 : __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize = prim::GetAttr[name="3"](%stubs.9)
                        %stubs.7 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_2 : __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize = prim::GetAttr[name="2"](%stubs.7)
                        %stubs.5 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_1.1 : __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize = prim::GetAttr[name="1"](%stubs.5)
                        %stubs.3 : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList = prim::GetAttr[name="stubs"](%self.365)
                        %_0.3 : __torch__.torch.nn.quantized.modules.DeQuantize = prim::GetAttr[name="0"](%stubs.3)
                        %17 : NoneType = prim::CallMethod[name="forward"](%_0.3, %1)
                        %18 : NoneType = prim::CallMethod[name="forward"](%_1.1, %2)
                        %19 : NoneType = prim::CallMethod[name="forward"](%_2, %3)
                        %20 : Tensor = prim::CallMethod[name="forward"](%_3, %4)
                        return (%20)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.quantized.modules.DeQuantize object at 0000020DCB8F7910>
                        1 = <__torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize object at 0000020DCB8F9390>
                        2 = <__torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize object at 0000020DCB8FBF90>
                        3 = <__torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize object at 0000020DCB8FC290>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.367 : __torch__.torch.nn.quantized.modules.DeQuantize,
                                    %1 : QUInt8(1, 16, 334, 667, strides=[3564448, 1, 10672, 16], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.369 : __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize,
                                    %1 : QUInt8(1, 24, 167, 334, strides=[1338672, 1, 8016, 24], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.371 : __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize,
                                    %1 : QUInt8(1, 32, 84, 167, strides=[448896, 1, 5344, 32], requires_grad=0, device=cpu)):
                                %3 : NoneType = prim::Constant()
                                return (%3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.373 : __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %feature_map : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.backbone/__module.model.model.backbone.dequant_stubs/__module.model.model.backbone.dequant_stubs.stubs.3 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                return (%feature_map)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.proposal_generator.rpn.RPN {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                rpn_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass object at 0000020DCBAC5B90>
                anchor_generator = <__torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator object at 0000020DCBAC5B10>
              }
              methods {
                method forward {
                  graph(%self.375 : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                        %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                        %image_size : Long(2, strides=[1], requires_grad=0, device=cpu)):
                    %rpn_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass = prim::GetAttr[name="rpn_head"](%self.375)
                    %anchor_generator : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator = prim::GetAttr[name="anchor_generator"](%self.375)
                    %534 : Tensor = prim::CallMethod[name="forward"](%anchor_generator, %1)
                    %535 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%rpn_head, %1)
                    %7 : Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), %8 : Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%535)
                    %9 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %10 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %11 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %12 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %13 : int[] = prim::ListConstruct(%9, %10, %11, %12), scope: __module.model/__module.model.model.proposal_generator
                    %14 : Float(1, 42, 84, 15, strides=[52920, 1260, 15, 1], requires_grad=0, device=cpu) = aten::permute(%7, %13), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %16 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %logits_i : Float(1, 52920, strides=[52920, 1], requires_grad=0, device=cpu) = aten::flatten(%14, %15, %16), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:458:0
                    %18 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %19 : int = aten::size(%8, %18), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %20 : Long(device=cpu) = prim::NumToTensor(%19), scope: __module.model/__module.model.model.proposal_generator
                    %21 : int = aten::Int(%20), scope: __module.model/__module.model.model.proposal_generator
                    %37 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %38 : int = aten::size(%8, %37), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %39 : Long(device=cpu) = prim::NumToTensor(%38), scope: __module.model/__module.model.model.proposal_generator
                    %40 : int = aten::Int(%39), scope: __module.model/__module.model.model.proposal_generator
                    %53 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %54 : int = aten::size(%8, %53), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %55 : Long(device=cpu) = prim::NumToTensor(%54), scope: __module.model/__module.model.model.proposal_generator
                    %56 : int = aten::Int(%55), scope: __module.model/__module.model.model.proposal_generator
                    %57 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %58 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %59 : int[] = prim::ListConstruct(%21, %57, %58, %40, %56), scope: __module.model/__module.model.model.proposal_generator
                    %60 : Float(1, 15, 4, 42, 84, strides=[60, 4, 1, 5040, 60], requires_grad=0, device=cpu) = aten::view(%8, %59), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %61 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %62 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %63 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %64 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %65 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %66 : int[] = prim::ListConstruct(%61, %62, %63, %64, %65), scope: __module.model/__module.model.model.proposal_generator
                    %67 : Float(1, 42, 84, 15, 4, strides=[60, 5040, 60, 4, 1], requires_grad=0, device=cpu) = aten::permute(%60, %66), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %68 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %69 : int = prim::Constant[value=-2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %pred_anchor_deltas_i : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::flatten(%67, %68, %69), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:463:0
                    %71 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:522:0
                    %72 : int = aten::size(%pred_anchor_deltas_i, %71), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:522:0
                    %N : Long(device=cpu) = prim::NumToTensor(%72), scope: __module.model/__module.model.model.proposal_generator
                    %74 : int = aten::Int(%N), scope: __module.model/__module.model.model.proposal_generator
                    %75 : int = aten::Int(%N), scope: __module.model/__module.model.model.proposal_generator
                    %82 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:526:0
                    %83 : int = aten::size(%534, %82), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:526:0
                    %B : Long(device=cpu) = prim::NumToTensor(%83), scope: __module.model/__module.model.model.proposal_generator
                    %85 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %86 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %87 : int = aten::Int(%B), scope: __module.model/__module.model.model.proposal_generator
                    %88 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:527:0
                    %89 : int[] = prim::ListConstruct(%88, %87), scope: __module.model/__module.model.model.proposal_generator
                    %deltas.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_anchor_deltas_i, %89), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:527:0
                    %91 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %92 : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%534, %91), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %93 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %94 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %95 : int[] = prim::ListConstruct(%75, %93, %94), scope: __module.model/__module.model.model.proposal_generator
                    %96 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %97 : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::expand(%92, %95, %96), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %98 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %99 : int[] = prim::ListConstruct(%98, %86), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%97, %99), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:529:0
                    %101 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %102 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %103 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %104 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %deltas.3 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%deltas.1, %101, %102, %103, %104), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %106 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %107 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %108 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %109 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %boxes.3 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%boxes.1, %106, %107, %108, %109), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %111 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %112 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %113 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %114 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %115 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %111, %112, %113, %114), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %116 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %117 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %118 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%115, %116, %117), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %119 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %120 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %121 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %122 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %123 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %119, %120, %121, %122), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %124 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %125 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %126 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%123, %124, %125), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %widths.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::sub(%118, %126, %127), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %129 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %130 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %131 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %133 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %129, %130, %131, %132), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %134 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %135 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %136 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%133, %134, %135), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %137 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %138 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %139 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %140 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %141 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %137, %138, %139, %140), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %142 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %143 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %144 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%141, %142, %143), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %145 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %heights.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::sub(%136, %144, %145), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %147 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %148 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %149 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %151 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %147, %148, %149, %150), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %152 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %153 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %154 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%151, %152, %153), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %155 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %156 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::mul(%widths.1, %155), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %157 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %ctr_x.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::add(%154, %156, %157), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %159 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %160 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %161 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %162 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %163 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.3, %159, %160, %161, %162), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %164 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %166 : Float(52920, strides=[4], requires_grad=0, device=cpu) = aten::select(%163, %164, %165), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %167 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %168 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::mul(%heights.1, %167), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %169 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %ctr_y.1 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::add(%166, %168, %169), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %171 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %172 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %173 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %174 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %175 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %171, %172, %173, %174), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %176 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %177 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %178 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %179 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %180 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%175, %176, %177, %178, %179), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %181 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %dx.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%180, %181), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %183 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %184 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %185 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %186 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %187 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %183, %184, %185, %186), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %188 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %189 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %190 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %191 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %192 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%187, %188, %189, %190, %191), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %193 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %dy.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%192, %193), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %195 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %196 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %197 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %198 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %199 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %195, %196, %197, %198), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %200 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %201 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %202 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %203 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %204 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%199, %200, %201, %202, %203), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %205 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %dw.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%204, %205), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %207 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %208 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %209 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %210 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %211 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas.3, %207, %208, %209, %210), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %212 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %213 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %214 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %215 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %216 : Float(52920, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%211, %212, %213, %214, %215), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %217 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %dh.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%216, %217), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %219 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %220 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %dw.3 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dw.1, %219, %220), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %222 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %223 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %dh.3 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dh.1, %222, %223), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %225 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %226 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %227 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %228 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %229 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths.1, %225, %226, %227, %228), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %230 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %231 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%229, %230), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %232 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dx.1, %231), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %233 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %234 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %235 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %236 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %237 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_x.1, %233, %234, %235, %236), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %238 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %239 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%237, %238), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %240 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %pred_ctr_x.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%232, %239, %240), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %242 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %243 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %244 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %245 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %246 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights.1, %242, %243, %244, %245), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %248 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%246, %247), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %249 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dy.1, %248), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %250 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %251 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %252 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %253 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %254 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_y.1, %250, %251, %252, %253), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %255 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %256 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%254, %255), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %pred_ctr_y.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%249, %256, %257), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %259 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dw.3), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %260 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %261 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %262 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %263 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %264 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths.1, %260, %261, %262, %263), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %265 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %266 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%264, %265), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %pred_w.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%259, %266), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %268 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dh.3), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %269 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %270 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %271 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %273 : Float(52920, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights.1, %269, %270, %271, %272), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %274 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %275 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%273, %274), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %pred_h.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%268, %275), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %277 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %278 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w.1, %277), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %279 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %x1.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_x.1, %278, %279), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %281 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %282 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h.1, %281), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %y1.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_y.1, %282, %283), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %285 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %286 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w.1, %285), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %287 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %x2.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_x.1, %286, %287), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %289 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %290 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h.1, %289), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %291 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %y2.1 : Float(52920, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_y.1, %290, %291), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %293 : Tensor[] = prim::ListConstruct(%x1.1, %y1.1, %x2.1, %y2.1), scope: __module.model/__module.model.model.proposal_generator
                    %294 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %pred_boxes.1 : Float(52920, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::stack(%293, %294), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %296 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %297 : int = aten::size(%deltas.3, %296), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %298 : Long(device=cpu) = prim::NumToTensor(%297), scope: __module.model/__module.model.model.proposal_generator
                    %299 : int = aten::Int(%298), scope: __module.model/__module.model.model.proposal_generator
                    %300 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %301 : int = aten::size(%deltas.3, %300), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %302 : Long(device=cpu) = prim::NumToTensor(%301), scope: __module.model/__module.model.model.proposal_generator
                    %303 : int = aten::Int(%302), scope: __module.model/__module.model.model.proposal_generator
                    %304 : int[] = prim::ListConstruct(%299, %303), scope: __module.model/__module.model.model.proposal_generator
                    %proposals_i.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_boxes.1, %304), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %306 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:532:0
                    %307 : int[] = prim::ListConstruct(%74, %306, %85), scope: __module.model/__module.model.model.proposal_generator
                    %proposals_i : Float(1, 52920, 4, strides=[211680, 4, 1], requires_grad=0, device=cpu) = aten::view(%proposals_i.1, %307), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\rpn.py:532:0
                    %309 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %310 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %311 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %312 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %313 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %314 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::arange(%309, %310, %311, %312, %313), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:71:0
                    %315 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator
                    %batch_idx : Tensor = prim::CallFunction(%315, %314, %proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %320 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:73:0
                    %321 : int = aten::size(%logits_i, %320), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:73:0
                    %Hi_Wi_A : Long(device=cpu) = prim::NumToTensor(%321), scope: __module.model/__module.model.model.proposal_generator
                    %323 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %324 : int = prim::Constant[value=6000](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:75:0
                    %num_proposals_i : Long(requires_grad=0, device=cpu) = aten::clamp(%Hi_Wi_A, %323, %324), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:75:0
                    %326 : int = aten::Int(%num_proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %327 : int = aten::Int(%num_proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %328 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %329 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %330 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %topk_scores : Float(1, 6000, strides=[6000, 1], requires_grad=0, device=cpu), %topk_idx : Long(1, 6000, strides=[6000, 1], requires_grad=0, device=cpu) = aten::topk(%logits_i, %327, %328, %329, %330), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:79:0
                    %333 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %334 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %335 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %336 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %337 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::slice(%batch_idx, %333, %334, %335, %336), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %338 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %339 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%337, %338), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %340 : Tensor?[] = prim::ListConstruct(%339, %topk_idx), scope: __module.model/__module.model.model.proposal_generator
                    %topk_proposals : Float(1, 6000, 4, strides=[24000, 4, 1], requires_grad=0, device=cpu) = aten::index(%proposals_i, %340), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:82:0
                    %342 : int[] = prim::ListConstruct(%326), scope: __module.model/__module.model.model.proposal_generator
                    %343 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %344 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %345 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %346 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %347 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %348 : Long(6000, strides=[1], requires_grad=0, device=cpu) = aten::full(%342, %343, %344, %345, %346, %347), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:88:0
                    %349 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator
                    %level_ids : Tensor = prim::CallFunction(%349, %348, %proposals_i), scope: __module.model/__module.model.model.proposal_generator
                    %351 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %352 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %tensor.5 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::select(%topk_proposals, %351, %352), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:101:0
                    %354 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %355 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %356 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %357 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.7 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.5, %354, %355, %356, %357), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %364 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %365 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %scores_per_img.1 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::select(%topk_scores, %364, %365), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:102:0
                    %376 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:704:0
                    %377 : Tensor[] = aten::unbind(%image_size, %376), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:704:0
                    %h.1 : Long(requires_grad=0, device=cpu), %w.1 : Long(requires_grad=0, device=cpu) = prim::ListUnpack(%377), scope: __module.model/__module.model.model.proposal_generator
                    %380 : Scalar = aten::ScalarImplicit(%h.1), scope: __module.model/__module.model.model.proposal_generator
                    %381 : Scalar = aten::ScalarImplicit(%w.1), scope: __module.model/__module.model.model.proposal_generator
                    %382 : Scalar = aten::ScalarImplicit(%h.1), scope: __module.model/__module.model.model.proposal_generator
                    %383 : Scalar = aten::ScalarImplicit(%w.1), scope: __module.model/__module.model.model.proposal_generator
                    %384 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %385 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %386 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %387 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %388 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %384, %385, %386, %387), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %389 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %390 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %391 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%388, %389, %390), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %392 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %x1.3 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%391, %392, %383), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %394 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %395 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %396 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %397 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %398 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %394, %395, %396, %397), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %399 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %400 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %401 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%398, %399, %400), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %402 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %y1.3 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%401, %402, %382), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %404 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %405 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %406 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %407 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %408 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %404, %405, %406, %407), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %409 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %410 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %411 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%408, %409, %410), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %412 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %x2.3 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%411, %412, %381), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %414 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %415 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %416 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %417 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %418 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %414, %415, %416, %417), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %419 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %420 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %421 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%418, %419, %420), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %422 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %y2.3 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%421, %422, %380), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %424 : Tensor[] = prim::ListConstruct(%x1.3, %y1.3, %x2.3, %y2.3), scope: __module.model/__module.model.model.proposal_generator
                    %425 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %box : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%424, %425), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %427 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %428 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %429 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %430 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %431 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %427, %428, %429, %430), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %432 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %433 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %434 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%431, %432, %433), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %435 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %436 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %437 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %438 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %439 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %435, %436, %437, %438), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %440 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %441 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %442 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%439, %440, %441), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %443 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %widths.3 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::sub(%434, %442, %443), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:210:0
                    %445 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %446 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %447 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %448 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %449 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %445, %446, %447, %448), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %450 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %451 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %452 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%449, %450, %451), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %453 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %454 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %455 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %456 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %457 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%box, %453, %454, %455, %456), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %458 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %459 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %460 : Float(6000, strides=[4], requires_grad=0, device=cpu) = aten::select(%457, %458, %459), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %461 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %heights.3 : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::sub(%452, %460, %461), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:211:0
                    %463 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %464 : Bool(6000, strides=[1], requires_grad=0, device=cpu) = aten::gt(%widths.3, %463), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %465 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %466 : Bool(6000, strides=[1], requires_grad=0, device=cpu) = aten::gt(%heights.3, %465), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %item.1 : Bool(6000, strides=[1], requires_grad=0, device=cpu) = aten::__and__(%464, %466), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:212:0
                    %468 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.9 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%box, %468), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:235:0
                    %470 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %471 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %472 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %473 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.11 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.9, %470, %471, %472, %473), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %480 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %scores_per_img : Float(6000, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores_per_img.1, %480), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:119:0
                    %482 : Tensor?[] = prim::ListConstruct(%item.1), scope: __module.model/__module.model.model.proposal_generator
                    %483 : Long(6000, strides=[1], requires_grad=0, device=cpu) = aten::index(%level_ids, %482), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:119:0
                    %492 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %493 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %494 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %495 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %496 : Float(6000, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.11, %492, %493, %494, %495), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %497 : float = prim::Constant[value=0.69999999999999996](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\jit\_trace.py:1121:0
                    %498 : Function = prim::Constant[name="_batched_nms_coordinate_trick"](), scope: __module.model/__module.model.model.proposal_generator
                    %keep.1 : Tensor = prim::CallFunction(%498, %496, %scores_per_img, %483, %497), scope: __module.model/__module.model.model.proposal_generator
                    %500 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %501 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %502 : int = prim::Constant[value=30](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %503 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %item : Long(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%keep.1, %500, %501, %502, %503), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\proposal_generator\proposal_utils.py:129:0
                    %505 : Tensor?[] = prim::ListConstruct(%item), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.13 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%496, %505), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:235:0
                    %507 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %508 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %509 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %510 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator
                    %tensor.15 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.13, %507, %508, %509, %510), scope: __module.model/__module.model.model.proposal_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    return (%tensor.15)
              
                }
              }
              submodules {
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    rpn_feature = <__torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule object at 0000020DCBAACA10>
                    rpn_regressor = <__torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor object at 0000020DCBAC5490>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested object at 0000020DCBAC4B10>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested object at 0000020DCBAC4490>
                  }
                  methods {
                    method forward {
                      graph(%self.379 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass,
                            %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                        %dequant_stubs.3 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.379)
                        %rpn_regressor : __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor = prim::GetAttr[name="rpn_regressor"](%self.379)
                        %rpn_feature : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule = prim::GetAttr[name="rpn_feature"](%self.379)
                        %quant_stubs.3 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.379)
                        %15 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.3, %1)
                        %16 : Tensor = prim::CallMethod[name="forward"](%rpn_feature, %15)
                        %17 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%rpn_regressor, %16)
                        %9 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), %10 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%17)
                        %18 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%dequant_stubs.3, %9, %10)
                        %12 : Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), %13 : Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = prim::TupleUnpack(%18)
                        %14 : (Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%12, %13)
                        return (%14)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_223.Sequential object at 0000020DCBAAC890>
                      }
                      methods {
                        method forward {
                          graph(%self.385 : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule,
                                %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                            %_0.9 : __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential = prim::GetAttr[name="0"](%self.385)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.9, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock object at 0000020DCB241980>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock object at 0000020D9D0D58D0>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock object at 0000020DCBAAC190>
                          }
                          methods {
                            method forward {
                              graph(%self.387 : __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %fbnetv2_0_2.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.387)
                                %fbnetv2_0_1.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.387)
                                %fbnetv2_0_0.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.387)
                                %8 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.3, %1)
                                %9 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.3, %8)
                                %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2.1, %9)
                                return (%10)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu object at 0000020DCB91DD90>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu object at 0000020DCB8FFE10>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu object at 0000020DCB240F00>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd object at 0000020DCB241500>
                              }
                              methods {
                                method forward {
                                  graph(%self.389 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %res_conn.23 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd = prim::GetAttr[name="res_conn"](%self.389)
                                    %pwl.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu = prim::GetAttr[name="pwl"](%self.389)
                                    %dw.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu = prim::GetAttr[name="dw"](%self.389)
                                    %pw.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu = prim::GetAttr[name="pw"](%self.389)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.29, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.39, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.31, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.23, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d object at 0000020DCB8FEE10>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_185.Identity object at 0000020DCB91DB10>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_186.Identity object at 0000020DCB91E810>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.391 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %relu.31 : __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity = prim::GetAttr[name="relu"](%self.391)
                                        %bn.61 : __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity = prim::GetAttr[name="bn"](%self.391)
                                        %conv.91 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d = prim::GetAttr[name="conv"](%self.391)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.91, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.61)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.31)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 352
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB91E790>
                                        scale = 0.015536025166511536
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.393 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
                                                %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.91 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.393)
                                            %15 : float = prim::Constant[value=0.015536025166511536](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.93 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.91, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.93)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.395 : __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.397 : __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d object at 0000020DCB91D310>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.399 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %conv.93 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d = prim::GetAttr[name="conv"](%self.399)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.93, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 352
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 352
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB900090>
                                        scale = 0.0034295436926186085
                                        zero_point = 65
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.401 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
                                                %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.93 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.401)
                                            %15 : float = prim::Constant[value=0.0034295436926186085](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.95 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.93, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.95)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d object at 0000020DCB8FFF10>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_191.Identity object at 0000020DCB240800>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.403 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %bn.63 : __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity = prim::GetAttr[name="bn"](%self.403)
                                        %conv.95 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d = prim::GetAttr[name="conv"](%self.403)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.95, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.63)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 88
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB928190>
                                        scale = 0.04224729910492897
                                        zero_point = 68
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.405 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
                                                %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.95 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.405)
                                            %15 : float = prim::Constant[value=0.04224729910492897](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.25 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.95, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.25)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.407 : __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional object at 0000020DCB241400>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.409 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %add_func.23 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional = prim::GetAttr[name="add_func"](%self.409)
                                        %activation_post_process.23 : __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity = prim::GetAttr[name="activation_post_process"](%add_func.23)
                                        %5 : float = prim::Constant[value=0.10697615891695023](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=66](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.97 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.23)
                                        return (%input.97)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_193.Identity object at 0000020DCB240F80>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.411 : __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu object at 0000020DCB8FF990>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu object at 0000020DBEC10B30>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu object at 0000020D9D0D23D0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd object at 0000020D9D0D51D0>
                              }
                              methods {
                                method forward {
                                  graph(%self.413 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %res_conn.25 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd = prim::GetAttr[name="res_conn"](%self.413)
                                    %pwl.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu = prim::GetAttr[name="pwl"](%self.413)
                                    %dw.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu = prim::GetAttr[name="dw"](%self.413)
                                    %pw.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu = prim::GetAttr[name="pw"](%self.413)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.31, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.41, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.33, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.25, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d object at 0000020DCB244000>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_198.Identity object at 0000020DCB8FFC90>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_199.Identity object at 0000020DCB8FF810>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.415 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %relu.33 : __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity = prim::GetAttr[name="relu"](%self.415)
                                        %bn.65 : __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity = prim::GetAttr[name="bn"](%self.415)
                                        %conv.97 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d = prim::GetAttr[name="conv"](%self.415)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.97, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.65)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.33)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 352
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB8FFD90>
                                        scale = 0.017396926879882812
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.417 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
                                                %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.97 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.417)
                                            %15 : float = prim::Constant[value=0.017396926879882812](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.99 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.97, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.99)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.419 : __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.421 : __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d object at 0000020DCB900A10>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.423 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %conv.99 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d = prim::GetAttr[name="conv"](%self.423)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.99, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 352
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 352
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB220A00>
                                        scale = 0.0046610306017100811
                                        zero_point = 56
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.425 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
                                                %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.99 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.425)
                                            %15 : float = prim::Constant[value=0.0046610306017100811](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=56](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.101 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.99, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.101)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d object at 0000020DBEC115B0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_204.Identity object at 0000020D9D0D14D0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.427 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %bn.67 : __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity = prim::GetAttr[name="bn"](%self.427)
                                        %conv.101 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d = prim::GetAttr[name="conv"](%self.427)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.101, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.67)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 88
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB90E390>
                                        scale = 0.043050095438957214
                                        zero_point = 64
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.429 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
                                                %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.101 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.429)
                                            %15 : float = prim::Constant[value=0.043050095438957214](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.27 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.101, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.27)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.431 : __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional object at 0000020D9D0D4550>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.433 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %add_func.25 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional = prim::GetAttr[name="add_func"](%self.433)
                                        %activation_post_process.25 : __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity = prim::GetAttr[name="activation_post_process"](%add_func.25)
                                        %5 : float = prim::Constant[value=0.12192749232053757](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.103 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.25)
                                        return (%input.103)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_206.Identity object at 0000020D9D0D3850>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.435 : __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu object at 0000020DCBA96290>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu object at 0000020DCBAA0290>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu object at 0000020DCBAACC90>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd object at 0000020DCBAAC010>
                              }
                              methods {
                                method forward {
                                  graph(%self.437 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock,
                                        %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %res_conn.27 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd = prim::GetAttr[name="res_conn"](%self.437)
                                    %pwl.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu = prim::GetAttr[name="pwl"](%self.437)
                                    %dw.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu = prim::GetAttr[name="dw"](%self.437)
                                    %pw.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu = prim::GetAttr[name="pw"](%self.437)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.33, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.43, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.35, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.27, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d object at 0000020D9D0D54D0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_211.Identity object at 0000020DCBA96F90>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_212.Identity object at 0000020DCBA96C90>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.439 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %relu.35 : __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity = prim::GetAttr[name="relu"](%self.439)
                                        %bn.69 : __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity = prim::GetAttr[name="bn"](%self.439)
                                        %conv.103 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d = prim::GetAttr[name="conv"](%self.439)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.103, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.69)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.35)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 352
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB20D280>
                                        scale = 0.016644317656755447
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.441 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
                                                %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                            %_packed_params.103 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.441)
                                            %15 : float = prim::Constant[value=0.016644317656755447](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.105 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.103, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.105)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.443 : __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.445 : __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d object at 0000020DCBA96310>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.447 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %conv.105 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d = prim::GetAttr[name="conv"](%self.447)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.105, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 352
                                        kernel_size = (5, 5)
                                        stride = (1, 1)
                                        padding = (2, 2)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 352
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAA0490>
                                        scale = 0.0051714531145989895
                                        zero_point = 76
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.449 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
                                                %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.105 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.449)
                                            %15 : float = prim::Constant[value=0.0051714531145989895](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=76](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.107 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.105, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.107)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d object at 0000020DCBAA1490>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_217.Identity object at 0000020DCBAAD410>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.451 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu,
                                            %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                        %bn.71 : __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity = prim::GetAttr[name="bn"](%self.451)
                                        %conv.107 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d = prim::GetAttr[name="conv"](%self.451)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.107, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.71)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 88
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAAD910>
                                        scale = 0.057626005262136459
                                        zero_point = 68
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.453 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
                                                %1 : QUInt8(1, 352, 42, 84, strides=[1241856, 1, 29568, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.107 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.453)
                                            %15 : float = prim::Constant[value=0.057626005262136459](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=68](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.29 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.107, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.29)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.455 : __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional object at 0000020DCBAACD90>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.457 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd,
                                            %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                                            %2 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                        %add_func.27 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional = prim::GetAttr[name="add_func"](%self.457)
                                        %activation_post_process.27 : __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity = prim::GetAttr[name="activation_post_process"](%add_func.27)
                                        %5 : float = prim::Constant[value=0.13029468059539795](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.109 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_feature/__module.model.model.proposal_generator.rpn_head.rpn_feature.0/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2/__module.model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.27)
                                        return (%input.109)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_219.Identity object at 0000020DCBAABA90>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.459 : __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        cls_logits = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d object at 0000020DCBAAEA10>
                        bbox_pred = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d object at 0000020DCBAB8290>
                      }
                      methods {
                        method forward {
                          graph(%self.461 : __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor,
                                %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                            %bbox_pred.1 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d = prim::GetAttr[name="bbox_pred"](%self.461)
                            %cls_logits : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d = prim::GetAttr[name="cls_logits"](%self.461)
                            %7 : Tensor = prim::CallMethod[name="forward"](%cls_logits, %1)
                            %8 : Tensor = prim::CallMethod[name="forward"](%bbox_pred.1, %1)
                            %6 : (QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%7, %8)
                            return (%6)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 88
                            out_channels = 15
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAB7F90>
                            scale = 0.1136840432882309
                            zero_point = 118
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                 = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.463 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %_packed_params.109 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.463)
                                %15 : float = prim::Constant[value=0.1136840432882309](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                %16 : int = prim::Constant[value=118](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                %Xq.3 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.109, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                return (%Xq.3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                        module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            in_channels = 88
                            out_channels = 60
                            kernel_size = (1, 1)
                            stride = (1, 1)
                            padding = (0, 0)
                            dilation = (1, 1)
                            transposed = False
                            output_padding = (0, 0)
                            groups = 1
                            padding_mode = zeros
                            _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAC4690>
                            scale = 0.024111820384860039
                            zero_point = 94
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d):
                                %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                %groups : int = prim::GetAttr[name="groups"](%self)
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %scale : float = prim::GetAttr[name="scale"](%self)
                                %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                return (%19)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
                                    %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="in_channels"](%self, %4)
                                %7 : int = prim::TupleIndex(%state.1, %6)
                                 = prim::SetAttr[name="out_channels"](%self, %7)
                                %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                 = prim::SetAttr[name="kernel_size"](%self, %10)
                                %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                 = prim::SetAttr[name="stride"](%self, %13)
                                %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                 = prim::SetAttr[name="padding"](%self, %16)
                                %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                 = prim::SetAttr[name="dilation"](%self, %19)
                                %22 : bool = prim::TupleIndex(%state.1, %21)
                                 = prim::SetAttr[name="transposed"](%self, %22)
                                %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                 = prim::SetAttr[name="output_padding"](%self, %25)
                                %28 : int = prim::TupleIndex(%state.1, %27)
                                 = prim::SetAttr[name="groups"](%self, %28)
                                %31 : str = prim::TupleIndex(%state.1, %30)
                                 = prim::SetAttr[name="padding_mode"](%self, %31)
                                %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                %41 : float = prim::TupleIndex(%state.1, %40)
                                 = prim::SetAttr[name="scale"](%self, %41)
                                %44 : int = prim::TupleIndex(%state.1, %43)
                                 = prim::SetAttr[name="zero_point"](%self, %44)
                                %47 : bool = prim::TupleIndex(%state.1, %46)
                                 = prim::SetAttr[name="training"](%self, %47)
                                return (%48)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d):
                                %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                return (%2)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
                                    %w.1 : Tensor,
                                    %b.1 : Tensor?):
                                %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                 = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                  block0():
                                    %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                    %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                    %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                    %15 : int[] = prim::ListConstruct(%13, %14)
                                    %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                    %18 : int[] = prim::ListConstruct(%16, %17)
                                    %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                    %21 : int[] = prim::ListConstruct(%19, %20)
                                    %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                     = prim::SetAttr[name="_packed_params"](%self, %22)
                                    -> ()
                                  block1():
                                    %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                    %27 : int[] = prim::ListConstruct(%26, %26)
                                    %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                    %groups : int = prim::GetAttr[name="groups"](%self)
                                    %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                    %32 : int[] = prim::ListConstruct(%30, %31)
                                    %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                    %35 : int[] = prim::ListConstruct(%33, %34)
                                    %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                     = prim::SetAttr[name="_packed_params"](%self, %36)
                                    -> ()
                                return (%37)
                          
                            }
                            method forward {
                              graph(%self.465 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
                                    %1 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %_packed_params.111 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.465)
                                %15 : float = prim::Constant[value=0.024111820384860039](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                %16 : int = prim::Constant[value=94](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                %Xq.5 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.111, %15, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.rpn_regressor/__module.model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                return (%Xq.5)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList object at 0000020DCBAC3C90>
                      }
                      methods {
                        method forward {
                          graph(%self.381 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested,
                                %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                            %stubs.11 : __torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList = prim::GetAttr[name="stubs"](%self.381)
                            %_0.7 : __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize = prim::GetAttr[name="0"](%stubs.11)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.7, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize object at 0000020DCBAC5790>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.383 : __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize,
                                        %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.089796319603919983](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=70](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %input.91 : QUInt8(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.quant_stubs/__module.model.model.proposal_generator.rpn_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%input.91)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList object at 0000020DCBAC4010>
                      }
                      methods {
                        method forward {
                          graph(%self.467 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested,
                                %1 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu),
                                %2 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)):
                            %stubs.15 : __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList = prim::GetAttr[name="stubs"](%self.467)
                            %_1.3 : __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize = prim::GetAttr[name="1"](%stubs.15)
                            %stubs.13 : __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList = prim::GetAttr[name="stubs"](%self.467)
                            %_0.11 : __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize = prim::GetAttr[name="0"](%stubs.13)
                            %10 : Tensor = prim::CallMethod[name="forward"](%_0.11, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%_1.3, %2)
                            %9 : (Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu), Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)) = prim::TupleConstruct(%10, %11)
                            return (%9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize object at 0000020DCBAC5510>
                            1 = <__torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize object at 0000020DCBAC3E10>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.469 : __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize,
                                        %1 : QUInt8(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu)):
                                    %score : Float(1, 15, 42, 84, strides=[52920, 1, 1260, 15], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.dequant_stubs/__module.model.model.proposal_generator.rpn_head.dequant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%score)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.471 : __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize,
                                        %1 : QUInt8(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu)):
                                    %x.31 : Float(1, 60, 42, 84, strides=[211680, 1, 5040, 60], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.rpn_head/__module.model.model.proposal_generator.rpn_head.dequant_stubs/__module.model.model.proposal_generator.rpn_head.dequant_stubs.stubs.1 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%x.31)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    cell_anchors = <__torch__.detectron2.modeling.anchor_generator.BufferList object at 0000020DCBAC6B10>
                  }
                  methods {
                    method forward {
                      graph(%self.377 : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
                            %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                        %cell_anchors : __torch__.detectron2.modeling.anchor_generator.BufferList = prim::GetAttr[name="cell_anchors"](%self.377)
                        %_0.5 : Tensor = prim::GetAttr[name="0"](%cell_anchors)
                        %10 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %11 : int = aten::size(%1, %10), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %grid_height : Long(device=cpu) = prim::NumToTensor(%11), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %13 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %14 : int = aten::size(%1, %13), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:229:0
                        %grid_width : Long(device=cpu) = prim::NumToTensor(%14), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %16 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %17 : Long(requires_grad=0, device=cpu) = aten::mul(%grid_width, %16), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %18 : Scalar = aten::ScalarImplicit(%17), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %19 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %20 : int = prim::Constant[value=16](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %21 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %22 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %23 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %24 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %25 : Float(84, strides=[1], requires_grad=0, device=cpu) = aten::arange(%19, %18, %20, %21, %22, %23, %24), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:44:0
                        %26 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %27 : Tensor = prim::CallFunction(%26, %25, %_0.5), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %28 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %29 : Long(requires_grad=0, device=cpu) = aten::mul(%grid_height, %28), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %30 : Scalar = aten::ScalarImplicit(%29), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %31 : float = prim::Constant[value=0.](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %32 : int = prim::Constant[value=16](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %33 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %34 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %35 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %36 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %37 : Float(42, strides=[1], requires_grad=0, device=cpu) = aten::arange(%31, %30, %32, %33, %34, %35, %36), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:48:0
                        %38 : Function = prim::Constant[name="move_device_like"](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %39 : Tensor = prim::CallFunction(%38, %37, %_0.5), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %40 : Tensor[] = prim::ListConstruct(%39, %27), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %41 : Tensor[] = aten::meshgrid(%40), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\functional.py:568:0
                        %shift_y.1 : Float(42, 84, strides=[1, 0], requires_grad=0, device=cpu), %shift_x.1 : Float(42, 84, strides=[0, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%41), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %44 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:53:0
                        %45 : int[] = prim::ListConstruct(%44), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %shift_x : Float(3528, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%shift_x.1, %45), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:53:0
                        %47 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:54:0
                        %48 : int[] = prim::ListConstruct(%47), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %shift_y : Float(3528, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%shift_y.1, %48), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:54:0
                        %50 : Tensor[] = prim::ListConstruct(%shift_x, %shift_y, %shift_x, %shift_y), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %51 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:175:0
                        %shifts : Float(3528, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%50, %51), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:175:0
                        %53 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %54 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %55 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %56 : int[] = prim::ListConstruct(%53, %54, %55), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %57 : Float(3528, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::view(%shifts, %56), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %58 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %59 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %60 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %61 : int[] = prim::ListConstruct(%58, %59, %60), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %62 : Float(1, 15, 4, strides=[60, 4, 1], requires_grad=0, device=cpu) = aten::view(%_0.5, %61), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %63 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %64 : Float(3528, 15, 4, strides=[60, 4, 1], requires_grad=0, device=cpu) = aten::add(%57, %62, %63), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %65 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %66 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %67 : int[] = prim::ListConstruct(%65, %66), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %tensor.1 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%64, %67), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\anchor_generator.py:177:0
                        %69 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %70 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %71 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        %72 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator
                        %tensor.3 : Float(52920, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.1, %69, %70, %71, %72), scope: __module.model/__module.model.model.proposal_generator/__module.model.model.proposal_generator.anchor_generator # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                        return (%tensor.3)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.modeling.anchor_generator.BufferList {
                      parameters {
                      }
                      attributes {
                        0 = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads {
              parameters {
              }
              attributes {
                training = False
                _is_full_backward_hook = None
                box_pooler = <__torch__.detectron2.modeling.poolers.ROIPooler object at 0000020DCBAC6990>
                box_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass object at 0000020DCB8F6B90>
                box_predictor = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass object at 0000020DCB924E10>
                keypoint_pooler = <__torch__.detectron2.modeling.poolers.___torch_mangle_302.ROIPooler object at 0000020DCB925E90>
                keypoint_head = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_377.QuantWrapSubClass object at 0000020DCBAC8690>
              }
              methods {
                method forward {
                  graph(%self.473 : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                        %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                        %2 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu),
                        %image_size : Long(2, strides=[1], requires_grad=0, device=cpu)):
                    %keypoint_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_377.QuantWrapSubClass = prim::GetAttr[name="keypoint_head"](%self.473)
                    %keypoint_pooler : __torch__.detectron2.modeling.poolers.___torch_mangle_302.ROIPooler = prim::GetAttr[name="keypoint_pooler"](%self.473)
                    %box_predictor : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass = prim::GetAttr[name="box_predictor"](%self.473)
                    %box_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass = prim::GetAttr[name="box_head"](%self.473)
                    %box_pooler : __torch__.detectron2.modeling.poolers.ROIPooler = prim::GetAttr[name="box_pooler"](%self.473)
                    %464 : Tensor = prim::CallMethod[name="forward"](%box_pooler, %1, %2)
                    %465 : Tensor = prim::CallMethod[name="forward"](%box_head, %464)
                    %466 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%box_predictor, %465)
                    %12 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu), %13 : Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%466)
                    %14 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %15 : int = aten::size(%2, %14), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %16 : Long(device=cpu) = prim::NumToTensor(%15), scope: __module.model/__module.model.model.roi_heads
                    %17 : int = aten::Int(%16), scope: __module.model/__module.model.model.roi_heads
                    %21 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %22 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %23 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %24 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %deltas : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%12, %21, %22, %23, %24), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:88:0
                    %26 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %27 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %28 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %29 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %boxes.7 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%2, %26, %27, %28, %29), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:89:0
                    %31 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %32 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %33 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %34 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %35 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.7, %31, %32, %33, %34), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %36 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %37 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %38 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%35, %36, %37), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %39 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %40 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %41 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %42 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %43 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.7, %39, %40, %41, %42), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %44 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %45 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %46 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%43, %44, %45), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %47 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %widths : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::sub(%38, %46, %47), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:91:0
                    %49 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %50 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %51 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %52 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %53 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.7, %49, %50, %51, %52), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %54 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %55 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %56 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%53, %54, %55), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %57 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %58 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %59 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %60 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %61 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.7, %57, %58, %59, %60), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %62 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %63 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %64 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%61, %62, %63), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %65 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %heights : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::sub(%56, %64, %65), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:92:0
                    %67 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %68 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %69 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %70 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %71 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.7, %67, %68, %69, %70), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %72 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %73 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %74 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%71, %72, %73), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %75 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %76 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::mul(%widths, %75), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %77 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %ctr_x : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::add(%74, %76, %77), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:93:0
                    %79 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %80 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %81 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %82 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %83 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%boxes.7, %79, %80, %81, %82), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %84 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %85 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %86 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%83, %84, %85), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %87 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %88 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::mul(%heights, %87), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %89 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %ctr_y : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::add(%86, %88, %89), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:94:0
                    %91 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %92 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %93 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %94 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %95 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %91, %92, %93, %94), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %96 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %97 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %98 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %99 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %100 : Float(30, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%95, %96, %97, %98, %99), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %101 : Double(requires_grad=0, device=cpu) = prim::Constant[value={10}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %dx : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%100, %101), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:97:0
                    %103 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %104 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %105 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %106 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %107 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %103, %104, %105, %106), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %108 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %109 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %110 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %111 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %112 : Float(30, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%107, %108, %109, %110, %111), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %113 : Double(requires_grad=0, device=cpu) = prim::Constant[value={10}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %dy : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%112, %113), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:98:0
                    %115 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %116 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %117 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %118 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %119 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %115, %116, %117, %118), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %120 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %121 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %122 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %123 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %124 : Float(30, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%119, %120, %121, %122, %123), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %125 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %dw.5 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%124, %125), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:99:0
                    %127 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %128 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %129 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %130 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %131 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%deltas, %127, %128, %129, %130), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %133 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %134 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %135 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %136 : Float(30, 1, strides=[4, 4], requires_grad=0, device=cpu) = aten::slice(%131, %132, %133, %134, %135), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %137 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %dh.5 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::div(%136, %137), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:100:0
                    %139 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %140 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %dw.7 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dw.5, %139, %140), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:103:0
                    %142 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %143 : float = prim::Constant[value=4.1351665567423561](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %dh : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::clamp(%dh.5, %142, %143), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:104:0
                    %145 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %146 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %147 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %148 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %149 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths, %145, %146, %147, %148), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %151 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%149, %150), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %152 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dx, %151), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %153 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %154 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %155 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %156 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %157 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_x, %153, %154, %155, %156), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %158 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %159 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%157, %158), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %160 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %pred_ctr_x : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%152, %159, %160), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:106:0
                    %162 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %163 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %164 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %166 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights, %162, %163, %164, %165), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %167 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %168 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%166, %167), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %169 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%dy, %168), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %170 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %171 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %172 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %173 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %174 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%ctr_y, %170, %171, %172, %173), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %175 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %176 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%174, %175), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %177 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %pred_ctr_y : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%169, %176, %177), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:107:0
                    %179 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dw.7), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %180 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %181 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %182 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %183 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %184 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%widths, %180, %181, %182, %183), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %185 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %186 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%184, %185), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %pred_w : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%179, %186), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:108:0
                    %188 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::exp(%dh), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %189 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %190 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %191 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %192 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %193 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::slice(%heights, %189, %190, %191, %192), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %194 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %195 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%193, %194), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %pred_h : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%188, %195), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:109:0
                    %197 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %198 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w, %197), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %199 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %x1.5 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_x, %198, %199), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:111:0
                    %201 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %202 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h, %201), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %203 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %y1.5 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sub(%pred_ctr_y, %202, %203), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:112:0
                    %205 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %206 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_w, %205), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %207 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %x2.5 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_x, %206, %207), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:113:0
                    %209 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.5}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %210 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::mul(%pred_h, %209), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %211 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %y2.5 : Float(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::add(%pred_ctr_y, %210, %211), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:114:0
                    %213 : Tensor[] = prim::ListConstruct(%x1.5, %y1.5, %x2.5, %y2.5), scope: __module.model/__module.model.model.roi_heads
                    %214 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %pred_boxes : Float(30, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::stack(%213, %214), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:115:0
                    %216 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %217 : int = aten::size(%deltas, %216), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %218 : Long(device=cpu) = prim::NumToTensor(%217), scope: __module.model/__module.model.model.roi_heads
                    %219 : int = aten::Int(%218), scope: __module.model/__module.model.model.roi_heads
                    %220 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %221 : int = aten::size(%deltas, %220), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %222 : Long(device=cpu) = prim::NumToTensor(%221), scope: __module.model/__module.model.model.roi_heads
                    %223 : int = aten::Int(%222), scope: __module.model/__module.model.model.roi_heads
                    %224 : int[] = prim::ListConstruct(%219, %223), scope: __module.model/__module.model.model.roi_heads
                    %225 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%pred_boxes, %224), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\box_regression.py:116:0
                    %226 : int[] = prim::ListConstruct(%17), scope: __module.model/__module.model.model.roi_heads
                    %227 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                    %228 : Tensor[] = aten::split_with_sizes(%225, %226, %227), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                    %boxes.9 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%228), scope: __module.model/__module.model.model.roi_heads
                    %230 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %231 : int = aten::size(%boxes.7, %230), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                    %232 : Long(device=cpu) = prim::NumToTensor(%231), scope: __module.model/__module.model.model.roi_heads
                    %233 : int = aten::Int(%232), scope: __module.model/__module.model.model.roi_heads
                    %237 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:1818:0
                    %238 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %239 : Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::softmax(%13, %237, %238), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:1818:0
                    %240 : int[] = prim::ListConstruct(%233), scope: __module.model/__module.model.model.roi_heads
                    %241 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                    %242 : Tensor[] = aten::split_with_sizes(%239, %240, %241), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                    %scores.1 : Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%242), scope: __module.model/__module.model.model.roi_heads
                    %254 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %255 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %256 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %258 : Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::slice(%scores.1, %254, %255, %256, %257), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %259 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %260 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %261 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %262 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %scores.3 : Float(30, 1, strides=[2, 1], requires_grad=0, device=cpu) = aten::slice(%258, %259, %260, %261, %262), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:142:0
                    %267 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:143:0
                    %268 : int = aten::size(%boxes.9, %267), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:143:0
                    %269 : Long(device=cpu) = prim::NumToTensor(%268), scope: __module.model/__module.model.model.roi_heads
                    %270 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:647:0
                    %271 : str = prim::Constant[value="trunc"](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:647:0
                    %num_bbox_reg_classes : Long(requires_grad=0, device=cpu) = aten::div(%269, %270, %271), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:647:0
                    %273 : int = aten::Int(%num_bbox_reg_classes), scope: __module.model/__module.model.model.roi_heads
                    %274 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %275 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %276 : int[] = prim::ListConstruct(%274, %275), scope: __module.model/__module.model.model.roi_heads
                    %tensor.17 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%boxes.9, %276), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:145:0
                    %278 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %279 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %280 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %281 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor.19 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.17, %278, %279, %280, %281), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %290 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:704:0
                    %291 : Tensor[] = aten::unbind(%image_size, %290), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:704:0
                    %h : Long(requires_grad=0, device=cpu), %w : Long(requires_grad=0, device=cpu) = prim::ListUnpack(%291), scope: __module.model/__module.model.model.roi_heads
                    %294 : Scalar = aten::ScalarImplicit(%h), scope: __module.model/__module.model.model.roi_heads
                    %295 : Scalar = aten::ScalarImplicit(%w), scope: __module.model/__module.model.model.roi_heads
                    %296 : Scalar = aten::ScalarImplicit(%h), scope: __module.model/__module.model.model.roi_heads
                    %297 : Scalar = aten::ScalarImplicit(%w), scope: __module.model/__module.model.model.roi_heads
                    %298 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %299 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %300 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %301 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %302 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %298, %299, %300, %301), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %303 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %304 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %305 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%302, %303, %304), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %306 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %x1 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%305, %306, %297), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:193:0
                    %308 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %309 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %310 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %311 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %312 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %308, %309, %310, %311), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %313 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %314 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %315 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%312, %313, %314), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %316 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %y1 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%315, %316, %296), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:194:0
                    %318 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %319 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %320 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %321 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %322 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %318, %319, %320, %321), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %323 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %324 : int = prim::Constant[value=2](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %325 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%322, %323, %324), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %326 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %x2 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%325, %326, %295), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:195:0
                    %328 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %329 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %330 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %331 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %332 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.19, %328, %329, %330, %331), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %333 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %334 : int = prim::Constant[value=3](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %335 : Float(30, strides=[4], requires_grad=0, device=cpu) = aten::select(%332, %333, %334), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %336 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %y2 : Float(30, strides=[1], requires_grad=0, device=cpu) = aten::clamp(%335, %336, %294), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:196:0
                    %338 : Tensor[] = prim::ListConstruct(%x1, %y1, %x2, %y2), scope: __module.model/__module.model.model.roi_heads
                    %339 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %340 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::stack(%338, %339), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:197:0
                    %341 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %342 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %343 : int[] = prim::ListConstruct(%341, %273, %342), scope: __module.model/__module.model.model.roi_heads
                    %boxes.11 : Float(30, 1, 4, strides=[4, 4, 1], requires_grad=0, device=cpu) = aten::view(%340, %343), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:147:0
                    %345 : float = prim::Constant[value=0.050000000000000003](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:151:0
                    %filter_mask : Bool(30, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::gt(%scores.3, %345), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:151:0
                    %filter_inds.1 : Long(0, 2, strides=[1, 0], requires_grad=0, device=cpu) = aten::nonzero(%filter_mask), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:154:0
                    %350 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %351 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %352 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %353 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %354 : Long(0, 2, strides=[1, 0], requires_grad=0, device=cpu) = aten::slice(%filter_inds.1, %350, %351, %352, %353), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %355 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %356 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %357 : Long(0, strides=[1], requires_grad=0, device=cpu) = aten::select(%354, %355, %356), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %358 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %359 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %360 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::select(%boxes.11, %358, %359), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %361 : Tensor?[] = prim::ListConstruct(%357), scope: __module.model/__module.model.model.roi_heads
                    %boxes.13 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%360, %361), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:156:0
                    %363 : Tensor?[] = prim::ListConstruct(%filter_mask), scope: __module.model/__module.model.model.roi_heads
                    %scores : Float(0, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores.3, %363), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:159:0
                    %365 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %366 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %367 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %368 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %369 : Long(0, 2, strides=[1, 0], requires_grad=0, device=cpu) = aten::slice(%filter_inds.1, %365, %366, %367, %368), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %370 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %371 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %372 : Long(0, strides=[1], requires_grad=0, device=cpu) = aten::select(%369, %370, %371), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:162:0
                    %381 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %382 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %383 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %384 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %boxes.15 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%boxes.13, %381, %382, %383, %384), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\nms.py:20:0
                    %386 : float = prim::Constant[value=0.5](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\jit\_trace.py:1121:0
                    %387 : Function = prim::Constant[name="_batched_nms_coordinate_trick"](), scope: __module.model/__module.model.model.roi_heads
                    %keep.3 : Tensor = prim::CallFunction(%387, %boxes.15, %scores, %372, %386), scope: __module.model/__module.model.model.roi_heads
                    %389 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %390 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %391 : int = prim::Constant[value=100](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %392 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %keep : Long(0, strides=[1], requires_grad=0, device=cpu) = aten::slice(%keep.3, %389, %390, %391, %392), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:164:0
                    %394 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %tensor.21 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::index(%boxes.15, %394), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %396 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %397 : Float(0, strides=[1], requires_grad=0, device=cpu) = aten::index(%scores, %396), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %398 : Tensor?[] = prim::ListConstruct(%keep), scope: __module.model/__module.model.model.roi_heads
                    %filter_inds : Long(0, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::index(%filter_inds.1, %398), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:165:0
                    %400 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %401 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %402 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %403 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor.23 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%tensor.21, %400, %401, %402, %403), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:150:0
                    %405 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %406 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %407 : int[] = prim::ListConstruct(%405, %406), scope: __module.model/__module.model.model.roi_heads
                    %408 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::reshape(%tensor.23, %407), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %409 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %410 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %411 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %412 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads
                    %tensor : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::to(%408, %409, %410, %411, %412), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:154:0
                    %434 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %435 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %436 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %437 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %438 : Long(0, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::slice(%filter_inds, %434, %435, %436, %437), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %439 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %440 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %441 : Long(0, strides=[2], requires_grad=0, device=cpu) = aten::select(%438, %439, %440), scope: __module.model/__module.model.model.roi_heads # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:170:0
                    %467 : Tensor = prim::CallMethod[name="forward"](%keypoint_pooler, %1, %tensor)
                    %468 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%keypoint_head, %467, %tensor)
                    %461 : Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), %462 : Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%468)
                    %463 : (Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu), Long(0, strides=[2], requires_grad=0, device=cpu), Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu), Float(0, strides=[1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%tensor, %441, %461, %462, %397)
                    return (%463)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.poolers.ROIPooler {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList object at 0000020DCBAC7090>
                  }
                  methods {
                    method forward {
                      graph(%self.475 : __torch__.detectron2.modeling.poolers.ROIPooler,
                            %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                            %2 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %level_poolers.1 : __torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList = prim::GetAttr[name="level_poolers"](%self.475)
                        %_0.13 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.1)
                        %10 : Tensor[] = prim::ListConstruct(%2), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %11 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\poolers.py:94:0
                        %12 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\poolers.py:94:0
                        %13 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %14 : int = aten::size(%2, %13), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %15 : Long(device=cpu) = prim::NumToTensor(%14), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %19 : Tensor[] = prim::ListConstruct(%15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %20 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
                        %21 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::stack(%19, %20), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
                        %22 : Function = prim::Constant[name="_convert_boxes_to_pooler_format"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %rois.1 : Tensor = prim::CallFunction(%22, %12, %21), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler
                        %25 : Tensor = prim::CallMethod[name="forward"](%_0.13, %rois.1, %1)
                        return (%25)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0000020DCBAC6D10>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.detectron2.layers.roi_align.ROIAlign {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.477 : __torch__.detectron2.layers.roi_align.ROIAlign,
                                    %rois.1 : Tensor,
                                    %2 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %8 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %9 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %10 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %11 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0
                                %boxes.5 : Float(30, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::to(%rois.1, %8, %9, %10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %18 : float = prim::Constant[value=0.0625](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %19 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %20 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %21 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %22 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %X.3 : Float(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu) = torchvision::roi_align(%2, %boxes.5, %18, %19, %20, %21, %22), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_pooler/__module.model.model.roi_heads.box_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                return (%X.3)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    roi_box_conv = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule object at 0000020DCB8F5C10>
                    avgpool = <__torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d object at 0000020DCB8F6790>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested object at 0000020DCB8F6090>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested object at 0000020DCB8F5190>
                  }
                  methods {
                    method forward {
                      graph(%self.479 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass,
                            %1 : Float(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                        %dequant_stubs.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.479)
                        %avgpool : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d = prim::GetAttr[name="avgpool"](%self.479)
                        %roi_box_conv : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule = prim::GetAttr[name="roi_box_conv"](%self.479)
                        %quant_stubs.5 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.479)
                        %36 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.5, %1)
                        %37 : Tensor = prim::CallMethod[name="forward"](%roi_box_conv, %36)
                        %38 : Tensor = prim::CallMethod[name="forward"](%avgpool, %37)
                        %39 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs.5, %38)
                        return (%39)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_281.Sequential object at 0000020DCB8F6490>
                      }
                      methods {
                        method forward {
                          graph(%self.485 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule,
                                %1 : QUInt8(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                            %_0.17 : __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential = prim::GetAttr[name="0"](%self.485)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.17, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock object at 0000020DCBAAEE90>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock object at 0000020DCBAA1610>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock object at 0000020DCBAAEB90>
                            fbnetv2_0_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock object at 0000020DCB8F5490>
                          }
                          methods {
                            method forward {
                              graph(%self.487 : __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential,
                                    %1 : QUInt8(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                %fbnetv2_0_3.1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock = prim::GetAttr[name="fbnetv2_0_3"](%self.487)
                                %fbnetv2_0_2.3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.487)
                                %fbnetv2_0_1.5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.487)
                                %fbnetv2_0_0.5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.487)
                                %10 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0.5, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1.5, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2.3, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_3.1, %12)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu object at 0000020DCBAD0990>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu object at 0000020DCBA9F410>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu object at 0000020DCBAAFA10>
                              }
                              methods {
                                method forward {
                                  graph(%self.489 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock,
                                        %1 : QUInt8(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %pwl.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu = prim::GetAttr[name="pwl"](%self.489)
                                    %dw.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu = prim::GetAttr[name="dw"](%self.489)
                                    %pw.35 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu = prim::GetAttr[name="pw"](%self.489)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%pw.35, %1)
                                    %9 : Tensor = prim::CallMethod[name="forward"](%dw.45, %8)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pwl.37, %9)
                                    return (%10)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d object at 0000020DCBAC6B90>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_236.Identity object at 0000020DCBAD0810>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_237.Identity object at 0000020DCBAD0B10>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.491 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu,
                                            %1 : QUInt8(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                        %relu.37 : __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity = prim::GetAttr[name="relu"](%self.491)
                                        %bn.73 : __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity = prim::GetAttr[name="bn"](%self.491)
                                        %conv.109 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d = prim::GetAttr[name="conv"](%self.491)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.109, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.73)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.37)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 352
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAD1410>
                                        scale = 0.01592710055410862
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.493 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
                                                %1 : QUInt8(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.113 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.493)
                                            %15 : float = prim::Constant[value=0.01592710055410862](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.113 : QUInt8(30, 352, 6, 6, strides=[12672, 1, 2112, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.113, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.113)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.495 : __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.497 : __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d object at 0000020DCBACFD90>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.499 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu,
                                            %1 : QUInt8(30, 352, 6, 6, strides=[12672, 1, 2112, 352], requires_grad=0, device=cpu)):
                                        %conv.111 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d = prim::GetAttr[name="conv"](%self.499)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.111, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 352
                                        kernel_size = (3, 3)
                                        stride = (2, 2)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 352
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBA9ED90>
                                        scale = 0.0048691257834434509
                                        zero_point = 71
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.501 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
                                                %1 : QUInt8(30, 352, 6, 6, strides=[12672, 1, 2112, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.115 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.501)
                                            %15 : float = prim::Constant[value=0.0048691257834434509](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=71](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.115 : QUInt8(30, 352, 3, 3, strides=[3168, 1, 1056, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.115, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.115)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d object at 0000020DCBA9DF90>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_242.Identity object at 0000020DCBAAF890>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.503 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu,
                                            %1 : QUInt8(30, 352, 3, 3, strides=[3168, 1, 1056, 352], requires_grad=0, device=cpu)):
                                        %bn.75 : __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity = prim::GetAttr[name="bn"](%self.503)
                                        %conv.113 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d = prim::GetAttr[name="conv"](%self.503)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.113, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.75)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAAEC90>
                                        scale = 0.02964261919260025
                                        zero_point = 62
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.505 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
                                                %1 : QUInt8(30, 352, 3, 3, strides=[3168, 1, 1056, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.117 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.505)
                                            %15 : float = prim::Constant[value=0.02964261919260025](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=62](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.117 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.117, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.117)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.507 : __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu object at 0000020DCBABBF90>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu object at 0000020DCBACDB10>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu object at 0000020DCBAA0590>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd object at 0000020DCBA9FD90>
                              }
                              methods {
                                method forward {
                                  graph(%self.509 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock,
                                        %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                    %res_conn.29 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd = prim::GetAttr[name="res_conn"](%self.509)
                                    %pwl.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu = prim::GetAttr[name="pwl"](%self.509)
                                    %dw.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu = prim::GetAttr[name="dw"](%self.509)
                                    %pw.37 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu = prim::GetAttr[name="pw"](%self.509)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.37, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.47, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.39, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.29, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d object at 0000020DCBAAE210>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_246.Identity object at 0000020DCBABBF10>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_247.Identity object at 0000020DCBABC090>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.511 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu,
                                            %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %relu.39 : __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity = prim::GetAttr[name="relu"](%self.511)
                                        %bn.77 : __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity = prim::GetAttr[name="bn"](%self.511)
                                        %conv.115 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d = prim::GetAttr[name="conv"](%self.511)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.115, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.77)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.39)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 576
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBABD610>
                                        scale = 0.018882663920521736
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.513 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
                                                %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                            %_packed_params.119 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.513)
                                            %15 : float = prim::Constant[value=0.018882663920521736](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.119 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.119, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.119)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.515 : __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.517 : __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d object at 0000020DCBABCA90>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.519 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu,
                                            %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %conv.117 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d = prim::GetAttr[name="conv"](%self.519)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.117, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 576
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 576
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBACC290>
                                        scale = 0.0029587519820779562
                                        zero_point = 52
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.521 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
                                                %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.121 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.521)
                                            %15 : float = prim::Constant[value=0.0029587519820779562](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=52](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.121 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.121, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.121)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d object at 0000020DCBACDB90>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_252.Identity object at 0000020DCBAA1410>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.523 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu,
                                            %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %bn.79 : __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity = prim::GetAttr[name="bn"](%self.523)
                                        %conv.119 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d = prim::GetAttr[name="conv"](%self.523)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.119, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.79)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAA1790>
                                        scale = 0.043222911655902863
                                        zero_point = 61
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.525 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
                                                %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.123 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.525)
                                            %15 : float = prim::Constant[value=0.043222911655902863](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=61](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.33 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.123, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.33)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.527 : __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional object at 0000020DCBAA1510>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.529 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd,
                                            %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %add_func.29 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional = prim::GetAttr[name="add_func"](%self.529)
                                        %activation_post_process.29 : __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity = prim::GetAttr[name="activation_post_process"](%add_func.29)
                                        %5 : float = prim::Constant[value=0.047752153128385544](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=58](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.123 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.29)
                                        return (%input.123)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_254.Identity object at 0000020DCBAA0990>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.531 : __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu object at 0000020DCBAB5B90>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu object at 0000020DCBACDE90>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu object at 0000020DCBAAB310>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd object at 0000020DCBAAE090>
                              }
                              methods {
                                method forward {
                                  graph(%self.533 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock,
                                        %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                    %res_conn.31 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd = prim::GetAttr[name="res_conn"](%self.533)
                                    %pwl.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu = prim::GetAttr[name="pwl"](%self.533)
                                    %dw.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu = prim::GetAttr[name="dw"](%self.533)
                                    %pw.39 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu = prim::GetAttr[name="pw"](%self.533)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.39, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.49, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.41, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.31, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d object at 0000020DCBAA0B90>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_259.Identity object at 0000020DCBAB6F10>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_260.Identity object at 0000020DCBAB6810>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.535 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu,
                                            %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %relu.41 : __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity = prim::GetAttr[name="relu"](%self.535)
                                        %bn.81 : __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity = prim::GetAttr[name="bn"](%self.535)
                                        %conv.121 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d = prim::GetAttr[name="conv"](%self.535)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.121, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.81)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.41)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 576
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAB6C10>
                                        scale = 0.013004320673644543
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.537 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
                                                %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                            %_packed_params.125 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.537)
                                            %15 : float = prim::Constant[value=0.013004320673644543](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.125 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.125, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.125)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.539 : __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.541 : __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d object at 0000020DCBAB5E90>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.543 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu,
                                            %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %conv.123 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d = prim::GetAttr[name="conv"](%self.543)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.123, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 576
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 576
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBACF010>
                                        scale = 0.0016746800392866135
                                        zero_point = 65
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.545 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
                                                %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.127 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.545)
                                            %15 : float = prim::Constant[value=0.0016746800392866135](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.127 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.127, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.127)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d object at 0000020DCBACDF10>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_265.Identity object at 0000020DCBAAA710>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.547 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu,
                                            %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %bn.83 : __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity = prim::GetAttr[name="bn"](%self.547)
                                        %conv.125 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d = prim::GetAttr[name="conv"](%self.547)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.125, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.83)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAAA810>
                                        scale = 0.053468119353055954
                                        zero_point = 55
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.549 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
                                                %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.129 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.549)
                                            %15 : float = prim::Constant[value=0.053468119353055954](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=55](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.35 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.129, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.35)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.551 : __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional object at 0000020DCBAAB910>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.553 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd,
                                            %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %add_func.31 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional = prim::GetAttr[name="add_func"](%self.553)
                                        %activation_post_process.31 : __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity = prim::GetAttr[name="activation_post_process"](%add_func.31)
                                        %5 : float = prim::Constant[value=0.069552652537822723](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=63](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.129 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.31)
                                        return (%input.129)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_267.Identity object at 0000020DCBAAB510>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.555 : __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu object at 0000020DCBACBB90>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu object at 0000020DCBAB4B10>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu object at 0000020DCB8F5A90>
                              }
                              methods {
                                method forward {
                                  graph(%self.557 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock,
                                        %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                    %pwl.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu = prim::GetAttr[name="pwl"](%self.557)
                                    %dw.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu = prim::GetAttr[name="dw"](%self.557)
                                    %pw.41 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu = prim::GetAttr[name="pw"](%self.557)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%pw.41, %1)
                                    %9 : Tensor = prim::CallMethod[name="forward"](%dw.51, %8)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pwl.43, %9)
                                    return (%10)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d object at 0000020DCBAB0510>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_272.Identity object at 0000020DCBACBE90>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_273.Identity object at 0000020DCBACD990>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.559 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu,
                                            %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %relu.43 : __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity = prim::GetAttr[name="relu"](%self.559)
                                        %bn.85 : __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity = prim::GetAttr[name="bn"](%self.559)
                                        %conv.127 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d = prim::GetAttr[name="conv"](%self.559)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.127, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.85)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.43)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 576
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBACCF10>
                                        scale = 0.022410595789551735
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.561 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
                                                %1 : QUInt8(30, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                            %_packed_params.131 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.561)
                                            %15 : float = prim::Constant[value=0.022410595789551735](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.131 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.131, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.131)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.563 : __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.565 : __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d object at 0000020DCBACCB10>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.567 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu,
                                            %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %conv.129 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d = prim::GetAttr[name="conv"](%self.567)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.129, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 576
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 576
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAB4390>
                                        scale = 0.0022731027565896511
                                        zero_point = 50
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.569 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
                                                %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.133 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.569)
                                            %15 : float = prim::Constant[value=0.0022731027565896511](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=50](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.133 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.133, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.133)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d object at 0000020DCBAB4C10>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_278.Identity object at 0000020DCB8F4F10>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.571 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu,
                                            %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %bn.87 : __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity = prim::GetAttr[name="bn"](%self.571)
                                        %conv.131 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d = prim::GetAttr[name="conv"](%self.571)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.131, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.87)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 120
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBAA4090>
                                        scale = 0.090585090219974518
                                        zero_point = 72
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.573 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
                                                %1 : QUInt8(30, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.135 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.573)
                                            %15 : float = prim::Constant[value=0.090585090219974518](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=72](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.37 : QUInt8(30, 120, 3, 3, strides=[1080, 1, 360, 120], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.135, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.roi_box_conv/__module.model.model.roi_heads.box_head.roi_box_conv.0/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.37)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.575 : __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self.577 : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d,
                                %1 : QUInt8(30, 120, 3, 3, strides=[1080, 1, 360, 120], requires_grad=0, device=cpu)):
                            %14 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:1241:0
                            %15 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:1241:0
                            %16 : int[] = prim::ListConstruct(%14, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool
                            %Xq.7 : QUInt8(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu) = aten::adaptive_avg_pool2d(%1, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.avgpool # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:1241:0
                            return (%Xq.7)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList object at 0000020DCB8F6010>
                      }
                      methods {
                        method forward {
                          graph(%self.481 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested,
                                %1 : Float(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                            %stubs.17 : __torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList = prim::GetAttr[name="stubs"](%self.481)
                            %_0.15 : __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize = prim::GetAttr[name="0"](%stubs.17)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.15, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize object at 0000020DCB8F6F10>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.483 : __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize,
                                        %1 : Float(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.07695508748292923](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=65](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %input.111 : QUInt8(30, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.quant_stubs/__module.model.model.roi_heads.box_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%input.111)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList object at 0000020DCB8F5390>
                      }
                      methods {
                        method forward {
                          graph(%self.579 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested,
                                %1 : QUInt8(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu)):
                            %stubs.19 : __torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList = prim::GetAttr[name="stubs"](%self.579)
                            %_0.19 : __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize = prim::GetAttr[name="0"](%stubs.19)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.19, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize object at 0000020DCB8F6B10>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.581 : __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize,
                                        %1 : QUInt8(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu)):
                                    %X.5 : Float(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_head/__module.model.model.roi_heads.box_head.dequant_stubs/__module.model.model.roi_heads.box_head.dequant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%X.5)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    cls_score = <__torch__.torch.nn.quantized.modules.linear.Linear object at 0000020DCBABC910>
                    bbox_pred = <__torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear object at 0000020DCB918C90>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested object at 0000020DCB91FC10>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested object at 0000020DCB920990>
                  }
                  methods {
                    method forward {
                      graph(%self.583 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass,
                            %1 : Float(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu)):
                        %dequant_stubs.7 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.583)
                        %bbox_pred : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear = prim::GetAttr[name="bbox_pred"](%self.583)
                        %cls_score : __torch__.torch.nn.quantized.modules.linear.Linear = prim::GetAttr[name="cls_score"](%self.583)
                        %quant_stubs.7 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.583)
                        %16 : Tensor = prim::CallMethod[name="forward"](%quant_stubs.7, %1)
                        %7 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %8 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %x.41 : QUInt8(30, 120, strides=[120, 1], requires_grad=0, device=cpu) = aten::flatten(%16, %7, %8), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\fast_rcnn.py:302:0
                        %17 : Tensor = prim::CallMethod[name="forward"](%cls_score, %x.41)
                        %18 : Tensor = prim::CallMethod[name="forward"](%bbox_pred, %x.41)
                        %19 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%dequant_stubs.7, %17, %18)
                        %13 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu), %14 : Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%19)
                        %15 : (Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu), Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%13, %14)
                        return (%15)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.quantized.modules.linear.Linear {
                      parameters {
                      }
                      attributes {
                        training = True
                        _is_full_backward_hook = None
                        _packed_params = <__torch__.torch.nn.quantized.modules.linear.LinearPackedParams object at 0000020DCB8F6190>
                      }
                      methods {
                        method forward {
                          graph(%self.589 : __torch__.torch.nn.quantized.modules.linear.Linear,
                                %x.41 : QUInt8(30, 120, strides=[120, 1], requires_grad=0, device=cpu)):
                            %_packed_params.137 : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams = prim::GetAttr[name="_packed_params"](%self.589)
                            %_packed_params.139 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%_packed_params.137)
                            %4 : float = prim::Constant[value=0.091204158961772919](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:178:0
                            %5 : int = prim::Constant[value=64](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:178:0
                            %Xq.9 : QUInt8(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = quantized::linear(%x.41, %_packed_params.139, %4, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.cls_score # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:178:0
                            return (%Xq.9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.linear.LinearPackedParams {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            dtype = 12
                            _packed_params = <__torch__.torch.classes.quantized.LinearPackedParamsBase object at 0000020DCBABC410>
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams):
                                %1 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:88:24
                                %qweight.1 : Tensor, %bias.1 : Tensor? = prim::TupleUnpack(%1)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %dtype : int = prim::GetAttr[name="dtype"](%self)
                                %8 : (Tensor, Tensor?, bool, int) = prim::TupleConstruct(%qweight.1, %bias.1, %training, %dtype)
                                return (%8)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams,
                                    %state.1 : (Tensor, Tensor?, bool, int)):
                                %15 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:92:21
                                %3 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:93:27
                                %6 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:94:35
                                %9 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:94:45
                                %13 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:95:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="dtype"](%self, %4)
                                %7 : Tensor = prim::TupleIndex(%state.1, %6)
                                %10 : Tensor? = prim::TupleIndex(%state.1, %9)
                                %11 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %7, %10) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:94:8
                                %14 : bool = prim::TupleIndex(%state.1, %13)
                                 = prim::SetAttr[name="training"](%self, %14)
                                return (%15)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams):
                                %18 : NoneType = prim::Constant()
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:31
                                %10 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:35:27
                                %2 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:33:25
                                %28 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::Uninitialized()
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %3 : bool = aten::eq(%dtype.1, %2) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:33:11
                                %30 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%3) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:33:8
                                  block0():
                                    %_packed_params.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %6 : Tensor, %7 : Tensor? = quantized::linear_unpack(%_packed_params.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:34:19
                                    %8 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%6, %7)
                                    -> (%8)
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %11 : bool = aten::eq(%dtype, %10) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:35:13
                                    %29 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%11) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:35:8
                                      block0():
                                        %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %14 : Tensor, %15 : Tensor? = quantized::linear_unpack_fp16(%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:19
                                        %16 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%14, %15)
                                        -> (%16)
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:12
                                        -> (%28)
                                    -> (%29)
                                return (%30)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams,
                                    %weight.1 : Tensor,
                                    %bias.1 : Tensor?):
                                %18 : NoneType = prim::Constant()
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:31
                                %11 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:27
                                %4 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:23:25
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %5 : bool = aten::eq(%dtype.1, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:23:11
                                 = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:23:8
                                  block0():
                                    %9 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack(%weight.1, %bias.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:24:34
                                     = prim::SetAttr[name="_packed_params"](%self, %9)
                                    -> ()
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %12 : bool = aten::eq(%dtype, %11) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:13
                                     = prim::If(%12) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:8
                                      block0():
                                        %16 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack_fp16(%weight.1, %bias.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:34
                                         = prim::SetAttr[name="_packed_params"](%self, %16)
                                        -> ()
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:12
                                        -> ()
                                    -> ()
                                return (%18)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear {
                      parameters {
                      }
                      attributes {
                        training = True
                        _is_full_backward_hook = None
                        _packed_params = <__torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams object at 0000020DCBABD590>
                      }
                      methods {
                        method forward {
                          graph(%self.591 : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear,
                                %x.41 : QUInt8(30, 120, strides=[120, 1], requires_grad=0, device=cpu)):
                            %_packed_params.141 : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams = prim::GetAttr[name="_packed_params"](%self.591)
                            %_packed_params.143 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%_packed_params.141)
                            %4 : float = prim::Constant[value=0.005936991423368454](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:178:0
                            %5 : int = prim::Constant[value=55](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:178:0
                            %Xq.11 : QUInt8(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = quantized::linear(%x.41, %_packed_params.143, %4, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.bbox_pred # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:178:0
                            return (%Xq.11)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams {
                          parameters {
                          }
                          attributes {
                            training = True
                            _is_full_backward_hook = None
                            dtype = 12
                            _packed_params = <__torch__.torch.classes.quantized.LinearPackedParamsBase object at 0000020DCBAB2610>
                          }
                          methods {
                            method __getstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams):
                                %1 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:88:24
                                %qweight.1 : Tensor, %bias.1 : Tensor? = prim::TupleUnpack(%1)
                                %training : bool = prim::GetAttr[name="training"](%self)
                                %dtype : int = prim::GetAttr[name="dtype"](%self)
                                %8 : (Tensor, Tensor?, bool, int) = prim::TupleConstruct(%qweight.1, %bias.1, %training, %dtype)
                                return (%8)
                          
                            }
                            method __setstate__ {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams,
                                    %state.1 : (Tensor, Tensor?, bool, int)):
                                %15 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:92:21
                                %3 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:93:27
                                %6 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:94:35
                                %9 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:94:45
                                %13 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:95:30
                                %4 : int = prim::TupleIndex(%state.1, %3)
                                 = prim::SetAttr[name="dtype"](%self, %4)
                                %7 : Tensor = prim::TupleIndex(%state.1, %6)
                                %10 : Tensor? = prim::TupleIndex(%state.1, %9)
                                %11 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %7, %10) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:94:8
                                %14 : bool = prim::TupleIndex(%state.1, %13)
                                 = prim::SetAttr[name="training"](%self, %14)
                                return (%15)
                          
                            }
                            method _weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams):
                                %18 : NoneType = prim::Constant()
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:31
                                %10 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:35:27
                                %2 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:33:25
                                %28 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::Uninitialized()
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %3 : bool = aten::eq(%dtype.1, %2) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:33:11
                                %30 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%3) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:33:8
                                  block0():
                                    %_packed_params.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                    %6 : Tensor, %7 : Tensor? = quantized::linear_unpack(%_packed_params.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:34:19
                                    %8 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%6, %7)
                                    -> (%8)
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %11 : bool = aten::eq(%dtype, %10) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:35:13
                                    %29 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::If(%11) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:35:8
                                      block0():
                                        %_packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %14 : Tensor, %15 : Tensor? = quantized::linear_unpack_fp16(%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:36:19
                                        %16 : NamedTuple(W_origin : Tensor, B_origin : Tensor?) = prim::TupleConstruct(%14, %15)
                                        -> (%16)
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:38:12
                                        -> (%28)
                                    -> (%29)
                                return (%30)
                          
                            }
                            method set_weight_bias {
                              graph(%self : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams,
                                    %weight.1 : Tensor,
                                    %bias.1 : Tensor?):
                                %18 : NoneType = prim::Constant()
                                %17 : str = prim::Constant[value="Unsupported dtype on dynamic quantized linear!"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:31
                                %11 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:27
                                %4 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:23:25
                                %dtype.1 : int = prim::GetAttr[name="dtype"](%self)
                                %5 : bool = aten::eq(%dtype.1, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:23:11
                                 = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:23:8
                                  block0():
                                    %9 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack(%weight.1, %bias.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:24:34
                                     = prim::SetAttr[name="_packed_params"](%self, %9)
                                    -> ()
                                  block1():
                                    %dtype : int = prim::GetAttr[name="dtype"](%self)
                                    %12 : bool = aten::eq(%dtype, %11) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:13
                                     = prim::If(%12) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:25:8
                                      block0():
                                        %16 : __torch__.torch.classes.quantized.LinearPackedParamsBase = quantized::linear_prepack_fp16(%weight.1, %bias.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:26:34
                                         = prim::SetAttr[name="_packed_params"](%self, %16)
                                        -> ()
                                      block1():
                                         = prim::RaiseException(%17, %18) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\linear.py:28:12
                                        -> ()
                                    -> ()
                                return (%18)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList object at 0000020DCB91F710>
                      }
                      methods {
                        method forward {
                          graph(%self.585 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested,
                                %1 : Float(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu)):
                            %stubs.21 : __torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList = prim::GetAttr[name="stubs"](%self.585)
                            %_0.21 : __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize = prim::GetAttr[name="0"](%stubs.21)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.21, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize object at 0000020DCB91E210>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.587 : __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize,
                                        %1 : Float(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=0.054688714444637299](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=70](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %x.39 : QUInt8(30, 120, 1, 1, strides=[120, 1, 120, 120], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.quant_stubs/__module.model.model.roi_heads.box_predictor.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%x.39)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList object at 0000020DCB91FC90>
                      }
                      methods {
                        method forward {
                          graph(%self.593 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested,
                                %1 : QUInt8(30, 2, strides=[2, 1], requires_grad=0, device=cpu),
                                %2 : QUInt8(30, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                            %stubs.25 : __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList = prim::GetAttr[name="stubs"](%self.593)
                            %_1 : __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize = prim::GetAttr[name="1"](%stubs.25)
                            %stubs.23 : __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList = prim::GetAttr[name="stubs"](%self.593)
                            %_0.23 : __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize = prim::GetAttr[name="0"](%stubs.23)
                            %10 : Tensor = prim::CallMethod[name="forward"](%_0.23, %1)
                            %11 : Tensor = prim::CallMethod[name="forward"](%_1, %2)
                            %9 : (Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu), Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%11, %10)
                            return (%9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize object at 0000020DCB91F390>
                            1 = <__torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize object at 0000020DCB91F990>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.595 : __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize,
                                        %1 : QUInt8(30, 2, strides=[2, 1], requires_grad=0, device=cpu)):
                                    %input.135 : Float(30, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.dequant_stubs/__module.model.model.roi_heads.box_predictor.dequant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%input.135)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.597 : __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize,
                                        %1 : QUInt8(30, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                                    %deltas.5 : Float(30, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.box_predictor/__module.model.model.roi_heads.box_predictor.dequant_stubs/__module.model.model.roi_heads.box_predictor.dequant_stubs.stubs.1 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%deltas.5)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.detectron2.modeling.poolers.___torch_mangle_302.ROIPooler {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_301.ModuleList object at 0000020DCB924C90>
                  }
                  methods {
                    method forward {
                      graph(%self.599 : __torch__.detectron2.modeling.poolers.___torch_mangle_302.ROIPooler,
                            %1 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu),
                            %tensor : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %level_poolers : __torch__.torch.nn.modules.container.___torch_mangle_301.ModuleList = prim::GetAttr[name="level_poolers"](%self.599)
                        %_0.25 : __torch__.detectron2.layers.roi_align.___torch_mangle_300.ROIAlign = prim::GetAttr[name="0"](%level_poolers)
                        %10 : Tensor[] = prim::ListConstruct(%tensor), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler
                        %11 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\poolers.py:94:0
                        %12 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\poolers.py:94:0
                        %13 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %14 : int = aten::size(%tensor, %13), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %15 : Long(device=cpu) = prim::NumToTensor(%14), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler
                        %19 : Tensor[] = prim::ListConstruct(%15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler
                        %20 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
                        %21 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::stack(%19, %20), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\wrappers.py:31:0
                        %22 : Function = prim::Constant[name="_convert_boxes_to_pooler_format"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler
                        %rois : Tensor = prim::CallFunction(%22, %12, %21), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler
                        %25 : Tensor = prim::CallMethod[name="forward"](%_0.25, %rois, %1)
                        return (%25)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.___torch_mangle_301.ModuleList {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.layers.roi_align.___torch_mangle_300.ROIAlign object at 0000020DCB924910>
                      }
                      methods {
                      }
                      submodules {
                        module __torch__.detectron2.layers.roi_align.___torch_mangle_300.ROIAlign {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self.601 : __torch__.detectron2.layers.roi_align.___torch_mangle_300.ROIAlign,
                                    %rois : Tensor,
                                    %2 : Float(1, 88, 42, 84, strides=[310464, 1, 7392, 88], requires_grad=0, device=cpu)):
                                %8 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %9 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %10 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %11 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0
                                %boxes : Float(0, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::to(%rois, %8, %9, %10, %11), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\layers\roi_align.py:60:0
                                %18 : float = prim::Constant[value=0.0625](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %19 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %20 : int = prim::Constant[value=6](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %21 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %22 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                %X : Float(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu) = torchvision::roi_align(%2, %boxes, %18, %19, %20, %21, %22), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_pooler/__module.model.model.roi_heads.keypoint_pooler.level_poolers.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torchvision\ops\roi_align.py:61:0
                                return (%X)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_377.QuantWrapSubClass {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                    feature_extractor = <__torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_361.FBNetModule object at 0000020DCBD6DF70>
                    predictor = <__torch__.d2go.modeling.backbone.modules.KeypointRCNNIRFPredictorNoUpscale object at 0000020DCBAC7010>
                    quant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_373.QuantStubNested object at 0000020DCBAC6190>
                    dequant_stubs = <__torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_376.QuantStubNested object at 0000020DCBAC9810>
                  }
                  methods {
                    method forward {
                      graph(%self.603 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_377.QuantWrapSubClass,
                            %1 : Float(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu),
                            %tensor : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu)):
                        %dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_376.QuantStubNested = prim::GetAttr[name="dequant_stubs"](%self.603)
                        %predictor : __torch__.d2go.modeling.backbone.modules.KeypointRCNNIRFPredictorNoUpscale = prim::GetAttr[name="predictor"](%self.603)
                        %feature_extractor : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_361.FBNetModule = prim::GetAttr[name="feature_extractor"](%self.603)
                        %quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_373.QuantStubNested = prim::GetAttr[name="quant_stubs"](%self.603)
                        %86 : Tensor = prim::CallMethod[name="forward"](%quant_stubs, %1)
                        %87 : Tensor = prim::CallMethod[name="forward"](%feature_extractor, %86)
                        %88 : Tensor = prim::CallMethod[name="forward"](%predictor, %87)
                        %89 : Tensor = prim::CallMethod[name="forward"](%dequant_stubs, %88)
                        %11 : Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu) = aten::detach(%89), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:120:0
                        %12 : Float(0, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::detach(%tensor), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:121:0
                        %13 : Function = prim::Constant[name="heatmaps_to_keypoints"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %keypoint_results : Tensor = prim::CallFunction(%13, %11, %12), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %15 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %16 : int = aten::size(%tensor, %15), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\structures\boxes.py:240:0
                        %17 : Long(device=cpu) = prim::NumToTensor(%16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %18 : int = aten::Int(%17), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %19 : int = aten::Int(%17), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %23 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %24 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %25 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %26 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %27 : Float(0, 17, 4, strides=[68, 4, 1], requires_grad=0, device=cpu) = aten::slice(%keypoint_results, %23, %24, %25, %26), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %28 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %29 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %30 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %31 : int = prim::Constant[value=1](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %32 : Float(0, 17, 4, strides=[68, 4, 1], requires_grad=0, device=cpu) = aten::slice(%27, %28, %29, %30, %31), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %33 : Long(3, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value= 0  1  3 [ CPULongType{3} ]](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %34 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %35 : int = prim::Constant[value=4](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %36 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %37 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %38 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %39 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::to(%33, %34, %35, %36, %37, %38), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %40 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %41 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %42 : Tensor?[] = prim::ListConstruct(%40, %41, %39), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %43 : Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu) = aten::index(%32, %42), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\detectron2\modeling\roi_heads\keypoint_head.py:123:0
                        %44 : int[] = prim::ListConstruct(%19), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %45 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                        %46 : Tensor[] = aten::split_with_sizes(%43, %44, %45), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                        %47 : Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%46), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %48 : int[] = prim::ListConstruct(%18), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %49 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                        %50 : Tensor[] = aten::split_with_sizes(%11, %48, %49), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\_tensor.py:574:0
                        %51 : Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%50), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head
                        %85 : (Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu), Float(0, 17, 3, strides=[51, 3, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%51, %47)
                        return (%85)
                  
                    }
                  }
                  submodules {
                    module __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_361.FBNetModule {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        0 = <__torch__.torch.nn.modules.container.___torch_mangle_360.Sequential object at 0000020DCBD6C0F0>
                      }
                      methods {
                        method forward {
                          graph(%self.609 : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_361.FBNetModule,
                                %1 : QUInt8(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                            %_0.29 : __torch__.torch.nn.modules.container.___torch_mangle_360.Sequential = prim::GetAttr[name="0"](%self.609)
                            %4 : Tensor = prim::CallMethod[name="forward"](%_0.29, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_360.Sequential {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            fbnetv2_0_0 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_312.IRFBlock object at 0000020DCBD6BDF0>
                            fbnetv2_0_1 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_325.IRFBlock object at 0000020DCBD8F270>
                            fbnetv2_0_2 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_338.IRFBlock object at 0000020DCBD74770>
                            fbnetv2_0_3 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_348.IRFBlock object at 0000020DCBD64DF0>
                            fbnetv2_0_4 = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_359.IRFBlock object at 0000020DCBD6BBF0>
                          }
                          methods {
                            method forward {
                              graph(%self.611 : __torch__.torch.nn.modules.container.___torch_mangle_360.Sequential,
                                    %1 : QUInt8(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                %fbnetv2_0_4 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_359.IRFBlock = prim::GetAttr[name="fbnetv2_0_4"](%self.611)
                                %fbnetv2_0_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_348.IRFBlock = prim::GetAttr[name="fbnetv2_0_3"](%self.611)
                                %fbnetv2_0_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_338.IRFBlock = prim::GetAttr[name="fbnetv2_0_2"](%self.611)
                                %fbnetv2_0_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_325.IRFBlock = prim::GetAttr[name="fbnetv2_0_1"](%self.611)
                                %fbnetv2_0_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_312.IRFBlock = prim::GetAttr[name="fbnetv2_0_0"](%self.611)
                                %12 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_0, %1)
                                %13 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_1, %12)
                                %14 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_2, %13)
                                %15 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_3, %14)
                                %16 : Tensor = prim::CallMethod[name="forward"](%fbnetv2_0_4, %15)
                                return (%16)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_312.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_306.ConvBNRelu object at 0000020DCB20AA00>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_308.ConvBNRelu object at 0000020DCBD62070>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_311.ConvBNRelu object at 0000020DCBD6BB70>
                              }
                              methods {
                                method forward {
                                  graph(%self.613 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_312.IRFBlock,
                                        %1 : QUInt8(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %pwl.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_311.ConvBNRelu = prim::GetAttr[name="pwl"](%self.613)
                                    %dw.53 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_308.ConvBNRelu = prim::GetAttr[name="dw"](%self.613)
                                    %pw.43 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_306.ConvBNRelu = prim::GetAttr[name="pw"](%self.613)
                                    %8 : Tensor = prim::CallMethod[name="forward"](%pw.43, %1)
                                    %9 : Tensor = prim::CallMethod[name="forward"](%dw.53, %8)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pwl.45, %9)
                                    return (%10)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_306.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d object at 0000020DCB925690>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_304.Identity object at 0000020DCB20A780>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_305.Identity object at 0000020DCB20C180>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.615 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_306.ConvBNRelu,
                                            %1 : QUInt8(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                        %relu.45 : __torch__.torch.nn.modules.linear.___torch_mangle_305.Identity = prim::GetAttr[name="relu"](%self.615)
                                        %bn.89 : __torch__.torch.nn.modules.linear.___torch_mangle_304.Identity = prim::GetAttr[name="bn"](%self.615)
                                        %conv.133 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d = prim::GetAttr[name="conv"](%self.615)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.133, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.89)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.45)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 88
                                        out_channels = 352
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBA9B010>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.617 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_303.ConvReLU2d,
                                                %1 : QUInt8(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.145 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.617)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.139 : QUInt8(0, 352, 6, 6, strides=[12672, 1, 2112, 352], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.145, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.139)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_304.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.619 : __torch__.torch.nn.modules.linear.___torch_mangle_304.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_305.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.621 : __torch__.torch.nn.modules.linear.___torch_mangle_305.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_308.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d object at 0000020DCB20AD80>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.623 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_308.ConvBNRelu,
                                            %1 : QUInt8(0, 352, 6, 6, strides=[12672, 1, 2112, 352], requires_grad=0, device=cpu)):
                                        %conv.135 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d = prim::GetAttr[name="conv"](%self.623)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.135, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 352
                                        kernel_size = (3, 3)
                                        stride = (2, 2)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 352
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCB92B110>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.625 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_307.Conv2d,
                                                %1 : QUInt8(0, 352, 6, 6, strides=[12672, 1, 2112, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.147 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.625)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.141 : QUInt8(0, 352, 3, 3, strides=[3168, 1, 1056, 352], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.147, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.141)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_311.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d object at 0000020DCBD601F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_310.Identity object at 0000020DCBD6BE70>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.627 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_311.ConvBNRelu,
                                            %1 : QUInt8(0, 352, 3, 3, strides=[3168, 1, 1056, 352], requires_grad=0, device=cpu)):
                                        %bn.91 : __torch__.torch.nn.modules.linear.___torch_mangle_310.Identity = prim::GetAttr[name="bn"](%self.627)
                                        %conv.137 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d = prim::GetAttr[name="conv"](%self.627)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.137, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.91)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 352
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD6B5F0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.629 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_309.Conv2d,
                                                %1 : QUInt8(0, 352, 3, 3, strides=[3168, 1, 1056, 352], requires_grad=0, device=cpu)):
                                            %_packed_params.149 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.629)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.143 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.149, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_0.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.143)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_310.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.631 : __torch__.torch.nn.modules.linear.___torch_mangle_310.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_325.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_316.ConvBNRelu object at 0000020DCBD76C70>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_318.ConvBNRelu object at 0000020DCBD839F0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_321.ConvBNRelu object at 0000020DCBD8E7F0>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_324.TorchAdd object at 0000020DCBD8F0F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.633 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_325.IRFBlock,
                                        %1 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                    %res_conn.33 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_324.TorchAdd = prim::GetAttr[name="res_conn"](%self.633)
                                    %pwl.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_321.ConvBNRelu = prim::GetAttr[name="pwl"](%self.633)
                                    %dw.55 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_318.ConvBNRelu = prim::GetAttr[name="dw"](%self.633)
                                    %pw.45 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_316.ConvBNRelu = prim::GetAttr[name="pw"](%self.633)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.45, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.55, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.47, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn.33, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_316.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d object at 0000020DCBD6B770>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_314.Identity object at 0000020DCBD76AF0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_315.Identity object at 0000020DCBD778F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.635 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_316.ConvBNRelu,
                                            %1 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %relu.47 : __torch__.torch.nn.modules.linear.___torch_mangle_315.Identity = prim::GetAttr[name="relu"](%self.635)
                                        %bn.93 : __torch__.torch.nn.modules.linear.___torch_mangle_314.Identity = prim::GetAttr[name="bn"](%self.635)
                                        %conv.139 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d = prim::GetAttr[name="conv"](%self.635)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.139, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.93)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.47)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 576
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD77FF0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.637 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_313.ConvReLU2d,
                                                %1 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                            %_packed_params.151 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.637)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.145 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.151, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.145)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_314.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.639 : __torch__.torch.nn.modules.linear.___torch_mangle_314.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_315.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.641 : __torch__.torch.nn.modules.linear.___torch_mangle_315.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_318.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d object at 0000020DCBD772F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.643 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_318.ConvBNRelu,
                                            %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %conv.141 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d = prim::GetAttr[name="conv"](%self.643)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.141, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 576
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 576
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD82FF0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.645 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_317.Conv2d,
                                                %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.153 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.645)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.147 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.153, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.147)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_321.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d object at 0000020DCBD83370>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_320.Identity object at 0000020DCBD8F370>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.647 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_321.ConvBNRelu,
                                            %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %bn.95 : __torch__.torch.nn.modules.linear.___torch_mangle_320.Identity = prim::GetAttr[name="bn"](%self.647)
                                        %conv.143 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d = prim::GetAttr[name="conv"](%self.647)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.143, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.95)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD8E1F0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.649 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_319.Conv2d,
                                                %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.155 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.649)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x.43 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.155, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x.43)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_320.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.651 : __torch__.torch.nn.modules.linear.___torch_mangle_320.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_324.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_323.QFunctional object at 0000020DCBD8E570>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.653 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_324.TorchAdd,
                                            %1 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu)):
                                        %add_func.33 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_323.QFunctional = prim::GetAttr[name="add_func"](%self.653)
                                        %activation_post_process.33 : __torch__.torch.nn.modules.linear.___torch_mangle_322.Identity = prim::GetAttr[name="activation_post_process"](%add_func.33)
                                        %5 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.149 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_1.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process.33)
                                        return (%input.149)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_323.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_322.Identity object at 0000020DCBD8E970>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_322.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.655 : __torch__.torch.nn.modules.linear.___torch_mangle_322.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_338.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_329.ConvBNRelu object at 0000020DCBD9A5F0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_331.ConvBNRelu object at 0000020DCBD675F0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_334.ConvBNRelu object at 0000020DCBD75F70>
                                res_conn = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_337.TorchAdd object at 0000020DCBD748F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.657 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_338.IRFBlock,
                                        %1 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                    %res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_337.TorchAdd = prim::GetAttr[name="res_conn"](%self.657)
                                    %pwl.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_334.ConvBNRelu = prim::GetAttr[name="pwl"](%self.657)
                                    %dw.57 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_331.ConvBNRelu = prim::GetAttr[name="dw"](%self.657)
                                    %pw.47 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_329.ConvBNRelu = prim::GetAttr[name="pw"](%self.657)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.47, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%dw.57, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%pwl.49, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%res_conn, %12, %1)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_329.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d object at 0000020DCBD8F9F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_327.Identity object at 0000020DCBD9B770>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_328.Identity object at 0000020DCBD9BAF0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.659 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_329.ConvBNRelu,
                                            %1 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                        %relu.49 : __torch__.torch.nn.modules.linear.___torch_mangle_328.Identity = prim::GetAttr[name="relu"](%self.659)
                                        %bn.97 : __torch__.torch.nn.modules.linear.___torch_mangle_327.Identity = prim::GetAttr[name="bn"](%self.659)
                                        %conv.145 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d = prim::GetAttr[name="conv"](%self.659)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.145, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.97)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.49)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 576
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD9BEF0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.661 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_326.ConvReLU2d,
                                                %1 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.157 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.661)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.151 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.157, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.151)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_327.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.663 : __torch__.torch.nn.modules.linear.___torch_mangle_327.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_328.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.665 : __torch__.torch.nn.modules.linear.___torch_mangle_328.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_331.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d object at 0000020DCBD9B370>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.667 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_331.ConvBNRelu,
                                            %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %conv.147 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d = prim::GetAttr[name="conv"](%self.667)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.147, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 576
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 576
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD66570>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.669 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_330.Conv2d,
                                                %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.159 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.669)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.153 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.159, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.153)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_334.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d object at 0000020DCBD66970>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_333.Identity object at 0000020DCBD75070>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.671 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_334.ConvBNRelu,
                                            %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %bn.99 : __torch__.torch.nn.modules.linear.___torch_mangle_333.Identity = prim::GetAttr[name="bn"](%self.671)
                                        %conv.149 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d = prim::GetAttr[name="conv"](%self.671)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.149, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.99)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD750F0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.673 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_332.Conv2d,
                                                %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.161 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.673)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %x : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.161, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%x)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_333.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.675 : __torch__.torch.nn.modules.linear.___torch_mangle_333.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_337.TorchAdd {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    add_func = <__torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_336.QFunctional object at 0000020DCBD757F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.677 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_337.TorchAdd,
                                            %1 : QUInt8(0, 96, 3, 3, strides=[864, 1, 288, 96], requires_grad=0, device=cpu),
                                            %2 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                        %add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_336.QFunctional = prim::GetAttr[name="add_func"](%self.677)
                                        %activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_335.Identity = prim::GetAttr[name="activation_post_process"](%add_func)
                                        %5 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %6 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %input.155 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu) = quantized::add(%1, %2, %5, %6), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_2.res_conn # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\functional_modules.py:186:0
                                        %9 : NoneType = prim::CallMethod[name="forward"](%activation_post_process)
                                        return (%input.155)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_336.QFunctional {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        activation_post_process = <__torch__.torch.nn.modules.linear.___torch_mangle_335.Identity object at 0000020DCBD742F0>
                                      }
                                      methods {
                                      }
                                      submodules {
                                        module __torch__.torch.nn.modules.linear.___torch_mangle_335.Identity {
                                          parameters {
                                          }
                                          attributes {
                                            training = True
                                            _is_full_backward_hook = None
                                          }
                                          methods {
                                            method forward {
                                              graph(%self.679 : __torch__.torch.nn.modules.linear.___torch_mangle_335.Identity):
                                                %1 : NoneType = prim::Constant()
                                                return (%1)
                                          
                                            }
                                          }
                                          submodules {
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_348.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_342.ConvBNRelu object at 0000020DCBD85CF0>
                                upsample = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.Upsample object at 0000020DCBD853F0>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_344.ConvBNRelu object at 0000020DCBD95270>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_347.ConvBNRelu object at 0000020DCBD64970>
                              }
                              methods {
                                method forward {
                                  graph(%self.681 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_348.IRFBlock,
                                        %1 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                    %pwl.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_347.ConvBNRelu = prim::GetAttr[name="pwl"](%self.681)
                                    %dw.59 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_344.ConvBNRelu = prim::GetAttr[name="dw"](%self.681)
                                    %upsample.1 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.Upsample = prim::GetAttr[name="upsample"](%self.681)
                                    %pw.49 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_342.ConvBNRelu = prim::GetAttr[name="pw"](%self.681)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.49, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%upsample.1, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%dw.59, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%pwl.51, %12)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_342.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d object at 0000020DCBD75FF0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_340.Identity object at 0000020DCBD847F0>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_341.Identity object at 0000020DCBD857F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.683 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_342.ConvBNRelu,
                                            %1 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                        %relu.51 : __torch__.torch.nn.modules.linear.___torch_mangle_341.Identity = prim::GetAttr[name="relu"](%self.683)
                                        %bn.101 : __torch__.torch.nn.modules.linear.___torch_mangle_340.Identity = prim::GetAttr[name="bn"](%self.683)
                                        %conv.151 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d = prim::GetAttr[name="conv"](%self.683)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.151, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.101)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.51)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 576
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD86070>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.685 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_339.ConvReLU2d,
                                                %1 : QUInt8(0, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.163 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.685)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.157 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.163, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.157)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_340.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.687 : __torch__.torch.nn.modules.linear.___torch_mangle_340.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_341.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.689 : __torch__.torch.nn.modules.linear.___torch_mangle_341.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.Upsample {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.691 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.Upsample,
                                            %1 : QUInt8(0, 576, 3, 3, strides=[5184, 1, 1728, 576], requires_grad=0, device=cpu)):
                                        %2 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.upsample
                                        %3 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                        %4 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                        %5 : float[] = prim::ListConstruct(%3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.upsample
                                        %input.159 : QUInt8(0, 576, 6, 6, strides=[20736, 36, 6, 1], requires_grad=0, device=cpu) = aten::upsample_nearest2d(%1, %2, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                        return (%input.159)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_344.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d object at 0000020DCBD855F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.693 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_344.ConvBNRelu,
                                            %1 : QUInt8(0, 576, 6, 6, strides=[20736, 36, 6, 1], requires_grad=0, device=cpu)):
                                        %conv.153 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d = prim::GetAttr[name="conv"](%self.693)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.153, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 576
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 576
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD95370>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.695 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_343.Conv2d,
                                                %1 : QUInt8(0, 576, 6, 6, strides=[20736, 36, 6, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.165 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.695)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.161 : QUInt8(0, 576, 6, 6, strides=[20736, 1, 3456, 576], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.165, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.161)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_347.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d object at 0000020DCBD95870>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_346.Identity object at 0000020DCBD658F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.697 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_347.ConvBNRelu,
                                            %1 : QUInt8(0, 576, 6, 6, strides=[20736, 1, 3456, 576], requires_grad=0, device=cpu)):
                                        %bn.103 : __torch__.torch.nn.modules.linear.___torch_mangle_346.Identity = prim::GetAttr[name="bn"](%self.697)
                                        %conv.155 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d = prim::GetAttr[name="conv"](%self.697)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.155, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn.103)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 576
                                        out_channels = 96
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD64A70>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.699 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_345.Conv2d,
                                                %1 : QUInt8(0, 576, 6, 6, strides=[20736, 1, 3456, 576], requires_grad=0, device=cpu)):
                                            %_packed_params.167 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.699)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.163 : QUInt8(0, 96, 6, 6, strides=[3456, 1, 576, 96], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.167, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_3.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.163)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_346.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.701 : __torch__.torch.nn.modules.linear.___torch_mangle_346.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_359.IRFBlock {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_352.ConvBNRelu object at 0000020DCBD7B070>
                                upsample = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_353.Upsample object at 0000020DCBD7BC70>
                                dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_355.ConvBNRelu object at 0000020DCBD92BF0>
                                pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_358.ConvBNRelu object at 0000020DCBD6AB70>
                              }
                              methods {
                                method forward {
                                  graph(%self.703 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_359.IRFBlock,
                                        %1 : QUInt8(0, 96, 6, 6, strides=[3456, 1, 576, 96], requires_grad=0, device=cpu)):
                                    %pwl.53 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_358.ConvBNRelu = prim::GetAttr[name="pwl"](%self.703)
                                    %dw.61 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_355.ConvBNRelu = prim::GetAttr[name="dw"](%self.703)
                                    %upsample.3 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_353.Upsample = prim::GetAttr[name="upsample"](%self.703)
                                    %pw.51 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_352.ConvBNRelu = prim::GetAttr[name="pw"](%self.703)
                                    %10 : Tensor = prim::CallMethod[name="forward"](%pw.51, %1)
                                    %11 : Tensor = prim::CallMethod[name="forward"](%upsample.3, %10)
                                    %12 : Tensor = prim::CallMethod[name="forward"](%dw.61, %11)
                                    %13 : Tensor = prim::CallMethod[name="forward"](%pwl.53, %12)
                                    return (%13)
                              
                                }
                              }
                              submodules {
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_352.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d object at 0000020DCBD648F0>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_350.Identity object at 0000020DCBD7BA70>
                                    relu = <__torch__.torch.nn.modules.linear.___torch_mangle_351.Identity object at 0000020DCBD7B3F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.705 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_352.ConvBNRelu,
                                            %1 : QUInt8(0, 96, 6, 6, strides=[3456, 1, 576, 96], requires_grad=0, device=cpu)):
                                        %relu.53 : __torch__.torch.nn.modules.linear.___torch_mangle_351.Identity = prim::GetAttr[name="relu"](%self.705)
                                        %bn.105 : __torch__.torch.nn.modules.linear.___torch_mangle_350.Identity = prim::GetAttr[name="bn"](%self.705)
                                        %conv.157 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d = prim::GetAttr[name="conv"](%self.705)
                                        %8 : Tensor = prim::CallMethod[name="forward"](%conv.157, %1)
                                        %9 : NoneType = prim::CallMethod[name="forward"](%bn.105)
                                        %10 : NoneType = prim::CallMethod[name="forward"](%relu.53)
                                        return (%8)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 96
                                        out_channels = 288
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD7B0F0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.707 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_349.ConvReLU2d,
                                                %1 : QUInt8(0, 96, 6, 6, strides=[3456, 1, 576, 96], requires_grad=0, device=cpu)):
                                            %_packed_params.169 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.707)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            %input.165 : QUInt8(0, 288, 6, 6, strides=[10368, 1, 1728, 288], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.169, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                            return (%input.165)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_350.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.709 : __torch__.torch.nn.modules.linear.___torch_mangle_350.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_351.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.711 : __torch__.torch.nn.modules.linear.___torch_mangle_351.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_353.Upsample {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.713 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_353.Upsample,
                                            %1 : QUInt8(0, 288, 6, 6, strides=[10368, 1, 1728, 288], requires_grad=0, device=cpu)):
                                        %2 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.upsample
                                        %3 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                        %4 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                        %5 : float[] = prim::ListConstruct(%3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.upsample
                                        %input.167 : QUInt8(0, 288, 12, 12, strides=[41472, 144, 12, 1], requires_grad=0, device=cpu) = aten::upsample_nearest2d(%1, %2, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                        return (%input.167)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_355.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d object at 0000020DCBD7B2F0>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.715 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_355.ConvBNRelu,
                                            %1 : QUInt8(0, 288, 12, 12, strides=[41472, 144, 12, 1], requires_grad=0, device=cpu)):
                                        %conv.159 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d = prim::GetAttr[name="conv"](%self.715)
                                        %4 : Tensor = prim::CallMethod[name="forward"](%conv.159, %1)
                                        return (%4)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 288
                                        out_channels = 288
                                        kernel_size = (3, 3)
                                        stride = (1, 1)
                                        padding = (1, 1)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 288
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD93DF0>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.717 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_354.Conv2d,
                                                %1 : QUInt8(0, 288, 12, 12, strides=[41472, 144, 12, 1], requires_grad=0, device=cpu)):
                                            %_packed_params.171 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.717)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.169 : QUInt8(0, 288, 12, 12, strides=[41472, 1, 3456, 288], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.171, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.dw/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.169)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                                module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_358.ConvBNRelu {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                    conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d object at 0000020DCBD92770>
                                    bn = <__torch__.torch.nn.modules.linear.___torch_mangle_357.Identity object at 0000020DCBD6B270>
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.719 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_358.ConvBNRelu,
                                            %1 : QUInt8(0, 288, 12, 12, strides=[41472, 1, 3456, 288], requires_grad=0, device=cpu)):
                                        %bn : __torch__.torch.nn.modules.linear.___torch_mangle_357.Identity = prim::GetAttr[name="bn"](%self.719)
                                        %conv.161 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d = prim::GetAttr[name="conv"](%self.719)
                                        %6 : Tensor = prim::CallMethod[name="forward"](%conv.161, %1)
                                        %7 : NoneType = prim::CallMethod[name="forward"](%bn)
                                        return (%6)
                                  
                                    }
                                  }
                                  submodules {
                                    module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d {
                                      parameters {
                                      }
                                      attributes {
                                        training = True
                                        _is_full_backward_hook = None
                                        in_channels = 288
                                        out_channels = 48
                                        kernel_size = (1, 1)
                                        stride = (1, 1)
                                        padding = (0, 0)
                                        dilation = (1, 1)
                                        transposed = False
                                        output_padding = (0, 0)
                                        groups = 1
                                        padding_mode = zeros
                                        _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD6BF70>
                                        scale = 1.
                                        zero_point = 0
                                      }
                                      methods {
                                        method __getstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d):
                                            %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                            %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                            %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                            %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                            %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                            %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %scale : float = prim::GetAttr[name="scale"](%self)
                                            %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                            %training : bool = prim::GetAttr[name="training"](%self)
                                            %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                            return (%19)
                                      
                                        }
                                        method __setstate__ {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d,
                                                %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                            %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                            %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                            %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                            %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                            %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                            %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                            %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                            %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                            %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                            %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                            %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                            %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                            %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                            %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                            %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                            %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                            %4 : int = prim::TupleIndex(%state.1, %3)
                                             = prim::SetAttr[name="in_channels"](%self, %4)
                                            %7 : int = prim::TupleIndex(%state.1, %6)
                                             = prim::SetAttr[name="out_channels"](%self, %7)
                                            %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                             = prim::SetAttr[name="kernel_size"](%self, %10)
                                            %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                             = prim::SetAttr[name="stride"](%self, %13)
                                            %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                             = prim::SetAttr[name="padding"](%self, %16)
                                            %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                             = prim::SetAttr[name="dilation"](%self, %19)
                                            %22 : bool = prim::TupleIndex(%state.1, %21)
                                             = prim::SetAttr[name="transposed"](%self, %22)
                                            %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                             = prim::SetAttr[name="output_padding"](%self, %25)
                                            %28 : int = prim::TupleIndex(%state.1, %27)
                                             = prim::SetAttr[name="groups"](%self, %28)
                                            %31 : str = prim::TupleIndex(%state.1, %30)
                                             = prim::SetAttr[name="padding_mode"](%self, %31)
                                            %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                            %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                            %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                            %41 : float = prim::TupleIndex(%state.1, %40)
                                             = prim::SetAttr[name="scale"](%self, %41)
                                            %44 : int = prim::TupleIndex(%state.1, %43)
                                             = prim::SetAttr[name="zero_point"](%self, %44)
                                            %47 : bool = prim::TupleIndex(%state.1, %46)
                                             = prim::SetAttr[name="training"](%self, %47)
                                            return (%48)
                                      
                                        }
                                        method _weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d):
                                            %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                            %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                            return (%2)
                                      
                                        }
                                        method set_weight_bias {
                                          graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d,
                                                %w.1 : Tensor,
                                                %b.1 : Tensor?):
                                            %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                            %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                            %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                            %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                            %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                             = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                              block0():
                                                %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                                %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                                %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                                %15 : int[] = prim::ListConstruct(%13, %14)
                                                %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                                %18 : int[] = prim::ListConstruct(%16, %17)
                                                %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                                %21 : int[] = prim::ListConstruct(%19, %20)
                                                %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %22)
                                                -> ()
                                              block1():
                                                %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                                %27 : int[] = prim::ListConstruct(%26, %26)
                                                %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                                %groups : int = prim::GetAttr[name="groups"](%self)
                                                %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                                %32 : int[] = prim::ListConstruct(%30, %31)
                                                %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                                %35 : int[] = prim::ListConstruct(%33, %34)
                                                %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                                 = prim::SetAttr[name="_packed_params"](%self, %36)
                                                -> ()
                                            return (%37)
                                      
                                        }
                                        method forward {
                                          graph(%self.721 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_356.Conv2d,
                                                %1 : QUInt8(0, 288, 12, 12, strides=[41472, 1, 3456, 288], requires_grad=0, device=cpu)):
                                            %_packed_params.173 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.721)
                                            %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            %input.171 : QUInt8(0, 48, 12, 12, strides=[6912, 1, 576, 48], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.173, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.feature_extractor/__module.model.model.roi_heads.keypoint_head.feature_extractor.0/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pwl/__module.model.model.roi_heads.keypoint_head.feature_extractor.0.fbnetv2_0_4.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                            return (%input.171)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                    module __torch__.torch.nn.modules.linear.___torch_mangle_357.Identity {
                                      parameters {
                                      }
                                      attributes {
                                        training = False
                                        _is_full_backward_hook = None
                                      }
                                      methods {
                                        method forward {
                                          graph(%self.723 : __torch__.torch.nn.modules.linear.___torch_mangle_357.Identity):
                                            %1 : NoneType = prim::Constant()
                                            return (%1)
                                      
                                        }
                                      }
                                      submodules {
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.d2go.modeling.backbone.modules.KeypointRCNNIRFPredictorNoUpscale {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        kps_score_lowres = <__torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_370.IRFBlock object at 0000020DCBAC7A10>
                      }
                      methods {
                        method forward {
                          graph(%self.725 : __torch__.d2go.modeling.backbone.modules.KeypointRCNNIRFPredictorNoUpscale,
                                %1 : QUInt8(0, 48, 12, 12, strides=[6912, 1, 576, 48], requires_grad=0, device=cpu)):
                            %kps_score_lowres : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_370.IRFBlock = prim::GetAttr[name="kps_score_lowres"](%self.725)
                            %4 : Tensor = prim::CallMethod[name="forward"](%kps_score_lowres, %1)
                            return (%4)
                      
                        }
                      }
                      submodules {
                        module __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_370.IRFBlock {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            pw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_364.ConvBNRelu object at 0000020DCBD8BD70>
                            upsample = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_365.Upsample object at 0000020DCBD8AE70>
                            dw = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_367.ConvBNRelu object at 0000020DCBD66F70>
                            pwl = <__torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_369.ConvBNRelu object at 0000020DCBABCD90>
                          }
                          methods {
                            method forward {
                              graph(%self.727 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_370.IRFBlock,
                                    %1 : QUInt8(0, 48, 12, 12, strides=[6912, 1, 576, 48], requires_grad=0, device=cpu)):
                                %pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_369.ConvBNRelu = prim::GetAttr[name="pwl"](%self.727)
                                %dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_367.ConvBNRelu = prim::GetAttr[name="dw"](%self.727)
                                %upsample : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_365.Upsample = prim::GetAttr[name="upsample"](%self.727)
                                %pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_364.ConvBNRelu = prim::GetAttr[name="pw"](%self.727)
                                %10 : Tensor = prim::CallMethod[name="forward"](%pw, %1)
                                %11 : Tensor = prim::CallMethod[name="forward"](%upsample, %10)
                                %12 : Tensor = prim::CallMethod[name="forward"](%dw, %11)
                                %13 : Tensor = prim::CallMethod[name="forward"](%pwl, %12)
                                return (%13)
                          
                            }
                          }
                          submodules {
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_364.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d object at 0000020DCBD6D9F0>
                                relu = <__torch__.torch.nn.modules.linear.___torch_mangle_363.Identity object at 0000020DCBD8ABF0>
                              }
                              methods {
                                method forward {
                                  graph(%self.729 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_364.ConvBNRelu,
                                        %1 : QUInt8(0, 48, 12, 12, strides=[6912, 1, 576, 48], requires_grad=0, device=cpu)):
                                    %relu : __torch__.torch.nn.modules.linear.___torch_mangle_363.Identity = prim::GetAttr[name="relu"](%self.729)
                                    %conv.163 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d = prim::GetAttr[name="conv"](%self.729)
                                    %6 : Tensor = prim::CallMethod[name="forward"](%conv.163, %1)
                                    %7 : NoneType = prim::CallMethod[name="forward"](%relu)
                                    return (%6)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 48
                                    out_channels = 144
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD8ACF0>
                                    scale = 1.
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.731 : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_362.ConvReLU2d,
                                            %1 : QUInt8(0, 48, 12, 12, strides=[6912, 1, 576, 48], requires_grad=0, device=cpu)):
                                        %_packed_params.175 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.731)
                                        %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pw/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pw/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        %input.173 : QUInt8(0, 144, 12, 12, strides=[20736, 1, 1728, 144], requires_grad=0, device=cpu) = quantized::conv2d_relu(%1, %_packed_params.175, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pw/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\intrinsic\quantized\modules\conv_relu.py:85:0
                                        return (%input.173)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                                module __torch__.torch.nn.modules.linear.___torch_mangle_363.Identity {
                                  parameters {
                                  }
                                  attributes {
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self.733 : __torch__.torch.nn.modules.linear.___torch_mangle_363.Identity):
                                        %1 : NoneType = prim::Constant()
                                        return (%1)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_365.Upsample {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.735 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_365.Upsample,
                                        %1 : QUInt8(0, 144, 12, 12, strides=[20736, 1, 1728, 144], requires_grad=0, device=cpu)):
                                    %2 : NoneType = prim::Constant(), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.upsample
                                    %3 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                    %4 : float = prim::Constant[value=2.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                    %5 : float[] = prim::ListConstruct(%3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.upsample
                                    %input.175 : QUInt8(0, 144, 24, 24, strides=[82944, 576, 24, 1], requires_grad=0, device=cpu) = aten::upsample_nearest2d(%1, %2, %5), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.upsample # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\functional.py:3891:0
                                    return (%input.175)
                              
                                }
                              }
                              submodules {
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_367.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d object at 0000020DCBD8B3F0>
                              }
                              methods {
                                method forward {
                                  graph(%self.737 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_367.ConvBNRelu,
                                        %1 : QUInt8(0, 144, 24, 24, strides=[82944, 576, 24, 1], requires_grad=0, device=cpu)):
                                    %conv.165 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d = prim::GetAttr[name="conv"](%self.737)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv.165, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 144
                                    out_channels = 144
                                    kernel_size = (3, 3)
                                    stride = (1, 1)
                                    padding = (1, 1)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 144
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD66470>
                                    scale = 1.
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.739 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_366.Conv2d,
                                            %1 : QUInt8(0, 144, 24, 24, strides=[82944, 576, 24, 1], requires_grad=0, device=cpu)):
                                        %_packed_params.177 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.739)
                                        %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.dw/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.dw/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %input : QUInt8(0, 144, 24, 24, strides=[82944, 1, 3456, 144], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params.177, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.dw/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.dw.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%input)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_369.ConvBNRelu {
                              parameters {
                              }
                              attributes {
                                training = False
                                _is_full_backward_hook = None
                                conv = <__torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d object at 0000020DCBD67170>
                              }
                              methods {
                                method forward {
                                  graph(%self.741 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_369.ConvBNRelu,
                                        %1 : QUInt8(0, 144, 24, 24, strides=[82944, 1, 3456, 144], requires_grad=0, device=cpu)):
                                    %conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d = prim::GetAttr[name="conv"](%self.741)
                                    %4 : Tensor = prim::CallMethod[name="forward"](%conv, %1)
                                    return (%4)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d {
                                  parameters {
                                  }
                                  attributes {
                                    training = True
                                    _is_full_backward_hook = None
                                    in_channels = 144
                                    out_channels = 17
                                    kernel_size = (1, 1)
                                    stride = (1, 1)
                                    padding = (0, 0)
                                    dilation = (1, 1)
                                    transposed = False
                                    output_padding = (0, 0)
                                    groups = 1
                                    padding_mode = zeros
                                    _packed_params = <__torch__.torch.classes.quantized.Conv2dPackedParamsBase object at 0000020DCBD97370>
                                    scale = 1.
                                    zero_point = 0
                                  }
                                  methods {
                                    method __getstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d):
                                        %1 : (Tensor, Tensor?) = prim::CallMethod[name="_weight_bias"](%self) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:128:17
                                        %w.1 : Tensor, %b.1 : Tensor? = prim::TupleUnpack(%1)
                                        %in_channels : int = prim::GetAttr[name="in_channels"](%self)
                                        %out_channels : int = prim::GetAttr[name="out_channels"](%self)
                                        %kernel_size : (int, int) = prim::GetAttr[name="kernel_size"](%self)
                                        %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                        %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                        %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                        %transposed : bool = prim::GetAttr[name="transposed"](%self)
                                        %output_padding : (int, int) = prim::GetAttr[name="output_padding"](%self)
                                        %groups : int = prim::GetAttr[name="groups"](%self)
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %scale : float = prim::GetAttr[name="scale"](%self)
                                        %zero_point : int = prim::GetAttr[name="zero_point"](%self)
                                        %training : bool = prim::GetAttr[name="training"](%self)
                                        %19 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool) = prim::TupleConstruct(%in_channels, %out_channels, %kernel_size, %stride, %padding, %dilation, %transposed, %output_padding, %groups, %padding_mode, %w.1, %b.1, %scale, %zero_point, %training)
                                        return (%19)
                                  
                                    }
                                    method __setstate__ {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d,
                                            %state.1 : (int, int, (int, int), (int, int), (int, int), (int, int), bool, (int, int), int, str, Tensor, Tensor?, float, int, bool)):
                                        %48 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:165:21
                                        %3 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:166:33
                                        %6 : int = prim::Constant[value=1]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:167:34
                                        %9 : int = prim::Constant[value=2]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:168:33
                                        %12 : int = prim::Constant[value=3]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:169:28
                                        %15 : int = prim::Constant[value=4]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:170:29
                                        %18 : int = prim::Constant[value=5]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:171:30
                                        %21 : int = prim::Constant[value=6]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:172:32
                                        %24 : int = prim::Constant[value=7]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:173:36
                                        %27 : int = prim::Constant[value=8]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:174:28
                                        %30 : int = prim::Constant[value=9]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:175:34
                                        %33 : int = prim::Constant[value=10]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:35
                                        %36 : int = prim::Constant[value=11]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:46
                                        %40 : int = prim::Constant[value=12]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:177:27
                                        %43 : int = prim::Constant[value=13]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:178:32
                                        %46 : int = prim::Constant[value=14]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:179:30
                                        %4 : int = prim::TupleIndex(%state.1, %3)
                                         = prim::SetAttr[name="in_channels"](%self, %4)
                                        %7 : int = prim::TupleIndex(%state.1, %6)
                                         = prim::SetAttr[name="out_channels"](%self, %7)
                                        %10 : (int, int) = prim::TupleIndex(%state.1, %9)
                                         = prim::SetAttr[name="kernel_size"](%self, %10)
                                        %13 : (int, int) = prim::TupleIndex(%state.1, %12)
                                         = prim::SetAttr[name="stride"](%self, %13)
                                        %16 : (int, int) = prim::TupleIndex(%state.1, %15)
                                         = prim::SetAttr[name="padding"](%self, %16)
                                        %19 : (int, int) = prim::TupleIndex(%state.1, %18)
                                         = prim::SetAttr[name="dilation"](%self, %19)
                                        %22 : bool = prim::TupleIndex(%state.1, %21)
                                         = prim::SetAttr[name="transposed"](%self, %22)
                                        %25 : (int, int) = prim::TupleIndex(%state.1, %24)
                                         = prim::SetAttr[name="output_padding"](%self, %25)
                                        %28 : int = prim::TupleIndex(%state.1, %27)
                                         = prim::SetAttr[name="groups"](%self, %28)
                                        %31 : str = prim::TupleIndex(%state.1, %30)
                                         = prim::SetAttr[name="padding_mode"](%self, %31)
                                        %34 : Tensor = prim::TupleIndex(%state.1, %33)
                                        %37 : Tensor? = prim::TupleIndex(%state.1, %36)
                                        %38 : NoneType = prim::CallMethod[name="set_weight_bias"](%self, %34, %37) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:176:8
                                        %41 : float = prim::TupleIndex(%state.1, %40)
                                         = prim::SetAttr[name="scale"](%self, %41)
                                        %44 : int = prim::TupleIndex(%state.1, %43)
                                         = prim::SetAttr[name="zero_point"](%self, %44)
                                        %47 : bool = prim::TupleIndex(%state.1, %46)
                                         = prim::SetAttr[name="training"](%self, %47)
                                        return (%48)
                                  
                                    }
                                    method _weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self)
                                        %2 : (Tensor, Tensor?) = prim::CallMethod[name="unpack"](%_packed_params) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:439:15
                                        return (%2)
                                  
                                    }
                                    method set_weight_bias {
                                      graph(%self : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d,
                                            %w.1 : Tensor,
                                            %b.1 : Tensor?):
                                        %37 : NoneType = prim::Constant() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:430:4
                                        %4 : str = prim::Constant[value="zeros"]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:32
                                        %26 : int = prim::Constant[value=0]() # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:436:41
                                        %padding_mode : str = prim::GetAttr[name="padding_mode"](%self)
                                        %5 : bool = aten::eq(%padding_mode, %4) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:11
                                         = prim::If(%5) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:431:8
                                          block0():
                                            %stride.1 : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %padding : (int, int) = prim::GetAttr[name="padding"](%self)
                                            %dilation.1 : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups.1 : int = prim::GetAttr[name="groups"](%self)
                                            %13 : int, %14 : int = prim::TupleUnpack(%stride.1)
                                            %15 : int[] = prim::ListConstruct(%13, %14)
                                            %16 : int, %17 : int = prim::TupleUnpack(%padding)
                                            %18 : int[] = prim::ListConstruct(%16, %17)
                                            %19 : int, %20 : int = prim::TupleUnpack(%dilation.1)
                                            %21 : int[] = prim::ListConstruct(%19, %20)
                                            %22 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %15, %18, %21, %groups.1) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:432:34
                                             = prim::SetAttr[name="_packed_params"](%self, %22)
                                            -> ()
                                          block1():
                                            %stride : (int, int) = prim::GetAttr[name="stride"](%self)
                                            %27 : int[] = prim::ListConstruct(%26, %26)
                                            %dilation : (int, int) = prim::GetAttr[name="dilation"](%self)
                                            %groups : int = prim::GetAttr[name="groups"](%self)
                                            %30 : int, %31 : int = prim::TupleUnpack(%stride)
                                            %32 : int[] = prim::ListConstruct(%30, %31)
                                            %33 : int, %34 : int = prim::TupleUnpack(%dilation)
                                            %35 : int[] = prim::ListConstruct(%33, %34)
                                            %36 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = quantized::conv2d_prepack(%w.1, %b.1, %32, %27, %35, %groups) # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:435:34
                                             = prim::SetAttr[name="_packed_params"](%self, %36)
                                            -> ()
                                        return (%37)
                                  
                                    }
                                    method forward {
                                      graph(%self.743 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_368.Conv2d,
                                            %1 : QUInt8(0, 144, 24, 24, strides=[82944, 1, 3456, 144], requires_grad=0, device=cpu)):
                                        %_packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params"](%self.743)
                                        %15 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pwl/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %16 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pwl/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        %Xq : QUInt8(0, 17, 24, 24, strides=[9792, 1, 408, 17], requires_grad=0, device=cpu) = quantized::conv2d(%1, %_packed_params, %15, %16), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.predictor/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pwl/__module.model.model.roi_heads.keypoint_head.predictor.kps_score_lowres.pwl.conv # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\conv.py:456:0
                                        return (%Xq)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_373.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_372.ModuleList object at 0000020DCBAC6110>
                      }
                      methods {
                        method forward {
                          graph(%self.605 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_373.QuantStubNested,
                                %1 : Float(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                            %stubs.27 : __torch__.torch.nn.modules.container.___torch_mangle_372.ModuleList = prim::GetAttr[name="stubs"](%self.605)
                            %_0.27 : __torch__.torch.nn.quantized.modules.___torch_mangle_371.Quantize = prim::GetAttr[name="0"](%stubs.27)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0.27, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_372.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_371.Quantize object at 0000020DCBAC7490>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_371.Quantize {
                              parameters {
                              }
                              attributes {
                                scale = ...
                                zero_point = ...
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self.607 : __torch__.torch.nn.quantized.modules.___torch_mangle_371.Quantize,
                                        %1 : Float(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu)):
                                    %2 : float = prim::Constant[value=1.](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.quant_stubs/__module.model.model.roi_heads.keypoint_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %3 : int = prim::Constant[value=0](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.quant_stubs/__module.model.model.roi_heads.keypoint_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %4 : int = prim::Constant[value=13](), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.quant_stubs/__module.model.model.roi_heads.keypoint_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    %input.137 : QUInt8(0, 88, 6, 6, strides=[3168, 36, 6, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%1, %2, %3, %4), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.quant_stubs/__module.model.model.roi_heads.keypoint_head.quant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:53:0
                                    return (%input.137)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_376.QuantStubNested {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                        stubs = <__torch__.torch.nn.modules.container.___torch_mangle_375.ModuleList object at 0000020DCBAC6390>
                      }
                      methods {
                        method forward {
                          graph(%self.745 : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_376.QuantStubNested,
                                %1 : QUInt8(0, 17, 24, 24, strides=[9792, 1, 408, 17], requires_grad=0, device=cpu)):
                            %stubs : __torch__.torch.nn.modules.container.___torch_mangle_375.ModuleList = prim::GetAttr[name="stubs"](%self.745)
                            %_0 : __torch__.torch.nn.quantized.modules.___torch_mangle_374.DeQuantize = prim::GetAttr[name="0"](%stubs)
                            %5 : Tensor = prim::CallMethod[name="forward"](%_0, %1)
                            return (%5)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.container.___torch_mangle_375.ModuleList {
                          parameters {
                          }
                          attributes {
                            training = False
                            _is_full_backward_hook = None
                            0 = <__torch__.torch.nn.quantized.modules.___torch_mangle_374.DeQuantize object at 0000020DCBAC5A90>
                          }
                          methods {
                          }
                          submodules {
                            module __torch__.torch.nn.quantized.modules.___torch_mangle_374.DeQuantize {
                              parameters {
                              }
                              attributes {
                                training = True
                                _is_full_backward_hook = None
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.torch.nn.quantized.modules.___torch_mangle_374.DeQuantize,
                                        %1 : QUInt8(0, 17, 24, 24, strides=[9792, 1, 408, 17], requires_grad=0, device=cpu)):
                                    %pred_keypoint_logits : Float(0, 17, 24, 24, strides=[9792, 576, 24, 1], requires_grad=0, device=cpu) = aten::dequantize(%1), scope: __module.model/__module.model.model.roi_heads/__module.model.model.roi_heads.keypoint_head/__module.model.model.roi_heads.keypoint_head.dequant_stubs/__module.model.model.roi_heads.keypoint_head.dequant_stubs.stubs.0 # C:\Users\phil0\anaconda3\envs\d2go\lib\site-packages\torch\nn\quantized\modules\__init__.py:85:0
                                    return (%pred_keypoint_logits)
                              
                                }
                              }
                              submodules {
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
