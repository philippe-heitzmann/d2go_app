
Code for root model, type=TracingAdapter:
class TracingAdapter(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  model : __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper
  def forward(self: __torch__.detectron2.export.flatten.TracingAdapter,
    argument_1: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
    model = self.model
    _0, _1, _2, _3, = (model).forward(argument_1, )
    return (_0, _1, _2, _3)

--------------------------------------------------------------------------------
Code for .model, type=D2RCNNInferenceWrapper:
class D2RCNNInferenceWrapper(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  model : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN
  def forward(self: __torch__.d2go.modeling.meta_arch.rcnn.D2RCNNInferenceWrapper,
    argument_1: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
    _0 = __torch__.detectron2.layers.wrappers.move_device_like
    model = self.model
    roi_heads = model.roi_heads
    model0 = self.model
    proposal_generator = model0.proposal_generator
    model1 = self.model
    backbone = model1.backbone
    model2 = self.model
    pixel_std = model2.pixel_std
    model3 = self.model
    pixel_mean = model3.pixel_mean
    x = _0(argument_1, pixel_mean, )
    t = torch.div(torch.sub(x, pixel_mean), pixel_std)
    _1 = ops.prim.NumToTensor(torch.size(t, 1))
    _2 = ops.prim.NumToTensor(torch.size(t, 2))
    image_size = torch.stack([_1, _2])
    max_size, _3 = torch.max(torch.stack([image_size]), 0)
    _4 = torch.sub(torch.select(max_size, 0, -1), torch.select(image_size, 0, 1))
    _5 = int(_4)
    _6 = torch.sub(torch.select(max_size, 0, -2), torch.select(image_size, 0, 0))
    _7 = torch.pad(t, [0, _5, 0, int(_6)], "constant", 0.)
    batched_imgs = torch.unsqueeze_(_7, 0)
    X = torch.contiguous(batched_imgs)
    _8 = (backbone).forward(X, )
    _9 = (proposal_generator).forward(_8, image_size, )
    _10 = (roi_heads).forward(_8, _9, image_size, )
    _11, _12, _13, = _10
    return (_11, _12, _13, image_size)

--------------------------------------------------------------------------------
Code for .model.model, type=GeneralizedRCNN:
class GeneralizedRCNN(Module):
  __parameters__ = []
  __buffers__ = ["pixel_mean", "pixel_std", ]
  pixel_mean : Tensor
  pixel_std : Tensor
  training : bool
  _is_full_backward_hook : Optional[bool]
  backbone : __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass
  proposal_generator : __torch__.detectron2.modeling.proposal_generator.rpn.RPN
  roi_heads : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads

--------------------------------------------------------------------------------
Code for .model.model.backbone, type=QuantWrapSubClass:
class QuantWrapSubClass(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  body : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone
  quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested
  dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.QuantWrapSubClass,
    X: Tensor) -> Tensor:
    dequant_stubs = self.dequant_stubs
    body = self.body
    quant_stubs = self.quant_stubs
    _0 = (body).forward((quant_stubs).forward(X, ), )
    _1, _2, _3, _4, = _0
    _5 = (dequant_stubs).forward(_1, _2, _3, _4, )
    return _5

--------------------------------------------------------------------------------
Code for .model.model.backbone.body, type=FBNetV2Backbone:
class FBNetV2Backbone(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  trunk0 : __torch__.torch.nn.modules.container.Sequential
  trunk1 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential
  trunk2 : __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential
  trunk3 : __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential
  def forward(self: __torch__.d2go.modeling.backbone.fbnet_v2.FBNetV2Backbone,
    argument_1: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
    trunk3 = self.trunk3
    trunk2 = self.trunk2
    trunk1 = self.trunk1
    trunk0 = self.trunk0
    _0 = (trunk0).forward(argument_1, )
    _1 = (trunk1).forward(_0, )
    _2 = (trunk2).forward(_1, )
    _3 = (_0, _1, _2, (trunk3).forward(_2, ))
    return _3

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0, type=Sequential:
class Sequential(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  fbnetv2_0_0 : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu
  fbnetv2_0_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock
  def forward(self: __torch__.torch.nn.modules.container.Sequential,
    argument_1: Tensor) -> Tensor:
    fbnetv2_0_1 = self.fbnetv2_0_1
    fbnetv2_0_0 = self.fbnetv2_0_0
    _0 = (fbnetv2_0_1).forward((fbnetv2_0_0).forward(argument_1, ), )
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_0, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_0.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.11585384607315063, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_0.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_0.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_0.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    _0 = (pwl).forward((dw).forward(argument_1, ), )
    _1 = (res_conn).forward(_0, argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_1.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.029041629284620285, 92)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_4.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_2.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.1336701512336731, 66)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_3.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.18334655463695526, 47)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk0.fbnetv2_0_1.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_5.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1, type=Sequential:
class Sequential(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  fbnetv2_1_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock
  fbnetv2_1_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock
  def forward(self: __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential,
    argument_1: Tensor) -> Tensor:
    fbnetv2_1_1 = self.fbnetv2_1_1
    fbnetv2_1_0 = self.fbnetv2_1_0
    _0 = (fbnetv2_1_1).forward((fbnetv2_1_0).forward(argument_1, ), )
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_15.IRFBlock,
    argument_1: Tensor) -> Tensor:
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    return (pwl).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_9.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_6.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.078753829002380371, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_7.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_11.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_10.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.05707220733165741, 64)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_14.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.092787548899650574, 62)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_0.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_13.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_28.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_19.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_16.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.02094450406730175, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_17.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_18.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_21.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_20.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.016607090830802917, 49)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_24.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_22.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.068524576723575592, 60)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_23.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_26.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_27.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.10955619066953659, 64)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk1.fbnetv2_1_1.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_25.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2, type=Sequential:
class Sequential(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  fbnetv2_2_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock
  fbnetv2_2_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock
  fbnetv2_2_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock
  fbnetv2_2_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock
  def forward(self: __torch__.torch.nn.modules.container.___torch_mangle_79.Sequential,
    argument_1: Tensor) -> Tensor:
    fbnetv2_2_3 = self.fbnetv2_2_3
    fbnetv2_2_2 = self.fbnetv2_2_2
    fbnetv2_2_1 = self.fbnetv2_2_1
    fbnetv2_2_0 = self.fbnetv2_2_0
    _0 = (fbnetv2_2_1).forward((fbnetv2_2_0).forward(argument_1, ), )
    _1 = (fbnetv2_2_3).forward((fbnetv2_2_2).forward(_0, ), )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_39.IRFBlock,
    argument_1: Tensor) -> Tensor:
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    return (pwl).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_33.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_30.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.025419605895876884, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_31.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_32.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_35.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_34.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.019645385444164276, 56)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_38.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_36.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.061339374631643295, 68)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_0.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_37.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_52.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_43.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_40.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.020118903368711472, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_41.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_42.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_45.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_44.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0067670787684619427, 55)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_48.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_46.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.057710312306880951, 69)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_47.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_50.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_51.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.074877820909023285, 63)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_1.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_49.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_65.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_56.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_53.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.019609589129686356, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_54.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_55.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_58.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_57.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0069701159372925758, 86)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_61.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_59.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.065368488430976868, 64)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_60.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_63.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_64.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.10211624205112457, 54)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_2.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_62.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_78.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_69.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_66.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.01242495235055685, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_67.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_68.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_71.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_70.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0033951580990105867, 92)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_74.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_72.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.044966179877519608, 54)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_73.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_76.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_77.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.10641296952962875, 50)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk2.fbnetv2_2_3.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_75.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3, type=Sequential:
class Sequential(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  fbnetv2_3_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock
  fbnetv2_3_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock
  fbnetv2_3_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock
  fbnetv2_3_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock
  fbnetv2_3_4 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock
  fbnetv2_3_5 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock
  fbnetv2_3_6 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock
  fbnetv2_3_7 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock
  def forward(self: __torch__.torch.nn.modules.container.___torch_mangle_178.Sequential,
    argument_1: Tensor) -> Tensor:
    fbnetv2_3_7 = self.fbnetv2_3_7
    fbnetv2_3_6 = self.fbnetv2_3_6
    fbnetv2_3_5 = self.fbnetv2_3_5
    fbnetv2_3_4 = self.fbnetv2_3_4
    fbnetv2_3_3 = self.fbnetv2_3_3
    fbnetv2_3_2 = self.fbnetv2_3_2
    fbnetv2_3_1 = self.fbnetv2_3_1
    fbnetv2_3_0 = self.fbnetv2_3_0
    _0 = (fbnetv2_3_1).forward((fbnetv2_3_0).forward(argument_1, ), )
    _1 = (fbnetv2_3_3).forward((fbnetv2_3_2).forward(_0, ), )
    _2 = (fbnetv2_3_5).forward((fbnetv2_3_4).forward(_1, ), )
    _3 = (fbnetv2_3_7).forward((fbnetv2_3_6).forward(_2, ), )
    return _3

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_89.IRFBlock,
    argument_1: Tensor) -> Tensor:
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    return (pwl).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_83.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_80.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.017263062298297882, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_81.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_82.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_85.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_84.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.01257427129894495, 65)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_88.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_86.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.065296202898025513, 48)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_0.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_87.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_102.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_93.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_90.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.015569943934679031, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_91.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_92.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_95.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_94.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0045942617580294609, 63)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_98.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_96.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.055696174502372742, 59)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_97.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_100.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_101.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.069978676736354828, 60)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_1.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_99.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_115.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_106.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_103.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.010320775210857391, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_104.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_105.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_108.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_107.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.002296387916430831, 43)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_111.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_109.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.033724598586559296, 59)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_110.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_113.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_114.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.065939456224441528, 61)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_2.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_112.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_128.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_119.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_116.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.0097023583948612213, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_117.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_118.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_121.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_120.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0034326065797358751, 61)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_124.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_122.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.042978081852197647, 66)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_123.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_126.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_127.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.073325932025909424, 56)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_3.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_125.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_138.IRFBlock,
    argument_1: Tensor) -> Tensor:
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    return (pwl).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_132.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_129.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.015027329325675964, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_130.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_131.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_134.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_133.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.010243155062198639, 54)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_137.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_135.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.019521206617355347, 87)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_4.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_136.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_151.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_142.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_139.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.013961838558316231, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_140.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_141.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_144.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_143.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0048557627014815807, 49)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_147.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_145.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.018382290378212929, 68)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_146.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_149.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_150.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.024247467517852783, 87)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_5.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_148.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_164.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_155.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_152.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.0088738147169351578, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_153.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_154.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_157.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_156.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0040600020438432693, 48)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_160.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_158.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.013197137042880058, 88)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_159.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_162.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_163.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.034928727895021439, 86)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_6.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_161.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_177.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_168.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_165.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.0092473095282912254, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_166.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_167.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_170.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_169.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0036785728298127651, 65)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_173.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_171.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.014938217587769032, 79)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_172.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_175.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_176.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    Xq = ops.quantized.add(argument_1, argument_2, 0.056048460304737091, 92)
    _0 = (activation_post_process).forward()
    return Xq

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity

--------------------------------------------------------------------------------
Code for .model.model.backbone.body.trunk3.fbnetv2_3_7.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_174.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.quant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.QuantStubNested,
    X: Tensor) -> Tensor:
    stubs = self.stubs
    _0 = getattr(stubs, "0")
    return (_0).forward(X, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.quant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.Quantize

--------------------------------------------------------------------------------
Code for .model.model.backbone.quant_stubs.stubs.0, type=Quantize:
class Quantize(Module):
  __parameters__ = []
  __buffers__ = ["scale", "zero_point", ]
  scale : Tensor
  zero_point : Tensor
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.Quantize,
    X: Tensor) -> Tensor:
    input = torch.quantize_per_tensor(X, 0.92053180932998657, 127, 13)
    return input

--------------------------------------------------------------------------------
Code for .model.model.backbone.dequant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_182.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_183.QuantStubNested,
    argument_1: Tensor,
    argument_2: Tensor,
    argument_3: Tensor,
    argument_4: Tensor) -> Tensor:
    stubs = self.stubs
    _3 = getattr(stubs, "3")
    stubs0 = self.stubs
    _2 = getattr(stubs0, "2")
    stubs1 = self.stubs
    _1 = getattr(stubs1, "1")
    stubs2 = self.stubs
    _0 = getattr(stubs2, "0")
    _4 = (_0).forward(argument_1, )
    _5 = (_1).forward(argument_2, )
    _6 = (_2).forward(argument_3, )
    return (_3).forward(argument_4, )

--------------------------------------------------------------------------------
Code for .model.model.backbone.dequant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.DeQuantize
  __annotations__["1"] = __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize
  __annotations__["2"] = __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize
  __annotations__["3"] = __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize

--------------------------------------------------------------------------------
Code for .model.model.backbone.dequant_stubs.stubs.0, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.DeQuantize,
    argument_1: Tensor) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.dequant_stubs.stubs.1, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_179.DeQuantize,
    argument_1: Tensor) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.dequant_stubs.stubs.2, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_180.DeQuantize,
    argument_1: Tensor) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.backbone.dequant_stubs.stubs.3, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_181.DeQuantize,
    argument_1: Tensor) -> Tensor:
    return torch.dequantize(argument_1)

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator, type=RPN:
class RPN(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  rpn_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass
  anchor_generator : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator
  def forward(self: __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
    argument_1: Tensor,
    image_size: Tensor) -> Tensor:
    _0 = __torch__.detectron2.layers.wrappers.move_device_like
    _1 = __torch__.detectron2.layers.wrappers.move_device_like
    _2 = __torch__.torchvision.ops.boxes._batched_nms_coordinate_trick
    rpn_head = self.rpn_head
    anchor_generator = self.anchor_generator
    _3 = (anchor_generator).forward(argument_1, )
    _4, _5, = (rpn_head).forward(argument_1, )
    logits_i = torch.flatten(torch.permute(_4, [0, 2, 3, 1]), 1)
    _6 = ops.prim.NumToTensor(torch.size(_5, 0))
    _7 = int(_6)
    _8 = ops.prim.NumToTensor(torch.size(_5, 2))
    _9 = int(_8)
    _10 = ops.prim.NumToTensor(torch.size(_5, 3))
    _11 = torch.view(_5, [_7, -1, 4, _9, int(_10)])
    pred_anchor_deltas_i = torch.flatten(torch.permute(_11, [0, 3, 4, 1, 2]), 1, -2)
    N = ops.prim.NumToTensor(torch.size(pred_anchor_deltas_i, 0))
    _12 = int(N)
    _13 = int(N)
    B = ops.prim.NumToTensor(torch.size(_3, 1))
    _14 = int(B)
    _15 = int(B)
    deltas = torch.reshape(pred_anchor_deltas_i, [-1, int(B)])
    _16 = torch.expand(torch.unsqueeze(_3, 0), [_13, -1, -1])
    boxes = torch.reshape(_16, [-1, _15])
    deltas0 = torch.to(deltas, 6)
    boxes0 = torch.to(boxes, 6)
    _17 = torch.slice(boxes0, 0, 0, 9223372036854775807)
    _18 = torch.select(_17, 1, 2)
    _19 = torch.slice(boxes0, 0, 0, 9223372036854775807)
    widths = torch.sub(_18, torch.select(_19, 1, 0))
    _20 = torch.slice(boxes0, 0, 0, 9223372036854775807)
    _21 = torch.select(_20, 1, 3)
    _22 = torch.slice(boxes0, 0, 0, 9223372036854775807)
    heights = torch.sub(_21, torch.select(_22, 1, 1))
    _23 = torch.slice(boxes0, 0, 0, 9223372036854775807)
    ctr_x = torch.add(torch.select(_23, 1, 0), torch.mul(widths, CONSTANTS.c0))
    _24 = torch.slice(boxes0, 0, 0, 9223372036854775807)
    ctr_y = torch.add(torch.select(_24, 1, 1), torch.mul(heights, CONSTANTS.c0))
    _25 = torch.slice(deltas0, 0, 0, 9223372036854775807)
    _26 = torch.slice(_25, 1, 0, 9223372036854775807, 4)
    dx = torch.div(_26, CONSTANTS.c1)
    _27 = torch.slice(deltas0, 0, 0, 9223372036854775807)
    _28 = torch.slice(_27, 1, 1, 9223372036854775807, 4)
    dy = torch.div(_28, CONSTANTS.c1)
    _29 = torch.slice(deltas0, 0, 0, 9223372036854775807)
    _30 = torch.slice(_29, 1, 2, 9223372036854775807, 4)
    dw = torch.div(_30, CONSTANTS.c1)
    _31 = torch.slice(deltas0, 0, 0, 9223372036854775807)
    _32 = torch.slice(_31, 1, 3, 9223372036854775807, 4)
    dh = torch.div(_32, CONSTANTS.c1)
    dw0 = torch.clamp(dw, None, 4.1351665567423561)
    dh0 = torch.clamp(dh, None, 4.1351665567423561)
    _33 = torch.slice(widths, 0, 0, 9223372036854775807)
    _34 = torch.mul(dx, torch.unsqueeze(_33, 1))
    _35 = torch.slice(ctr_x, 0, 0, 9223372036854775807)
    pred_ctr_x = torch.add(_34, torch.unsqueeze(_35, 1))
    _36 = torch.slice(heights, 0, 0, 9223372036854775807)
    _37 = torch.mul(dy, torch.unsqueeze(_36, 1))
    _38 = torch.slice(ctr_y, 0, 0, 9223372036854775807)
    pred_ctr_y = torch.add(_37, torch.unsqueeze(_38, 1))
    _39 = torch.exp(dw0)
    _40 = torch.slice(widths, 0, 0, 9223372036854775807)
    pred_w = torch.mul(_39, torch.unsqueeze(_40, 1))
    _41 = torch.exp(dh0)
    _42 = torch.slice(heights, 0, 0, 9223372036854775807)
    pred_h = torch.mul(_41, torch.unsqueeze(_42, 1))
    x1 = torch.sub(pred_ctr_x, torch.mul(pred_w, CONSTANTS.c0))
    y1 = torch.sub(pred_ctr_y, torch.mul(pred_h, CONSTANTS.c0))
    x2 = torch.add(pred_ctr_x, torch.mul(pred_w, CONSTANTS.c0))
    y2 = torch.add(pred_ctr_y, torch.mul(pred_h, CONSTANTS.c0))
    pred_boxes = torch.stack([x1, y1, x2, y2], -1)
    _43 = ops.prim.NumToTensor(torch.size(deltas0, 0))
    _44 = int(_43)
    _45 = ops.prim.NumToTensor(torch.size(deltas0, 1))
    proposals_i = torch.reshape(pred_boxes, [_44, int(_45)])
    proposals_i0 = torch.view(proposals_i, [_12, -1, _14])
    _46 = torch.arange(1, dtype=None, layout=0, device=torch.device("cpu"), pin_memory=False)
    batch_idx = _0(_46, proposals_i0, )
    Hi_Wi_A = ops.prim.NumToTensor(torch.size(logits_i, 1))
    num_proposals_i = torch.clamp(Hi_Wi_A, None, 1000)
    _47 = int(num_proposals_i)
    topk_scores, topk_idx = torch.topk(logits_i, int(num_proposals_i), 1)
    _48 = torch.slice(batch_idx, 0, 0, 9223372036854775807)
    _49 = annotate(List[Optional[Tensor]], [torch.unsqueeze(_48, 1), topk_idx])
    topk_proposals = torch.index(proposals_i0, _49)
    _50 = torch.full([_47], 0, dtype=4, layout=0, device=torch.device("cpu"), pin_memory=False)
    level_ids = _1(_50, proposals_i0, )
    tensor = torch.select(topk_proposals, 0, 0)
    tensor0 = torch.to(tensor, 6)
    scores_per_img = torch.select(topk_scores, 0, 0)
    h, w, = torch.unbind(image_size)
    _51 = annotate(number, h)
    _52 = annotate(number, w)
    _53 = annotate(number, h)
    _54 = annotate(number, w)
    _55 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    x10 = torch.clamp(torch.select(_55, 1, 0), 0, _54)
    _56 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    y10 = torch.clamp(torch.select(_56, 1, 1), 0, _53)
    _57 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    x20 = torch.clamp(torch.select(_57, 1, 2), 0, _52)
    _58 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    y20 = torch.clamp(torch.select(_58, 1, 3), 0, _51)
    box = torch.stack([x10, y10, x20, y20], -1)
    _59 = torch.slice(box, 0, 0, 9223372036854775807)
    _60 = torch.select(_59, 1, 2)
    _61 = torch.slice(box, 0, 0, 9223372036854775807)
    widths0 = torch.sub(_60, torch.select(_61, 1, 0))
    _62 = torch.slice(box, 0, 0, 9223372036854775807)
    _63 = torch.select(_62, 1, 3)
    _64 = torch.slice(box, 0, 0, 9223372036854775807)
    heights0 = torch.sub(_63, torch.select(_64, 1, 1))
    item = torch.__and__(torch.gt(widths0, 0.), torch.gt(heights0, 0.))
    _65 = annotate(List[Optional[Tensor]], [item])
    tensor1 = torch.index(box, _65)
    tensor2 = torch.to(tensor1, 6)
    _66 = annotate(List[Optional[Tensor]], [item])
    scores_per_img0 = torch.index(scores_per_img, _66)
    _67 = annotate(List[Optional[Tensor]], [item])
    _68 = torch.index(level_ids, _67)
    boxes1 = torch.to(tensor2, 6)
    keep = _2(boxes1, scores_per_img0, _68, 0.69999999999999996, )
    item0 = torch.slice(keep, 0, 0, 30)
    _69 = annotate(List[Optional[Tensor]], [item0])
    tensor3 = torch.index(boxes1, _69)
    return torch.to(tensor3, 6)

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head, type=QuantWrapSubClass:
class QuantWrapSubClass(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  rpn_feature : __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule
  rpn_regressor : __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor
  quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested
  dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_233.QuantWrapSubClass,
    argument_1: Tensor) -> Tuple[Tensor, Tensor]:
    dequant_stubs = self.dequant_stubs
    rpn_regressor = self.rpn_regressor
    rpn_feature = self.rpn_feature
    quant_stubs = self.quant_stubs
    _0 = (rpn_feature).forward((quant_stubs).forward(argument_1, ), )
    _1, _2, = (rpn_regressor).forward(_0, )
    _3, _4, = (dequant_stubs).forward(_1, _2, )
    return (_3, _4)

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature, type=FBNetModule:
class FBNetModule(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential
  def forward(self: __torch__.d2go.modeling.backbone.fbnet_v2.FBNetModule,
    argument_1: Tensor) -> Tensor:
    _0 = getattr(self, "0")
    return (_0).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0, type=Sequential:
class Sequential(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  fbnetv2_0_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock
  fbnetv2_0_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock
  fbnetv2_0_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock
  def forward(self: __torch__.torch.nn.modules.container.___torch_mangle_223.Sequential,
    argument_1: Tensor) -> Tensor:
    fbnetv2_0_2 = self.fbnetv2_0_2
    fbnetv2_0_1 = self.fbnetv2_0_1
    fbnetv2_0_0 = self.fbnetv2_0_0
    _0 = (fbnetv2_0_1).forward((fbnetv2_0_0).forward(argument_1, ), )
    return (fbnetv2_0_2).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_196.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_187.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_184.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.01914406381547451, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_185.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_186.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_189.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_188.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0027076601982116699, 54)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_192.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_190.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.021053750067949295, 80)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_191.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_194.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_195.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.066744588315486908, 97)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_0.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_193.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_209.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_200.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_197.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.021621430292725563, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_198.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_199.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_202.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_201.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0035627409815788269, 74)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_205.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_203.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.026709176599979401, 63)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_204.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_207.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_208.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.087418779730796814, 94)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_1.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_206.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_222.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_213.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_210.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.020912541076540947, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_211.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_212.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_215.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_214.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0052649891003966331, 61)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_218.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_216.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.069133251905441284, 81)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_217.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_220.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_221.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.13211663067340851, 90)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_feature.0.fbnetv2_0_2.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_219.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_regressor, type=RPNHeadConvRegressor:
class RPNHeadConvRegressor(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  cls_logits : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d
  bbox_pred : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d
  def forward(self: __torch__.d2go.modeling.backbone.modules.RPNHeadConvRegressor,
    argument_1: Tensor) -> Tuple[Tensor, Tensor]:
    bbox_pred = self.bbox_pred
    cls_logits = self.cls_logits
    _0 = ((cls_logits).forward(argument_1, ), (bbox_pred).forward(argument_1, ))
    return _0

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_regressor.cls_logits, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_224.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    Xq = ops.quantized.conv2d(argument_1, _packed_params, 0.11338348686695099, 127)
    return Xq

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.rpn_regressor.bbox_pred, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_225.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    Xq = ops.quantized.conv2d(argument_1, _packed_params, 0.026389690116047859, 99)
    return Xq

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.quant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_227.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_228.QuantStubNested,
    argument_1: Tensor) -> Tensor:
    stubs = self.stubs
    _0 = getattr(stubs, "0")
    return (_0).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.quant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.quant_stubs.stubs.0, type=Quantize:
class Quantize(Module):
  __parameters__ = []
  __buffers__ = ["scale", "zero_point", ]
  scale : Tensor
  zero_point : Tensor
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_226.Quantize,
    argument_1: Tensor) -> Tensor:
    input = torch.quantize_per_tensor(argument_1, 0.056048460304737091, 92, 13)
    return input

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.dequant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_231.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_232.QuantStubNested,
    argument_1: Tensor,
    argument_2: Tensor) -> Tuple[Tensor, Tensor]:
    stubs = self.stubs
    _1 = getattr(stubs, "1")
    stubs0 = self.stubs
    _0 = getattr(stubs0, "0")
    _2 = ((_0).forward(argument_1, ), (_1).forward(argument_2, ))
    return _2

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.dequant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize
  __annotations__["1"] = __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.dequant_stubs.stubs.0, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_229.DeQuantize,
    argument_1: Tensor) -> Tensor:
    return torch.dequantize(argument_1)

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.rpn_head.dequant_stubs.stubs.1, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_230.DeQuantize,
    argument_1: Tensor) -> Tensor:
    return torch.dequantize(argument_1)

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.anchor_generator, type=DefaultAnchorGenerator:
class DefaultAnchorGenerator(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  cell_anchors : __torch__.detectron2.modeling.anchor_generator.BufferList
  def forward(self: __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
    argument_1: Tensor) -> Tensor:
    _0 = __torch__.detectron2.layers.wrappers.move_device_like
    _1 = __torch__.detectron2.layers.wrappers.move_device_like
    cell_anchors = self.cell_anchors
    _00 = getattr(cell_anchors, "0")
    grid_height = ops.prim.NumToTensor(torch.size(argument_1, 2))
    grid_width = ops.prim.NumToTensor(torch.size(argument_1, 3))
    _2 = annotate(number, torch.mul(grid_width, CONSTANTS.c0))
    _3 = torch.arange(0., _2, 16, dtype=6, layout=0, device=torch.device("cpu"), pin_memory=False)
    _4 = _0(_3, _00, )
    _5 = torch.mul(grid_height, CONSTANTS.c0)
    _6 = torch.arange(0., annotate(number, _5), 16, dtype=6, layout=0, device=torch.device("cpu"), pin_memory=False)
    shift_y, shift_x, = torch.meshgrid([_1(_6, _00, ), _4])
    shift_x0 = torch.reshape(shift_x, [-1])
    shift_y0 = torch.reshape(shift_y, [-1])
    _7 = [shift_x0, shift_y0, shift_x0, shift_y0]
    shifts = torch.stack(_7, 1)
    _8 = torch.add(torch.view(shifts, [-1, 1, 4]), torch.view(_00, [1, -1, 4]))
    tensor = torch.reshape(_8, [-1, 4])
    return torch.to(tensor, 6)

--------------------------------------------------------------------------------
Code for .model.model.proposal_generator.anchor_generator.cell_anchors, type=BufferList:
class BufferList(Module):
  __parameters__ = []
  __buffers__ = ["0", ]
  __annotations__ = []
  __annotations__["0"] = Tensor
  training : bool
  _is_full_backward_hook : Optional[bool]

--------------------------------------------------------------------------------
Code for .model.model.roi_heads, type=StandardROIHeads:
class StandardROIHeads(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  box_pooler : __torch__.detectron2.modeling.poolers.ROIPooler
  box_head : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass
  box_predictor : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass
  def forward(self: __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
    argument_1: Tensor,
    argument_2: Tensor,
    image_size: Tensor) -> Tuple[Tensor, Tensor, Tensor]:
    _0 = __torch__.torchvision.ops.boxes._batched_nms_coordinate_trick
    box_predictor = self.box_predictor
    box_head = self.box_head
    box_pooler = self.box_pooler
    _1 = (box_pooler).forward(argument_1, argument_2, )
    _2 = (box_predictor).forward((box_head).forward(_1, ), )
    _3, _4, = _2
    _5 = ops.prim.NumToTensor(torch.size(argument_2, 0))
    _6 = int(_5)
    deltas = torch.to(_3, 6)
    boxes = torch.to(argument_2, 6)
    _7 = torch.slice(boxes, 0, 0, 9223372036854775807)
    _8 = torch.select(_7, 1, 2)
    _9 = torch.slice(boxes, 0, 0, 9223372036854775807)
    widths = torch.sub(_8, torch.select(_9, 1, 0))
    _10 = torch.slice(boxes, 0, 0, 9223372036854775807)
    _11 = torch.select(_10, 1, 3)
    _12 = torch.slice(boxes, 0, 0, 9223372036854775807)
    heights = torch.sub(_11, torch.select(_12, 1, 1))
    _13 = torch.slice(boxes, 0, 0, 9223372036854775807)
    ctr_x = torch.add(torch.select(_13, 1, 0), torch.mul(widths, CONSTANTS.c0))
    _14 = torch.slice(boxes, 0, 0, 9223372036854775807)
    ctr_y = torch.add(torch.select(_14, 1, 1), torch.mul(heights, CONSTANTS.c0))
    _15 = torch.slice(deltas, 0, 0, 9223372036854775807)
    _16 = torch.slice(_15, 1, 0, 9223372036854775807, 4)
    dx = torch.div(_16, CONSTANTS.c1)
    _17 = torch.slice(deltas, 0, 0, 9223372036854775807)
    _18 = torch.slice(_17, 1, 1, 9223372036854775807, 4)
    dy = torch.div(_18, CONSTANTS.c1)
    _19 = torch.slice(deltas, 0, 0, 9223372036854775807)
    _20 = torch.slice(_19, 1, 2, 9223372036854775807, 4)
    dw = torch.div(_20, CONSTANTS.c2)
    _21 = torch.slice(deltas, 0, 0, 9223372036854775807)
    _22 = torch.slice(_21, 1, 3, 9223372036854775807, 4)
    dh = torch.div(_22, CONSTANTS.c2)
    dw0 = torch.clamp(dw, None, 4.1351665567423561)
    dh0 = torch.clamp(dh, None, 4.1351665567423561)
    _23 = torch.slice(widths, 0, 0, 9223372036854775807)
    _24 = torch.mul(dx, torch.unsqueeze(_23, 1))
    _25 = torch.slice(ctr_x, 0, 0, 9223372036854775807)
    pred_ctr_x = torch.add(_24, torch.unsqueeze(_25, 1))
    _26 = torch.slice(heights, 0, 0, 9223372036854775807)
    _27 = torch.mul(dy, torch.unsqueeze(_26, 1))
    _28 = torch.slice(ctr_y, 0, 0, 9223372036854775807)
    pred_ctr_y = torch.add(_27, torch.unsqueeze(_28, 1))
    _29 = torch.exp(dw0)
    _30 = torch.slice(widths, 0, 0, 9223372036854775807)
    pred_w = torch.mul(_29, torch.unsqueeze(_30, 1))
    _31 = torch.exp(dh0)
    _32 = torch.slice(heights, 0, 0, 9223372036854775807)
    pred_h = torch.mul(_31, torch.unsqueeze(_32, 1))
    x1 = torch.sub(pred_ctr_x, torch.mul(pred_w, CONSTANTS.c0))
    y1 = torch.sub(pred_ctr_y, torch.mul(pred_h, CONSTANTS.c0))
    x2 = torch.add(pred_ctr_x, torch.mul(pred_w, CONSTANTS.c0))
    y2 = torch.add(pred_ctr_y, torch.mul(pred_h, CONSTANTS.c0))
    pred_boxes = torch.stack([x1, y1, x2, y2], -1)
    _33 = ops.prim.NumToTensor(torch.size(deltas, 0))
    _34 = int(_33)
    _35 = ops.prim.NumToTensor(torch.size(deltas, 1))
    _36 = torch.reshape(pred_boxes, [_34, int(_35)])
    boxes0, = torch.split_with_sizes(_36, [_6])
    _37 = ops.prim.NumToTensor(torch.size(boxes, 0))
    _38 = int(_37)
    _39 = torch.split_with_sizes(torch.softmax(_4, -1), [_38])
    scores, = _39
    _40 = torch.slice(scores, 0, 0, 9223372036854775807)
    scores0 = torch.slice(_40, 1, 0, -1)
    _41 = ops.prim.NumToTensor(torch.size(boxes0, 1))
    num_bbox_reg_classes = torch.floor_divide(_41, CONSTANTS.c3)
    _42 = int(num_bbox_reg_classes)
    tensor = torch.reshape(boxes0, [-1, 4])
    tensor0 = torch.to(tensor, 6)
    h, w, = torch.unbind(image_size)
    _43 = annotate(number, h)
    _44 = annotate(number, w)
    _45 = annotate(number, h)
    _46 = annotate(number, w)
    _47 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    x10 = torch.clamp(torch.select(_47, 1, 0), 0, _46)
    _48 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    y10 = torch.clamp(torch.select(_48, 1, 1), 0, _45)
    _49 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    x20 = torch.clamp(torch.select(_49, 1, 2), 0, _44)
    _50 = torch.slice(tensor0, 0, 0, 9223372036854775807)
    y20 = torch.clamp(torch.select(_50, 1, 3), 0, _43)
    _51 = torch.stack([x10, y10, x20, y20], -1)
    boxes1 = torch.view(_51, [-1, _42, 4])
    filter_mask = torch.gt(scores0, 0.050000000000000003)
    filter_inds = torch.nonzero(filter_mask)
    _52 = annotate(List[Optional[Tensor]], [filter_mask])
    boxes2 = torch.index(boxes1, _52)
    _53 = annotate(List[Optional[Tensor]], [filter_mask])
    scores1 = torch.index(scores0, _53)
    _54 = torch.slice(filter_inds, 0, 0, 9223372036854775807)
    _55 = torch.select(_54, 1, 1)
    boxes3 = torch.to(boxes2, 6)
    keep = _0(boxes3, scores1, _55, 0.5, )
    keep0 = torch.slice(keep, 0, 0, 100)
    _56 = annotate(List[Optional[Tensor]], [keep0])
    tensor1 = torch.index(boxes3, _56)
    _57 = annotate(List[Optional[Tensor]], [keep0])
    _58 = torch.index(scores1, _57)
    _59 = annotate(List[Optional[Tensor]], [keep0])
    filter_inds0 = torch.index(filter_inds, _59)
    tensor2 = torch.to(tensor1, 6)
    tensor3 = torch.to(torch.reshape(tensor2, [-1, 4]), 6)
    _60 = torch.slice(filter_inds0, 0, 0, 9223372036854775807)
    _61 = (tensor3, torch.select(_60, 1, 1), _58)
    return _61

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_pooler, type=ROIPooler:
class ROIPooler(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  level_poolers : __torch__.torch.nn.modules.container.___torch_mangle_234.ModuleList
  def forward(self: __torch__.detectron2.modeling.poolers.ROIPooler,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    _0 = __torch__.detectron2.modeling.poolers._convert_boxes_to_pooler_format
    level_poolers = self.level_poolers
    _00 = getattr(level_poolers, "0")
    _1 = torch.cat([argument_2])
    _2 = ops.prim.NumToTensor(torch.size(argument_2, 0))
    rois = _0(_1, torch.stack([_2]), )
    return (_00).forward(rois, argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_pooler.level_poolers, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.detectron2.layers.roi_align.ROIAlign

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_pooler.level_poolers.0, type=ROIAlign:
class ROIAlign(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.detectron2.layers.roi_align.ROIAlign,
    rois: Tensor,
    argument_2: Tensor) -> Tensor:
    boxes = torch.to(rois, 6)
    X = ops.torchvision.roi_align(argument_2, boxes, 0.0625, 6, 6, 0, True)
    return X

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head, type=QuantWrapSubClass:
class QuantWrapSubClass(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  roi_box_conv : __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule
  avgpool : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d
  quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested
  dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_289.QuantWrapSubClass,
    argument_1: Tensor) -> Tensor:
    dequant_stubs = self.dequant_stubs
    avgpool = self.avgpool
    roi_box_conv = self.roi_box_conv
    quant_stubs = self.quant_stubs
    _0 = (roi_box_conv).forward((quant_stubs).forward(argument_1, ), )
    _1 = (dequant_stubs).forward((avgpool).forward(_0, ), )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv, type=FBNetModule:
class FBNetModule(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential
  def forward(self: __torch__.d2go.modeling.backbone.fbnet_v2.___torch_mangle_282.FBNetModule,
    argument_1: Tensor) -> Tensor:
    _0 = getattr(self, "0")
    return (_0).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0, type=Sequential:
class Sequential(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  fbnetv2_0_0 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock
  fbnetv2_0_1 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock
  fbnetv2_0_2 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock
  fbnetv2_0_3 : __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock
  def forward(self: __torch__.torch.nn.modules.container.___torch_mangle_281.Sequential,
    argument_1: Tensor) -> Tensor:
    fbnetv2_0_3 = self.fbnetv2_0_3
    fbnetv2_0_2 = self.fbnetv2_0_2
    fbnetv2_0_1 = self.fbnetv2_0_1
    fbnetv2_0_0 = self.fbnetv2_0_0
    _0 = (fbnetv2_0_1).forward((fbnetv2_0_0).forward(argument_1, ), )
    _1 = (fbnetv2_0_3).forward((fbnetv2_0_2).forward(_0, ), )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_244.IRFBlock,
    argument_1: Tensor) -> Tensor:
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    return (pwl).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_238.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_235.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.021674800664186478, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_236.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_237.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_240.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_239.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.010925987735390663, 67)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_243.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_241.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.061936497688293457, 74)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_0.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_242.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_257.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_248.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_245.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.022799083963036537, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_246.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_247.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_250.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_249.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0027748993597924709, 66)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_253.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_251.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.048601623624563217, 61)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_252.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_255.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_256.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.0594521164894104, 69)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_1.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_254.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu
  res_conn : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_270.IRFBlock,
    argument_1: Tensor) -> Tensor:
    res_conn = self.res_conn
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    _1 = (res_conn).forward((pwl).forward(_0, ), argument_1, )
    return _1

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_261.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_258.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.0076013030484318733, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_259.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_260.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_263.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_262.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.0013381578028202057, 66)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_266.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_264.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _18 = ops.quantized.conv2d(argument_1, _packed_params, 0.033281244337558746, 69)
    return _18

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_265.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn, type=TorchAdd:
class TorchAdd(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  add_func : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_268.QFunctional
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_269.TorchAdd,
    argument_1: Tensor,
    argument_2: Tensor) -> Tensor:
    add_func = self.add_func
    activation_post_process = add_func.activation_post_process
    input = ops.quantized.add(argument_1, argument_2, 0.063229329884052277, 67)
    _0 = (activation_post_process).forward()
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn.add_func, type=QFunctional:
class QFunctional(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  activation_post_process : __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_2.res_conn.add_func.activation_post_process, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_267.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3, type=IRFBlock:
class IRFBlock(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  pw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu
  dw : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu
  pwl : __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.irf_block.___torch_mangle_280.IRFBlock,
    argument_1: Tensor) -> Tensor:
    pwl = self.pwl
    dw = self.dw
    pw = self.pw
    _0 = (dw).forward((pw).forward(argument_1, ), )
    return (pwl).forward(_0, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity
  relu : __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_274.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    relu = self.relu
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    _2 = (relu).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.conv, type=ConvReLU2d:
class ConvReLU2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.intrinsic.quantized.modules.conv_relu.___torch_mangle_271.ConvReLU2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d_relu(argument_1, _packed_params, 0.0098056122660636902, 0)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_272.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pw.relu, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_273.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_276.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    conv = self.conv
    return (conv).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.dw.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_275.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    input = ops.quantized.conv2d(argument_1, _packed_params, 0.002167640021070838, 68)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl, type=ConvBNRelu:
class ConvBNRelu(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  conv : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d
  bn : __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity
  def forward(self: __torch__.mobile_cv.arch.fbnet_v2.basic_blocks.___torch_mangle_279.ConvBNRelu,
    argument_1: Tensor) -> Tensor:
    bn = self.bn
    conv = self.conv
    _0 = (conv).forward(argument_1, )
    _1 = (bn).forward()
    return _0

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.conv, type=Conv2d:
class Conv2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  in_channels : int
  out_channels : int
  kernel_size : Tuple[int, int]
  stride : Tuple[int, int]
  padding : Tuple[int, int]
  dilation : Tuple[int, int]
  transposed : bool
  output_padding : Tuple[int, int]
  groups : int
  padding_mode : str
  _packed_params : __torch__.torch.classes.quantized.Conv2dPackedParamsBase
  scale : float
  zero_point : int
  def __getstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d) -> Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]:
    w, b, = (self)._weight_bias()
    in_channels = self.in_channels
    out_channels = self.out_channels
    kernel_size = self.kernel_size
    stride = self.stride
    padding = self.padding
    dilation = self.dilation
    transposed = self.transposed
    output_padding = self.output_padding
    groups = self.groups
    padding_mode = self.padding_mode
    scale = self.scale
    zero_point = self.zero_point
    training = self.training
    _0 = (in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, padding_mode, w, b, scale, zero_point, training)
    return _0
  def __setstate__(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
    state: Tuple[int, int, Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int], bool, Tuple[int, int], int, str, Tensor, Optional[Tensor], float, int, bool]) -> NoneType:
    self.in_channels = (state)[0]
    self.out_channels = (state)[1]
    self.kernel_size = (state)[2]
    self.stride = (state)[3]
    self.padding = (state)[4]
    self.dilation = (state)[5]
    self.transposed = (state)[6]
    self.output_padding = (state)[7]
    self.groups = (state)[8]
    self.padding_mode = (state)[9]
    _1 = (self).set_weight_bias((state)[10], (state)[11], )
    self.scale = (state)[12]
    self.zero_point = (state)[13]
    self.training = (state)[14]
    return None
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d) -> Tuple[Tensor, Optional[Tensor]]:
    _packed_params = self._packed_params
    return (_packed_params).unpack()
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
    w: Tensor,
    b: Optional[Tensor]) -> NoneType:
    padding_mode = self.padding_mode
    if torch.eq(padding_mode, "zeros"):
      stride = self.stride
      padding = self.padding
      dilation = self.dilation
      groups = self.groups
      _2, _3, = stride
      _4 = [_2, _3]
      _5, _6, = padding
      _7 = [_5, _6]
      _8, _9, = dilation
      _10 = ops.quantized.conv2d_prepack(w, b, _4, _7, [_8, _9], groups)
      self._packed_params = _10
    else:
      stride0 = self.stride
      _11 = [0, 0]
      dilation0 = self.dilation
      groups0 = self.groups
      _12, _13, = stride0
      _14 = [_12, _13]
      _15, _16, = dilation0
      _17 = ops.quantized.conv2d_prepack(w, b, _14, _11, [_15, _16], groups0)
      self._packed_params = _17
    return None
  def forward(self: __torch__.torch.nn.quantized.modules.conv.___torch_mangle_277.Conv2d,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    x = ops.quantized.conv2d(argument_1, _packed_params, 0.104253850877285, 62)
    return x

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.roi_box_conv.0.fbnetv2_0_3.pwl.bn, type=Identity:
class Identity(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.linear.___torch_mangle_278.Identity) -> NoneType:
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.avgpool, type=AdaptiveAvgPool2d:
class AdaptiveAvgPool2d(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d,
    argument_1: Tensor) -> Tensor:
    Xq = torch.adaptive_avg_pool2d(argument_1, [1, 1])
    return Xq

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.quant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_284.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_285.QuantStubNested,
    argument_1: Tensor) -> Tensor:
    stubs = self.stubs
    _0 = getattr(stubs, "0")
    return (_0).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.quant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.quant_stubs.stubs.0, type=Quantize:
class Quantize(Module):
  __parameters__ = []
  __buffers__ = ["scale", "zero_point", ]
  scale : Tensor
  zero_point : Tensor
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_283.Quantize,
    argument_1: Tensor) -> Tensor:
    input = torch.quantize_per_tensor(argument_1, 0.036483913660049438, 82, 13)
    return input

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.dequant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_287.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_288.QuantStubNested,
    argument_1: Tensor) -> Tensor:
    stubs = self.stubs
    _0 = getattr(stubs, "0")
    return (_0).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.dequant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_head.dequant_stubs.stubs.0, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_286.DeQuantize,
    argument_1: Tensor) -> Tensor:
    return torch.dequantize(argument_1)

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor, type=QuantWrapSubClass:
class QuantWrapSubClass(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  cls_score : __torch__.torch.nn.quantized.modules.linear.Linear
  bbox_pred : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear
  quant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested
  dequant_stubs : __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_299.QuantWrapSubClass,
    argument_1: Tensor) -> Tuple[Tensor, Tensor]:
    dequant_stubs = self.dequant_stubs
    bbox_pred = self.bbox_pred
    cls_score = self.cls_score
    quant_stubs = self.quant_stubs
    _0 = torch.flatten((quant_stubs).forward(argument_1, ), 1)
    _1 = (dequant_stubs).forward((cls_score).forward(_0, ), (bbox_pred).forward(_0, ), )
    _2, _3, = _1
    return (_2, _3)

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.cls_score, type=Linear:
class Linear(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  _packed_params : __torch__.torch.nn.quantized.modules.linear.LinearPackedParams
  def forward(self: __torch__.torch.nn.quantized.modules.linear.Linear,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _packed_params0 = _packed_params._packed_params
    Xq = ops.quantized.linear(argument_1, _packed_params0, 0.14934095740318298, 28)
    return Xq

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.cls_score._packed_params, type=LinearPackedParams:
class LinearPackedParams(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  dtype : int
  _packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.linear.LinearPackedParams) -> Tuple[Tensor, Optional[Tensor]]:
    _0 = "Unsupported dtype on dynamic quantized linear!"
    _1 = uninitialized(Tuple[Tensor, Optional[Tensor]])
    dtype = self.dtype
    if torch.eq(dtype, 12):
      _packed_params = self._packed_params
      _3, _4 = ops.quantized.linear_unpack(_packed_params)
      _2 = (_3, _4)
    else:
      dtype0 = self.dtype
      if torch.eq(dtype0, 5):
        _packed_params0 = self._packed_params
        _6, _7 = ops.quantized.linear_unpack_fp16(_packed_params0)
        _5 = (_6, _7)
      else:
        ops.prim.RaiseException(_0, "builtins.RuntimeError")
        _5 = _1
      _2 = _5
    return _2
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.linear.LinearPackedParams,
    weight: Tensor,
    bias: Optional[Tensor]) -> NoneType:
    _8 = "Unsupported dtype on dynamic quantized linear!"
    dtype = self.dtype
    if torch.eq(dtype, 12):
      _9 = ops.quantized.linear_prepack(weight, bias)
      self._packed_params = _9
    else:
      dtype1 = self.dtype
      if torch.eq(dtype1, 5):
        _10 = ops.quantized.linear_prepack_fp16(weight, bias)
        self._packed_params = _10
      else:
        ops.prim.RaiseException(_8, "builtins.RuntimeError")
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.bbox_pred, type=Linear:
class Linear(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  _packed_params : __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams
  def forward(self: __torch__.torch.nn.quantized.modules.linear.___torch_mangle_291.Linear,
    argument_1: Tensor) -> Tensor:
    _packed_params = self._packed_params
    _packed_params0 = _packed_params._packed_params
    Xq = ops.quantized.linear(argument_1, _packed_params0, 0.017371678724884987, 63)
    return Xq

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.bbox_pred._packed_params, type=LinearPackedParams:
class LinearPackedParams(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  dtype : int
  _packed_params : __torch__.torch.classes.quantized.LinearPackedParamsBase
  def _weight_bias(self: __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams) -> Tuple[Tensor, Optional[Tensor]]:
    _0 = "Unsupported dtype on dynamic quantized linear!"
    _1 = uninitialized(Tuple[Tensor, Optional[Tensor]])
    dtype = self.dtype
    if torch.eq(dtype, 12):
      _packed_params = self._packed_params
      _3, _4 = ops.quantized.linear_unpack(_packed_params)
      _2 = (_3, _4)
    else:
      dtype0 = self.dtype
      if torch.eq(dtype0, 5):
        _packed_params0 = self._packed_params
        _6, _7 = ops.quantized.linear_unpack_fp16(_packed_params0)
        _5 = (_6, _7)
      else:
        ops.prim.RaiseException(_0, "builtins.RuntimeError")
        _5 = _1
      _2 = _5
    return _2
  def set_weight_bias(self: __torch__.torch.nn.quantized.modules.linear.___torch_mangle_290.LinearPackedParams,
    weight: Tensor,
    bias: Optional[Tensor]) -> NoneType:
    _8 = "Unsupported dtype on dynamic quantized linear!"
    dtype = self.dtype
    if torch.eq(dtype, 12):
      _9 = ops.quantized.linear_prepack(weight, bias)
      self._packed_params = _9
    else:
      dtype1 = self.dtype
      if torch.eq(dtype1, 5):
        _10 = ops.quantized.linear_prepack_fp16(weight, bias)
        self._packed_params = _10
      else:
        ops.prim.RaiseException(_8, "builtins.RuntimeError")
    return None

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.quant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_293.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_294.QuantStubNested,
    argument_1: Tensor) -> Tensor:
    stubs = self.stubs
    _0 = getattr(stubs, "0")
    return (_0).forward(argument_1, )

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.quant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.quant_stubs.stubs.0, type=Quantize:
class Quantize(Module):
  __parameters__ = []
  __buffers__ = ["scale", "zero_point", ]
  scale : Tensor
  zero_point : Tensor
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_292.Quantize,
    argument_1: Tensor) -> Tensor:
    x = torch.quantize_per_tensor(argument_1, 0.066273242235183716, 62, 13)
    return x

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.dequant_stubs, type=QuantStubNested:
class QuantStubNested(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  stubs : __torch__.torch.nn.modules.container.___torch_mangle_297.ModuleList
  def forward(self: __torch__.mobile_cv.arch.utils.quantize_utils.___torch_mangle_298.QuantStubNested,
    argument_1: Tensor,
    argument_2: Tensor) -> Tuple[Tensor, Tensor]:
    stubs = self.stubs
    _1 = getattr(stubs, "1")
    stubs0 = self.stubs
    _0 = getattr(stubs0, "0")
    _2 = (_0).forward(argument_1, )
    return ((_1).forward(argument_2, ), _2)

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.dequant_stubs.stubs, type=ModuleList:
class ModuleList(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  __annotations__["0"] = __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize
  __annotations__["1"] = __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.dequant_stubs.stubs.0, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_295.DeQuantize,
    argument_1: Tensor) -> Tensor:
    return torch.dequantize(argument_1)

--------------------------------------------------------------------------------
Code for .model.model.roi_heads.box_predictor.dequant_stubs.stubs.1, type=DeQuantize:
class DeQuantize(Module):
  __parameters__ = []
  __buffers__ = []
  training : bool
  _is_full_backward_hook : Optional[bool]
  def forward(self: __torch__.torch.nn.quantized.modules.___torch_mangle_296.DeQuantize,
    argument_1: Tensor) -> Tensor:
    return torch.dequantize(argument_1)

--------------------------------------------------------------------------------